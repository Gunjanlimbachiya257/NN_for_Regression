{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Fit Regression Data with NN Model in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "y = pd.Series(boston['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "    # :Attribute Information (in order):\n",
    "    #     - CRIM     per capita crime rate by town\n",
    "    #     - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    #     - INDUS    proportion of non-retail business acres per town\n",
    "    #     - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "    #     - NOX      nitric oxides concentration (parts per 10 million)\n",
    "    #     - RM       average number of rooms per dwelling\n",
    "    #     - AGE      proportion of owner-occupied units built prior to 1940\n",
    "    #     - DIS      weighted distances to five Boston employment centres\n",
    "    #     - RAD      index of accessibility to radial highways\n",
    "    #     - TAX      full-value property-tax rate per $10,000\n",
    "    #     - PTRATIO  pupil-teacher ratio by town\n",
    "    #     - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "    #     - LSTAT    % lower status of the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Length: 506, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y   # MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter_Tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor # There is also a KerasClassifier class\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# To tune ANN hyperparameters we will need a function building/returning a model.\n",
    "# This function's parameters must be our model hyperparameters that we want to tune.\n",
    "\n",
    "#tuning:\n",
    "#  - the number of hidden layers\n",
    "#  - the number of neurons in each hidden layer.\n",
    "\n",
    "\n",
    "def build_model(number_of_hidden_layers=3, number_of_neurons=2):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(Dense(number_of_neurons, input_shape=(13,), activation='relu'))\n",
    "    \n",
    "    # hidden layers\n",
    "    for hidden_layer_number in range(1, number_of_hidden_layers):\n",
    "        model.add(Dense(number_of_neurons, activation='relu'))\n",
    "        \n",
    "    # output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = KerasRegressor(build_fn=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 823.1649 - val_loss: 195.5978\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 143.5387 - val_loss: 199.2804\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 134.8203 - val_loss: 143.9524\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.2175 - val_loss: 126.6239\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.9348 - val_loss: 97.9818\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.5402 - val_loss: 87.2333\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.7425 - val_loss: 83.2636\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5817 - val_loss: 82.4228\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4851 - val_loss: 84.4232\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9600 - val_loss: 83.8963\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9793 - val_loss: 85.1288\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6053 - val_loss: 82.5398\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1785 - val_loss: 81.1463\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.8273 - val_loss: 83.3449\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5243 - val_loss: 80.5787\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5440 - val_loss: 76.6460\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7643 - val_loss: 87.4223\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.9384 - val_loss: 78.2492\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.3132 - val_loss: 77.2930\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1333 - val_loss: 88.0539\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3783 - val_loss: 79.0364\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3207 - val_loss: 79.8460\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.7246 - val_loss: 74.3975\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2770 - val_loss: 81.4031\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.5320 - val_loss: 72.6411\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9829 - val_loss: 77.7496\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.3677 - val_loss: 70.2705\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.0456 - val_loss: 77.4948\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 54.3802 - val_loss: 68.7256\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0937 - val_loss: 75.7083\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5427 - val_loss: 68.3376\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5530 - val_loss: 76.7050\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2527 - val_loss: 69.1941\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4038 - val_loss: 72.4470\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6877 - val_loss: 69.4649\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0486 - val_loss: 69.3341\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7256 - val_loss: 65.5278\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2233 - val_loss: 77.3839\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5527 - val_loss: 69.4362\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8733 - val_loss: 64.6897\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2063 - val_loss: 73.6728\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5172 - val_loss: 63.2523\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6252 - val_loss: 72.6154\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5666 - val_loss: 68.8696\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8755 - val_loss: 60.3414\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7276 - val_loss: 70.9089\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.5438 - val_loss: 61.7005\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4404 - val_loss: 64.7961\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.8014 - val_loss: 62.1739\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.5056 - val_loss: 64.8301\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 45.9493 - val_loss: 62.5698\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8872 - val_loss: 69.1000\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4229 - val_loss: 61.4320\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1460 - val_loss: 58.9354\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3390 - val_loss: 77.0317\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7137 - val_loss: 59.8409\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7440 - val_loss: 59.3944\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8399 - val_loss: 69.5226\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7711 - val_loss: 56.8203\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 43.9013 - val_loss: 56.0228\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8252 - val_loss: 59.3117\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8052 - val_loss: 53.6076\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8925 - val_loss: 62.6085\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9207 - val_loss: 58.4289\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4680 - val_loss: 54.0532\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3959 - val_loss: 57.9079\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4794 - val_loss: 52.5676\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7317 - val_loss: 54.2794\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 42.8692 - val_loss: 51.7126\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9951 - val_loss: 61.2030\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0593 - val_loss: 52.4480\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4844 - val_loss: 51.1624\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.0824 - val_loss: 50.6082\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.9813 - val_loss: 47.8518\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2239 - val_loss: 54.2164\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4014 - val_loss: 45.9567\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 38.5120 - val_loss: 51.3078\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.8896 - val_loss: 46.0409\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6187 - val_loss: 44.4533\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6813 - val_loss: 49.9150\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4439 - val_loss: 47.7527\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7650 - val_loss: 47.6537\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3576 - val_loss: 45.0349\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6344 - val_loss: 45.0694\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0906 - val_loss: 43.9974\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9490 - val_loss: 43.3570\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.0938 - val_loss: 40.7324\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8527 - val_loss: 44.0757\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.5046 - val_loss: 42.0115\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6782 - val_loss: 45.3604\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3949 - val_loss: 46.0678\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.6424 - val_loss: 40.6787\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.5445 - val_loss: 41.8290\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9425 - val_loss: 40.3239\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0903 - val_loss: 38.7863\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.3337 - val_loss: 38.3655\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4908 - val_loss: 38.9063\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4087 - val_loss: 40.1547\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6044 - val_loss: 43.2279\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1541 - val_loss: 38.3064\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1429 - val_loss: 36.4881\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6950 - val_loss: 47.6833\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5837 - val_loss: 36.0191\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.6103 - val_loss: 38.9567\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.7645 - val_loss: 34.4173\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.1773 - val_loss: 35.5079\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1047 - val_loss: 34.3706\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9953 - val_loss: 37.8112\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.4333 - val_loss: 37.6056\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4872 - val_loss: 44.2742\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5322 - val_loss: 46.9123\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4834 - val_loss: 61.2147\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7260 - val_loss: 35.0566\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8855 - val_loss: 38.8253\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7342 - val_loss: 35.3850\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0599 - val_loss: 36.8958\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5903 - val_loss: 42.0728\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4954 - val_loss: 35.0506\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0968 - val_loss: 34.0578\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1013 - val_loss: 31.5047\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0474 - val_loss: 34.1151\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1614 - val_loss: 30.9320\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.4646 - val_loss: 33.6250\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6737 - val_loss: 29.2866\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.6404 - val_loss: 34.6013\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.6776 - val_loss: 37.3309\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3376 - val_loss: 27.9713\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.2192 - val_loss: 27.3186\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.1150 - val_loss: 28.6072\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.1045 - val_loss: 32.2016\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4613 - val_loss: 31.4042\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6739 - val_loss: 30.6144\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1161 - val_loss: 26.7236\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.9268 - val_loss: 31.8293\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0629 - val_loss: 29.2037\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2910 - val_loss: 30.6003\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.1904 - val_loss: 25.9244\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9195 - val_loss: 28.0453\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6242 - val_loss: 69.3226\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9991 - val_loss: 32.0713\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9780 - val_loss: 41.1739\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5279 - val_loss: 38.6209\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9670 - val_loss: 29.8625\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0030 - val_loss: 28.9426\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.4442 - val_loss: 26.2004\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5423 - val_loss: 27.7712\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0442 - val_loss: 26.1549\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4734 - val_loss: 25.6659\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7940 - val_loss: 27.6819\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7384 - val_loss: 24.9119\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5027 - val_loss: 25.5332\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4402 - val_loss: 27.5479\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3067 - val_loss: 26.3261\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9564 - val_loss: 25.6795\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1710 - val_loss: 25.9132\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6175 - val_loss: 26.3361\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6118 - val_loss: 25.9214\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5087 - val_loss: 29.5782\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1473 - val_loss: 29.9944\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6221 - val_loss: 26.1519\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9695 - val_loss: 23.2906\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8390 - val_loss: 24.1504\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0372 - val_loss: 25.7621\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2383 - val_loss: 26.2373\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1103 - val_loss: 23.6069\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8872 - val_loss: 28.6673\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6929 - val_loss: 36.0648\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5799 - val_loss: 31.3034\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4349 - val_loss: 24.8547\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3851 - val_loss: 22.3189\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3901 - val_loss: 24.4730\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4207 - val_loss: 24.0341\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6489 - val_loss: 24.7938\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9978 - val_loss: 25.8206\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6656 - val_loss: 23.4648\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0577 - val_loss: 23.6611\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8561 - val_loss: 24.5824\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4448 - val_loss: 35.2755\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8472 - val_loss: 30.1836\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3868 - val_loss: 25.6016\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1014 - val_loss: 25.9468\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9001 - val_loss: 23.6054\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2168 - val_loss: 22.4870\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4158 - val_loss: 27.6913\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5549 - val_loss: 26.2833\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3988 - val_loss: 29.5395\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0385 - val_loss: 22.5721\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9707 - val_loss: 22.6970\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1616 - val_loss: 29.9409\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4283 - val_loss: 24.3525\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5713 - val_loss: 22.7540\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8875 - val_loss: 22.2965\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0704 - val_loss: 21.7667\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6160 - val_loss: 23.0733\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6753 - val_loss: 23.9822\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5493 - val_loss: 21.6561\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7993 - val_loss: 21.7511\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6811 - val_loss: 26.5958\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7589 - val_loss: 24.1009\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5187 - val_loss: 21.9573\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 27.7295\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 197.6561 - val_loss: 139.5558\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.2534 - val_loss: 97.8958\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.7300 - val_loss: 92.1547\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.7366 - val_loss: 81.8308\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4573 - val_loss: 81.9721\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0603 - val_loss: 77.9532\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9560 - val_loss: 78.1587\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6529 - val_loss: 82.3849\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1951 - val_loss: 75.9105\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.6507 - val_loss: 77.8097\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0558 - val_loss: 75.1661\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.2114 - val_loss: 73.4182\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5886 - val_loss: 76.2770\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8286 - val_loss: 82.4214\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.8850 - val_loss: 78.6230\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4073 - val_loss: 75.6888\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3284 - val_loss: 71.3481\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4449 - val_loss: 72.8154\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3247 - val_loss: 71.2283\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1848 - val_loss: 72.8075\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.3025 - val_loss: 69.6489\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8238 - val_loss: 67.7321\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.7842 - val_loss: 67.6342\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.7130 - val_loss: 69.0203\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9824 - val_loss: 65.1708\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8116 - val_loss: 68.5109\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4260 - val_loss: 71.2166\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7809 - val_loss: 64.1917\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1108 - val_loss: 65.2246\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0756 - val_loss: 66.6024\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9492 - val_loss: 64.4743\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2993 - val_loss: 64.6519\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6636 - val_loss: 65.1794\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2958 - val_loss: 61.4653\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0788 - val_loss: 62.0240\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4495 - val_loss: 63.8365\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1413 - val_loss: 73.0518\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7244 - val_loss: 58.2653\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7805 - val_loss: 57.6079\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7489 - val_loss: 58.7475\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7094 - val_loss: 59.0112\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7213 - val_loss: 56.9097\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3987 - val_loss: 56.2210\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5980 - val_loss: 72.8400\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9613 - val_loss: 62.3789\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6994 - val_loss: 61.5173\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5147 - val_loss: 53.8975\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8017 - val_loss: 52.6851\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4191 - val_loss: 54.7484\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3641 - val_loss: 54.7028\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0077 - val_loss: 55.2156\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3722 - val_loss: 52.4807\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5128 - val_loss: 48.7866\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4183 - val_loss: 48.5911\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0028 - val_loss: 47.0615\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0379 - val_loss: 46.2116\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.7493 - val_loss: 46.0542\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3039 - val_loss: 46.9810\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2599 - val_loss: 46.0655\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7289 - val_loss: 58.9923\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.3821 - val_loss: 42.8031\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3488 - val_loss: 44.6634\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.8993 - val_loss: 43.5759\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.2873 - val_loss: 42.5055\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.5632 - val_loss: 39.3829\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4742 - val_loss: 39.1630\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9515 - val_loss: 42.8024\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7111 - val_loss: 36.2690\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8099 - val_loss: 36.3811\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1465 - val_loss: 36.9483\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.0315 - val_loss: 34.3771\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.6294 - val_loss: 35.6170\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7264 - val_loss: 34.5385\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5633 - val_loss: 33.0485\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.6647 - val_loss: 38.7902\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.3187 - val_loss: 40.3784\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0875 - val_loss: 30.5535\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2001 - val_loss: 36.3043\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1292 - val_loss: 31.1286\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6070 - val_loss: 43.6913\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8899 - val_loss: 41.4547\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1710 - val_loss: 46.1808\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3854 - val_loss: 33.0675\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7604 - val_loss: 29.9478\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6467 - val_loss: 35.7078\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9888 - val_loss: 34.6517\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4830 - val_loss: 34.3287\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9889 - val_loss: 32.2575\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7114 - val_loss: 42.8917\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.5679 - val_loss: 33.8036\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0939 - val_loss: 35.3631\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.2694 - val_loss: 29.4376\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0389 - val_loss: 31.8290\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1017 - val_loss: 31.1197\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0555 - val_loss: 28.4473\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7380 - val_loss: 30.0603\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.8834 - val_loss: 27.1194\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9272 - val_loss: 26.9353\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9321 - val_loss: 28.1655\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9668 - val_loss: 27.1272\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7781 - val_loss: 26.7486\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7298 - val_loss: 28.3335\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8166 - val_loss: 25.4438\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5818 - val_loss: 26.2219\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8982 - val_loss: 24.5162\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.5871 - val_loss: 27.8004\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7740 - val_loss: 30.4877\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9218 - val_loss: 25.1417\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1245 - val_loss: 31.2018\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.6360 - val_loss: 25.2071\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3170 - val_loss: 24.7720\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5283 - val_loss: 27.7615\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5543 - val_loss: 24.4824\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5149 - val_loss: 24.6253\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5708 - val_loss: 26.5137\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8470 - val_loss: 23.5653\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2995 - val_loss: 29.8734\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7031 - val_loss: 23.0846\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1964 - val_loss: 22.0064\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6863 - val_loss: 21.7700\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5301 - val_loss: 22.6942\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0660 - val_loss: 23.2288\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9337 - val_loss: 27.0376\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3035 - val_loss: 23.4558\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6262 - val_loss: 23.0413\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3275 - val_loss: 21.2076\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7321 - val_loss: 22.1376\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4595 - val_loss: 21.9898\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6606 - val_loss: 23.2576\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5996 - val_loss: 20.2448\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4344 - val_loss: 25.2717\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9406 - val_loss: 20.5035\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2413 - val_loss: 19.6448\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1793 - val_loss: 19.8562\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9672 - val_loss: 20.2637\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7043 - val_loss: 20.9052\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7523 - val_loss: 20.5587\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5856 - val_loss: 28.9022\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2368 - val_loss: 20.5770\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0879 - val_loss: 18.6128\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9471 - val_loss: 21.2947\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7691 - val_loss: 19.3589\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.6784 - val_loss: 18.5413\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3931 - val_loss: 22.8681\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4233 - val_loss: 19.7769\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0950 - val_loss: 19.9278\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5770 - val_loss: 18.8063\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9691 - val_loss: 18.4537\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9087 - val_loss: 19.5945\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1922 - val_loss: 19.4751\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9990 - val_loss: 17.8367\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.6425 - val_loss: 18.8814\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1798 - val_loss: 18.3544\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.4724 - val_loss: 19.4194\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.8346 - val_loss: 21.8374\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8662 - val_loss: 22.0892\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9130 - val_loss: 19.9638\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4488 - val_loss: 17.8191\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.6897 - val_loss: 19.9400\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3245 - val_loss: 19.0510\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7604 - val_loss: 18.5277\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.0028 - val_loss: 23.1901\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8947 - val_loss: 26.7256\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.0260 - val_loss: 17.7872\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.2221 - val_loss: 17.4073\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.6038 - val_loss: 18.5794\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9678 - val_loss: 19.3031\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.3760 - val_loss: 17.0277\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.5343 - val_loss: 17.8564\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1386 - val_loss: 16.1583\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9976 - val_loss: 21.4456\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1445 - val_loss: 19.8544\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5277 - val_loss: 15.3073\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.2902 - val_loss: 18.8437\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.1681 - val_loss: 17.2284\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.0056 - val_loss: 16.1725\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3774 - val_loss: 19.0347\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2606 - val_loss: 27.0589\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0176 - val_loss: 20.2599\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6344 - val_loss: 31.8620\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1381 - val_loss: 18.8089\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9829 - val_loss: 17.7722\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8773 - val_loss: 17.8620\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.9732 - val_loss: 16.4983\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.6236 - val_loss: 16.6174\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.0460 - val_loss: 19.7243\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6987 - val_loss: 17.8068\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7928 - val_loss: 16.1161\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.8495 - val_loss: 17.7934\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0776 - val_loss: 20.8672\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3393 - val_loss: 18.0214\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.9418 - val_loss: 17.2847\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8710 - val_loss: 17.7787\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.4307 - val_loss: 16.2476\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8666 - val_loss: 16.1425\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8045 - val_loss: 17.5663\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7417 - val_loss: 16.0695\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.8326 - val_loss: 16.1179\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7474 - val_loss: 20.5089\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.6758 - val_loss: 20.5327\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 27.7780\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1099.8806 - val_loss: 295.5637\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 325.2327 - val_loss: 179.9292\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114.1564 - val_loss: 181.8003\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 96.2309 - val_loss: 116.2381\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 84.7464 - val_loss: 101.6582\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.2149 - val_loss: 98.3358\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8596 - val_loss: 91.0452\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.3618 - val_loss: 86.5456\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4894 - val_loss: 87.5567\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8418 - val_loss: 85.9249\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0238 - val_loss: 83.4186\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1796 - val_loss: 81.1068\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6458 - val_loss: 78.0172\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.0216 - val_loss: 77.0044\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6363 - val_loss: 77.3281\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8656 - val_loss: 77.5239\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8569 - val_loss: 75.3621\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5576 - val_loss: 74.4874\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1311 - val_loss: 76.9940\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.8409 - val_loss: 74.5075\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0372 - val_loss: 73.8398\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7017 - val_loss: 73.7191\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3308 - val_loss: 72.5359\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.8193 - val_loss: 72.6031\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7807 - val_loss: 72.1603\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.0519 - val_loss: 73.3531\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8460 - val_loss: 74.2717\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.9360 - val_loss: 73.4036\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3229 - val_loss: 77.4539\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4931 - val_loss: 77.6718\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7845 - val_loss: 76.0879\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.8291 - val_loss: 70.8408\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1491 - val_loss: 69.7323\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1426 - val_loss: 70.2898\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.8556 - val_loss: 69.0328\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9700 - val_loss: 67.1843\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8973 - val_loss: 66.9852\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0171 - val_loss: 67.0346\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6801 - val_loss: 68.1887\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5107 - val_loss: 74.7329\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6390 - val_loss: 89.4220\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6766 - val_loss: 83.3679\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0693 - val_loss: 68.1323\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.3736 - val_loss: 67.4207\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.3627 - val_loss: 67.4064\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5307 - val_loss: 64.4086\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0305 - val_loss: 64.8079\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8378 - val_loss: 65.7915\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8717 - val_loss: 63.3381\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5499 - val_loss: 64.6834\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3525 - val_loss: 63.8702\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2187 - val_loss: 64.3663\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6962 - val_loss: 63.0659\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5472 - val_loss: 62.5905\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 49.6851 - val_loss: 62.4064\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1431 - val_loss: 62.2019\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0018 - val_loss: 60.8144\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8532 - val_loss: 61.0812\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2553 - val_loss: 61.1478\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4333 - val_loss: 60.2141\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8919 - val_loss: 65.0432\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9891 - val_loss: 60.0435\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 46.7575 - val_loss: 64.4367\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0313 - val_loss: 59.4700\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3888 - val_loss: 58.1045\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8118 - val_loss: 56.7690\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1339 - val_loss: 55.6972\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6350 - val_loss: 57.1511\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1651 - val_loss: 60.5783\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0344 - val_loss: 55.5946\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6153 - val_loss: 56.2058\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.8907 - val_loss: 62.9158\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5513 - val_loss: 55.7761\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4621 - val_loss: 58.2759\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4271 - val_loss: 54.4568\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.0538 - val_loss: 58.4344\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7690 - val_loss: 62.6976\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3213 - val_loss: 54.5868\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4405 - val_loss: 53.5831\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1753 - val_loss: 54.1022\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4173 - val_loss: 51.6836\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7373 - val_loss: 50.2161\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3168 - val_loss: 51.2247\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6482 - val_loss: 52.1620\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9284 - val_loss: 55.7353\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0069 - val_loss: 55.4260\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7959 - val_loss: 55.0757\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1083 - val_loss: 49.8820\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2494 - val_loss: 48.9483\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2410 - val_loss: 49.7832\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.0497 - val_loss: 48.1481\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.4657 - val_loss: 47.7376\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0459 - val_loss: 55.7769\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9674 - val_loss: 48.5347\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.1111 - val_loss: 51.3221\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6998 - val_loss: 46.1078\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5953 - val_loss: 53.2429\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1889 - val_loss: 62.4453\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6851 - val_loss: 48.8328\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.3388 - val_loss: 46.4772\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.3415 - val_loss: 45.4848\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2514 - val_loss: 58.0803\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1318 - val_loss: 46.1614\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0753 - val_loss: 47.0623\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3235 - val_loss: 52.7763\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4808 - val_loss: 56.3248\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2319 - val_loss: 47.9226\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9521 - val_loss: 47.3249\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8287 - val_loss: 51.8246\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1923 - val_loss: 44.0870\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0200 - val_loss: 43.8164\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7164 - val_loss: 42.7009\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.0536 - val_loss: 41.7583\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5362 - val_loss: 45.0591\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2967 - val_loss: 41.0847\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8131 - val_loss: 45.2017\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8352 - val_loss: 40.7036\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0324 - val_loss: 39.4062\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6137 - val_loss: 41.2286\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2347 - val_loss: 41.2268\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1760 - val_loss: 38.4936\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.4637 - val_loss: 38.1581\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8185 - val_loss: 41.0746\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1994 - val_loss: 39.2937\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6384 - val_loss: 39.7980\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5205 - val_loss: 43.8301\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4968 - val_loss: 52.9565\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3132 - val_loss: 36.9382\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8120 - val_loss: 38.6705\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5958 - val_loss: 37.1106\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9842 - val_loss: 36.6691\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.3567 - val_loss: 39.3209\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0520 - val_loss: 39.9464\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0858 - val_loss: 36.4847\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1882 - val_loss: 42.4672\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7378 - val_loss: 35.5581\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9695 - val_loss: 41.4332\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6052 - val_loss: 34.5149\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.0849 - val_loss: 38.9275\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7849 - val_loss: 41.1737\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5796 - val_loss: 34.4772\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9568 - val_loss: 34.4747\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.4254 - val_loss: 33.2926\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1161 - val_loss: 33.7287\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.3920 - val_loss: 35.1164\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2504 - val_loss: 37.1772\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7562 - val_loss: 39.3365\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2099 - val_loss: 33.7416\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1244 - val_loss: 33.1206\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8853 - val_loss: 32.3594\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.0670 - val_loss: 31.8831\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3020 - val_loss: 31.3261\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6677 - val_loss: 34.8492\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8850 - val_loss: 32.8499\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8595 - val_loss: 29.8945\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1050 - val_loss: 30.9263\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7323 - val_loss: 30.1585\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.1832 - val_loss: 33.7608\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2654 - val_loss: 29.1723\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4766 - val_loss: 31.4012\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3204 - val_loss: 30.2232\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2904 - val_loss: 29.4774\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6054 - val_loss: 32.9814\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2764 - val_loss: 32.9800\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1556 - val_loss: 28.7680\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2311 - val_loss: 29.2962\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7126 - val_loss: 29.7597\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8510 - val_loss: 33.6741\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5805 - val_loss: 27.8358\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5044 - val_loss: 37.1584\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3156 - val_loss: 28.3360\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6234 - val_loss: 26.8725\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3625 - val_loss: 27.2051\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.7309 - val_loss: 27.1125\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8189 - val_loss: 26.2264\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2606 - val_loss: 27.2590\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8020 - val_loss: 26.8864\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6382 - val_loss: 25.3975\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0346 - val_loss: 28.0607\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7849 - val_loss: 36.7414\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2061 - val_loss: 27.0923\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7298 - val_loss: 34.7506\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0482 - val_loss: 25.2406\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1871 - val_loss: 26.6446\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5829 - val_loss: 28.2035\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3950 - val_loss: 24.8744\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1253 - val_loss: 25.2877\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3889 - val_loss: 24.8650\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.6902 - val_loss: 24.6776\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3913 - val_loss: 35.1923\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5213 - val_loss: 27.0834\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0224 - val_loss: 26.9395\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2161 - val_loss: 24.5407\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1766 - val_loss: 25.5380\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7073 - val_loss: 25.3736\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5723 - val_loss: 23.9389\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5595 - val_loss: 26.7010\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3680 - val_loss: 25.2157\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4468 - val_loss: 24.0559\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5406 - val_loss: 24.5048\n",
      "3/3 [==============================] - 0s 909us/step - loss: 22.5949\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 738.0164 - val_loss: 208.5529\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 226.6126 - val_loss: 149.1157\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95.1285 - val_loss: 131.0131\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 87.8030 - val_loss: 94.7535\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.9338 - val_loss: 89.2154\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.8180 - val_loss: 84.4049\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9916 - val_loss: 79.8893\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2377 - val_loss: 76.9378\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2179 - val_loss: 76.3950\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7961 - val_loss: 74.9737\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1189 - val_loss: 73.6018\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3865 - val_loss: 73.3744\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.4876 - val_loss: 71.6376\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3412 - val_loss: 70.4034\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9781 - val_loss: 69.3426\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0083 - val_loss: 68.7003\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6825 - val_loss: 67.3883\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2635 - val_loss: 65.9356\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3280 - val_loss: 67.4379\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3529 - val_loss: 64.7060\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3338 - val_loss: 66.0764\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0465 - val_loss: 64.6510\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9173 - val_loss: 65.1363\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2045 - val_loss: 65.0008\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4398 - val_loss: 66.3464\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1637 - val_loss: 65.8136\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0343 - val_loss: 67.9454\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4051 - val_loss: 63.3516\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5322 - val_loss: 61.4004\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3425 - val_loss: 59.1147\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4949 - val_loss: 62.4132\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2428 - val_loss: 61.5239\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6056 - val_loss: 58.4299\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4096 - val_loss: 60.1006\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2952 - val_loss: 63.0522\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3087 - val_loss: 71.8172\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3849 - val_loss: 56.6836\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1213 - val_loss: 55.9962\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9486 - val_loss: 56.7909\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2896 - val_loss: 56.1920\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5518 - val_loss: 57.4315\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8521 - val_loss: 57.9868\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3331 - val_loss: 53.3847\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9075 - val_loss: 63.8616\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5090 - val_loss: 73.2651\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0663 - val_loss: 52.2205\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4437 - val_loss: 63.9152\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0688 - val_loss: 59.0535\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0089 - val_loss: 53.3872\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3517 - val_loss: 52.5699\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5627 - val_loss: 52.2990\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.0201 - val_loss: 48.7424\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2659 - val_loss: 51.4122\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6825 - val_loss: 48.9815\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2876 - val_loss: 47.1024\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0980 - val_loss: 49.4246\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.0983 - val_loss: 48.7911\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9331 - val_loss: 48.3444\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0103 - val_loss: 48.5045\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6593 - val_loss: 44.4514\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.4764 - val_loss: 48.8798\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8710 - val_loss: 45.1911\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0528 - val_loss: 43.5815\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1159 - val_loss: 45.1447\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2350 - val_loss: 43.7860\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6560 - val_loss: 41.6912\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9114 - val_loss: 43.2248\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7611 - val_loss: 43.4859\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1144 - val_loss: 43.8865\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3451 - val_loss: 42.1449\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2862 - val_loss: 41.9950\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7384 - val_loss: 41.3046\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7623 - val_loss: 46.0347\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0124 - val_loss: 42.7395\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4408 - val_loss: 46.1057\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5338 - val_loss: 40.4224\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9238 - val_loss: 40.1886\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9746 - val_loss: 45.0190\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1083 - val_loss: 37.5076\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.6969 - val_loss: 36.3525\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6620 - val_loss: 41.1852\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7070 - val_loss: 39.5876\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0352 - val_loss: 37.9434\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5341 - val_loss: 37.7833\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8698 - val_loss: 47.5269\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4111 - val_loss: 60.1258\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9389 - val_loss: 37.9853\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.0502 - val_loss: 36.6501\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7040 - val_loss: 37.8160\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9285 - val_loss: 37.6330\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0185 - val_loss: 36.9458\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5371 - val_loss: 33.7327\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1149 - val_loss: 40.5393\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.8507 - val_loss: 38.3262\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8167 - val_loss: 36.0916\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6127 - val_loss: 33.6595\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9505 - val_loss: 33.8428\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0850 - val_loss: 33.1267\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1480 - val_loss: 34.2463\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0520 - val_loss: 38.7444\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0796 - val_loss: 33.1335\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1610 - val_loss: 33.9890\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3393 - val_loss: 32.9462\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9567 - val_loss: 31.7120\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2067 - val_loss: 35.0961\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7942 - val_loss: 35.7955\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 29.0579 - val_loss: 33.2057\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.6119 - val_loss: 35.6621\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2798 - val_loss: 30.6380\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8533 - val_loss: 31.9026\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1411 - val_loss: 32.2420\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0348 - val_loss: 33.6406\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4441 - val_loss: 31.3388\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8480 - val_loss: 30.4682\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7370 - val_loss: 34.4123\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3749 - val_loss: 33.7520\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6456 - val_loss: 39.6839\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3601 - val_loss: 32.9294\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.5123 - val_loss: 37.4131\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4288 - val_loss: 32.5496\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8998 - val_loss: 36.8130\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8313 - val_loss: 33.9335\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4656 - val_loss: 45.1818\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6283 - val_loss: 34.2080\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9917 - val_loss: 31.4091\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8904 - val_loss: 33.4026\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4073 - val_loss: 29.8554\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5245 - val_loss: 29.4325\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.2710 - val_loss: 31.3386\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5513 - val_loss: 30.6598\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9499 - val_loss: 29.3326\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1242 - val_loss: 32.0833\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2425 - val_loss: 28.3488\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2137 - val_loss: 30.0459\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5357 - val_loss: 31.2552\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7453 - val_loss: 32.1127\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9669 - val_loss: 29.5539\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8538 - val_loss: 35.7252\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3485 - val_loss: 37.6578\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2411 - val_loss: 30.8989\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1558 - val_loss: 31.3585\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7512 - val_loss: 28.3030\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1878 - val_loss: 28.5074\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3720 - val_loss: 27.4056\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7849 - val_loss: 28.9512\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.6461 - val_loss: 34.3574\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6889 - val_loss: 35.6481\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6843 - val_loss: 27.4549\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4902 - val_loss: 26.7209\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8204 - val_loss: 33.7541\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1087 - val_loss: 35.0138\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0098 - val_loss: 28.2981\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9293 - val_loss: 30.9898\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3413 - val_loss: 29.3773\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3538 - val_loss: 30.4748\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5782 - val_loss: 31.2148\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2475 - val_loss: 34.2648\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2551 - val_loss: 27.5090\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5751 - val_loss: 27.9218\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5376 - val_loss: 26.8468\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5617 - val_loss: 28.8791\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4391 - val_loss: 28.1886\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5405 - val_loss: 27.5301\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7932 - val_loss: 27.4840\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5885 - val_loss: 26.5577\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1884 - val_loss: 26.6356\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3192 - val_loss: 26.8783\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.6653 - val_loss: 25.0576\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8701 - val_loss: 25.7217\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4337 - val_loss: 24.2865\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2552 - val_loss: 25.2164\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7914 - val_loss: 25.5374\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0290 - val_loss: 26.6123\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3170 - val_loss: 29.3541\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.0538 - val_loss: 30.5911\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9259 - val_loss: 26.6479\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5783 - val_loss: 42.3921\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3107 - val_loss: 36.3724\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7275 - val_loss: 27.5351\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0975 - val_loss: 25.5927\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3177 - val_loss: 25.7642\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4014 - val_loss: 26.6781\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8730 - val_loss: 23.2935\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0656 - val_loss: 27.3962\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 20.6429 - val_loss: 25.6709\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1625 - val_loss: 25.0404\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2540 - val_loss: 25.0330\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2951 - val_loss: 25.2320\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9856 - val_loss: 24.3321\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.5089 - val_loss: 25.5802\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0529 - val_loss: 31.2510\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9186 - val_loss: 27.1293\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4642 - val_loss: 24.8960\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3179 - val_loss: 24.4863\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3323 - val_loss: 30.0773\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.7258 - val_loss: 27.6270\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8387 - val_loss: 30.9970\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5121 - val_loss: 26.8801\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.2118 - val_loss: 27.6297\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9187 - val_loss: 25.5580\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 19.0912\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 557.7717 - val_loss: 183.1035\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 127.4277 - val_loss: 148.1015\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.9118 - val_loss: 99.2933\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3179 - val_loss: 79.7467\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6411 - val_loss: 77.2027\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5303 - val_loss: 74.9635\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1426 - val_loss: 73.6037\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3180 - val_loss: 74.0443\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2028 - val_loss: 71.2228\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4596 - val_loss: 72.4747\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6113 - val_loss: 70.8057\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0993 - val_loss: 71.1993\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5285 - val_loss: 70.1126\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4448 - val_loss: 72.1551\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3910 - val_loss: 72.4185\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1184 - val_loss: 68.8903\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2425 - val_loss: 72.2131\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6719 - val_loss: 70.3993\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2939 - val_loss: 72.9801\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8143 - val_loss: 67.7255\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3295 - val_loss: 70.0304\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9593 - val_loss: 69.0856\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6987 - val_loss: 69.5826\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6932 - val_loss: 68.3378\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.5080 - val_loss: 67.7345\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6005 - val_loss: 66.8078\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2647 - val_loss: 71.9867\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0908 - val_loss: 68.2060\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.2405 - val_loss: 65.9679\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0729 - val_loss: 64.5789\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9984 - val_loss: 68.3546\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0504 - val_loss: 64.1579\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5103 - val_loss: 63.0134\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9230 - val_loss: 64.0989\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6568 - val_loss: 64.5195\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8968 - val_loss: 63.1371\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2672 - val_loss: 62.0082\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0831 - val_loss: 59.1451\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5715 - val_loss: 62.4463\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3143 - val_loss: 59.3614\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0371 - val_loss: 65.6303\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7882 - val_loss: 59.4613\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6103 - val_loss: 57.2716\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.3624 - val_loss: 63.6928\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6395 - val_loss: 57.0479\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4560 - val_loss: 54.6649\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2517 - val_loss: 57.6454\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2575 - val_loss: 63.9702\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.9954 - val_loss: 53.8369\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1116 - val_loss: 57.1207\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0835 - val_loss: 54.0860\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3233 - val_loss: 54.5240\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4617 - val_loss: 52.5343\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2150 - val_loss: 51.4618\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2318 - val_loss: 52.2603\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2250 - val_loss: 54.0831\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.5151 - val_loss: 59.5671\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9772 - val_loss: 49.6083\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0689 - val_loss: 50.9233\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0647 - val_loss: 47.8854\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7218 - val_loss: 44.5774\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6807 - val_loss: 45.4732\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5127 - val_loss: 44.4275\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1244 - val_loss: 44.2391\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0737 - val_loss: 43.6142\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3860 - val_loss: 45.7714\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.9018 - val_loss: 60.3259\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3612 - val_loss: 45.2545\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1690 - val_loss: 49.7071\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2248 - val_loss: 43.3988\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3622 - val_loss: 39.0918\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9923 - val_loss: 41.5895\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4511 - val_loss: 42.4729\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9597 - val_loss: 47.3674\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1458 - val_loss: 38.2941\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.0499 - val_loss: 37.4057\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3383 - val_loss: 37.2174\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1208 - val_loss: 35.8097\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9487 - val_loss: 36.3019\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2998 - val_loss: 36.8396\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8893 - val_loss: 38.3112\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6130 - val_loss: 36.7157\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2615 - val_loss: 40.3785\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.1229 - val_loss: 34.2951\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5544 - val_loss: 34.5861\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4546 - val_loss: 32.9986\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5032 - val_loss: 33.4175\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7928 - val_loss: 42.8786\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7641 - val_loss: 38.6266\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1907 - val_loss: 33.9922\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0811 - val_loss: 45.5278\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.5660 - val_loss: 33.9627\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9731 - val_loss: 39.9890\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6218 - val_loss: 39.2191\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5214 - val_loss: 31.2923\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7608 - val_loss: 31.1589\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4637 - val_loss: 31.3585\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2898 - val_loss: 30.9974\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3334 - val_loss: 32.6615\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2371 - val_loss: 35.4782\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6824 - val_loss: 33.1320\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2461 - val_loss: 34.0525\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1730 - val_loss: 34.4466\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.4751 - val_loss: 28.6377\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8462 - val_loss: 33.3823\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9169 - val_loss: 25.4684\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0373 - val_loss: 30.4043\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9701 - val_loss: 34.5443\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6932 - val_loss: 41.9993\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2940 - val_loss: 30.7704\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4127 - val_loss: 25.7874\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0572 - val_loss: 27.9674\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8256 - val_loss: 27.4682\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3960 - val_loss: 28.1826\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1721 - val_loss: 35.4037\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4027 - val_loss: 39.8713\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5650 - val_loss: 30.3017\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3817 - val_loss: 25.0579\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.5649 - val_loss: 26.8728\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0628 - val_loss: 24.4283\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8216 - val_loss: 22.3574\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1723 - val_loss: 25.5985\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.2076 - val_loss: 22.7066\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7845 - val_loss: 26.5833\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7268 - val_loss: 28.2850\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3484 - val_loss: 27.4922\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5026 - val_loss: 27.6158\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.0894 - val_loss: 24.9851\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7772 - val_loss: 24.4845\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.8307 - val_loss: 39.4685\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7129 - val_loss: 28.8324\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8107 - val_loss: 26.1041\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0542 - val_loss: 24.8020\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6546 - val_loss: 27.4322\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1416 - val_loss: 24.3411\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7722 - val_loss: 25.2475\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2682 - val_loss: 22.7827\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5192 - val_loss: 25.0336\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3986 - val_loss: 27.1292\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.8491 - val_loss: 22.8090\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.2592 - val_loss: 26.6487\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.4825 - val_loss: 27.5329\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.3471 - val_loss: 21.9226\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.6382 - val_loss: 21.7821\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3516 - val_loss: 21.5839\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.2625 - val_loss: 27.6407\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4151 - val_loss: 29.7607\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2312 - val_loss: 25.4306\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3719 - val_loss: 23.7516\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.0116 - val_loss: 28.3563\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.9406 - val_loss: 31.2310\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.6860 - val_loss: 21.1244\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.5662 - val_loss: 19.8639\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.3310 - val_loss: 26.7675\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.9445 - val_loss: 28.1812\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7227 - val_loss: 22.4738\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5118 - val_loss: 27.4717\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0537 - val_loss: 22.2272\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6253 - val_loss: 27.2859\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0773 - val_loss: 21.1209\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.5886 - val_loss: 21.7676\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.2796 - val_loss: 18.3956\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.4444 - val_loss: 21.1552\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.4553 - val_loss: 19.6599\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6608 - val_loss: 20.8943\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3233 - val_loss: 26.9746\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.7188 - val_loss: 23.1282\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.3482 - val_loss: 22.6558\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.7444 - val_loss: 29.7337\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6840 - val_loss: 32.8637\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5751 - val_loss: 35.1429\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2928 - val_loss: 20.2009\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6289 - val_loss: 21.9105\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.9511 - val_loss: 21.6514\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.2591 - val_loss: 19.3650\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.5747 - val_loss: 18.6641\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.9480 - val_loss: 22.2065\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.0424 - val_loss: 24.1509\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.2149 - val_loss: 18.3211\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 13.2128 - val_loss: 18.3376\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.9722 - val_loss: 18.1810\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.2402 - val_loss: 17.1090\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.4904 - val_loss: 17.8716\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8214 - val_loss: 19.5806\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6268 - val_loss: 23.8285\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.4459 - val_loss: 20.2467\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.5278 - val_loss: 17.5176\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.5241 - val_loss: 17.8688\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.0872 - val_loss: 17.5055\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 13.2751 - val_loss: 17.4608\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1903 - val_loss: 21.4013\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0991 - val_loss: 19.8087\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.4384 - val_loss: 20.3731\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.1836 - val_loss: 17.6554\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.9113 - val_loss: 20.1025\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13.1510 - val_loss: 23.8683\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.5502 - val_loss: 23.8582\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.3883 - val_loss: 18.3546\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.3391 - val_loss: 20.6041\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2208 - val_loss: 22.4824\n",
      "3/3 [==============================] - 0s 947us/step - loss: 32.3317\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 88.8942 - val_loss: 89.5233\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.4203 - val_loss: 90.1573\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.8152 - val_loss: 88.7950\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9151 - val_loss: 88.4140\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.1365 - val_loss: 88.5126\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.7448 - val_loss: 91.0200\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4230 - val_loss: 87.8289\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.8655 - val_loss: 86.2282\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.8328 - val_loss: 85.6710\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2842 - val_loss: 83.7911\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6877 - val_loss: 84.6447\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3380 - val_loss: 86.1014\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8693 - val_loss: 84.5451\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1384 - val_loss: 84.4494\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4901 - val_loss: 83.2651\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1111 - val_loss: 83.4109\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2286 - val_loss: 81.2328\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8469 - val_loss: 82.7065\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2087 - val_loss: 82.6810\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9058 - val_loss: 81.7966\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7876 - val_loss: 80.2259\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6509 - val_loss: 85.4800\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4698 - val_loss: 81.1028\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3588 - val_loss: 80.3301\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0476 - val_loss: 81.3458\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2544 - val_loss: 81.6171\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.9530 - val_loss: 79.6723\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3282 - val_loss: 79.9364\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3888 - val_loss: 79.5806\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0078 - val_loss: 81.1352\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5569 - val_loss: 79.3091\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2801 - val_loss: 78.4084\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0482 - val_loss: 80.8958\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1440 - val_loss: 79.2065\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6196 - val_loss: 82.2178\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8088 - val_loss: 76.3987\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0058 - val_loss: 78.0367\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0632 - val_loss: 76.4649\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3492 - val_loss: 78.3221\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2945 - val_loss: 75.3367\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4573 - val_loss: 76.4920\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1007 - val_loss: 76.6141\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1191 - val_loss: 74.2276\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1573 - val_loss: 73.8747\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3867 - val_loss: 75.5122\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.4326 - val_loss: 79.0695\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9151 - val_loss: 74.9816\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3614 - val_loss: 73.1520\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1446 - val_loss: 74.4120\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7439 - val_loss: 74.5333\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0196 - val_loss: 76.6831\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8555 - val_loss: 81.0616\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5773 - val_loss: 72.1039\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3776 - val_loss: 72.6521\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3963 - val_loss: 76.0881\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0439 - val_loss: 75.1093\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8909 - val_loss: 75.7555\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2778 - val_loss: 81.2056\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.8600 - val_loss: 75.4203\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0457 - val_loss: 73.6758\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.4047 - val_loss: 77.8541\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2715 - val_loss: 70.8755\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9417 - val_loss: 71.6992\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7675 - val_loss: 73.4694\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7613 - val_loss: 71.1052\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0513 - val_loss: 70.5791\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0339 - val_loss: 71.6431\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0956 - val_loss: 74.5759\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8289 - val_loss: 69.6530\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2035 - val_loss: 65.9666\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5035 - val_loss: 73.1367\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9948 - val_loss: 66.8661\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8621 - val_loss: 68.1946\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3457 - val_loss: 67.9841\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9854 - val_loss: 67.6445\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5132 - val_loss: 66.7432\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2230 - val_loss: 67.2314\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3072 - val_loss: 74.0387\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6233 - val_loss: 65.5881\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2780 - val_loss: 65.1527\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6854 - val_loss: 65.6000\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1766 - val_loss: 65.2774\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7300 - val_loss: 74.1943\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3317 - val_loss: 65.4781\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2079 - val_loss: 62.4260\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4325 - val_loss: 64.4209\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4665 - val_loss: 66.4628\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1773 - val_loss: 64.3571\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8980 - val_loss: 62.2872\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3836 - val_loss: 66.6161\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4722 - val_loss: 61.0474\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6328 - val_loss: 63.6896\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9324 - val_loss: 78.6354\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0435 - val_loss: 60.8210\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9669 - val_loss: 63.1015\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8261 - val_loss: 65.1508\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9502 - val_loss: 59.4346\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9601 - val_loss: 60.5816\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8550 - val_loss: 62.2352\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6807 - val_loss: 58.9002\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6361 - val_loss: 59.9880\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8695 - val_loss: 60.5869\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4781 - val_loss: 60.4764\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5465 - val_loss: 57.5313\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9911 - val_loss: 57.4913\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2082 - val_loss: 57.7242\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2361 - val_loss: 59.2345\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0563 - val_loss: 55.5314\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2414 - val_loss: 55.2003\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9276 - val_loss: 60.8069\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2820 - val_loss: 55.6336\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3462 - val_loss: 54.6229\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4534 - val_loss: 55.1322\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7313 - val_loss: 55.2526\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2807 - val_loss: 55.7170\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6295 - val_loss: 53.5969\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4715 - val_loss: 54.9358\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2531 - val_loss: 56.6288\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2662 - val_loss: 57.7839\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7074 - val_loss: 51.8388\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9713 - val_loss: 52.4265\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9373 - val_loss: 57.1277\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9913 - val_loss: 55.2070\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7926 - val_loss: 60.8102\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1061 - val_loss: 50.5049\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7174 - val_loss: 52.0118\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6882 - val_loss: 50.9264\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4017 - val_loss: 50.5948\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0017 - val_loss: 49.8183\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7205 - val_loss: 50.9267\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1151 - val_loss: 48.8704\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.7183 - val_loss: 54.5725\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0699 - val_loss: 64.8119\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3058 - val_loss: 47.0031\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7261 - val_loss: 48.3963\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9623 - val_loss: 49.3109\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.4945 - val_loss: 46.2730\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7056 - val_loss: 49.3013\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5430 - val_loss: 52.3620\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4007 - val_loss: 46.1914\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.8300 - val_loss: 46.2806\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6195 - val_loss: 46.7733\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.5072 - val_loss: 46.5396\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7169 - val_loss: 45.3552\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8158 - val_loss: 50.4276\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0058 - val_loss: 46.3363\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0123 - val_loss: 43.7029\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0419 - val_loss: 50.4990\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0183 - val_loss: 44.2536\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2677 - val_loss: 43.3438\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5327 - val_loss: 45.3268\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7341 - val_loss: 42.4246\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3490 - val_loss: 43.5047\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2860 - val_loss: 44.6444\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6023 - val_loss: 44.0164\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2790 - val_loss: 48.8710\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.3052 - val_loss: 45.3416\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.3714 - val_loss: 46.6167\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.6561 - val_loss: 43.0959\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 34.3496 - val_loss: 44.4246\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3174 - val_loss: 45.1428\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7320 - val_loss: 41.5098\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0489 - val_loss: 46.2564\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5572 - val_loss: 40.0281\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0030 - val_loss: 40.0828\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9800 - val_loss: 39.8000\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5355 - val_loss: 45.4162\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.0105 - val_loss: 39.3430\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.2288 - val_loss: 40.1647\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.7206 - val_loss: 43.4076\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6589 - val_loss: 43.0818\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8722 - val_loss: 39.5664\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9305 - val_loss: 37.5770\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6535 - val_loss: 38.3798\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4998 - val_loss: 37.6175\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6889 - val_loss: 36.1133\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1646 - val_loss: 37.4185\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.4106 - val_loss: 38.6046\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.3066 - val_loss: 43.3107\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.3856 - val_loss: 36.2912\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.0127 - val_loss: 36.0866\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.8785 - val_loss: 35.9689\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9296 - val_loss: 35.4888\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2848 - val_loss: 35.3500\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.5474 - val_loss: 36.3034\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5813 - val_loss: 36.0748\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4651 - val_loss: 34.1286\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8201 - val_loss: 32.1444\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.9643 - val_loss: 34.7445\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 28.1174 - val_loss: 34.9700\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2009 - val_loss: 32.7188\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7926 - val_loss: 33.8245\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.1447 - val_loss: 31.9867\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3556 - val_loss: 32.2485\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7866 - val_loss: 32.7319\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4004 - val_loss: 30.0743\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0819 - val_loss: 35.0857\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1417 - val_loss: 34.3562\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0420 - val_loss: 34.2828\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5442 - val_loss: 32.8322\n",
      "3/3 [==============================] - 0s 922us/step - loss: 23.7118\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 906.6240 - val_loss: 661.2055\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 493.5298 - val_loss: 447.7174\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 347.0406 - val_loss: 334.6004\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 248.8364 - val_loss: 248.9942\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 173.5453 - val_loss: 172.1220\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 115.6502 - val_loss: 139.2138\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 99.8763 - val_loss: 129.5275\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.5388 - val_loss: 120.3953\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.5984 - val_loss: 113.4785\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.7523 - val_loss: 110.5948\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.5561 - val_loss: 105.7365\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 81.3793 - val_loss: 104.3130\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.3082 - val_loss: 101.5196\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.8317 - val_loss: 99.6618\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.9451 - val_loss: 99.0200\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 77.1209 - val_loss: 96.8764\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.8146 - val_loss: 95.2021\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 74.5490 - val_loss: 94.3654\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.5604 - val_loss: 93.1705\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 72.7263 - val_loss: 92.0147\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6050 - val_loss: 90.8337\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 70.9494 - val_loss: 89.4832\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 69.7319 - val_loss: 87.8577\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.7764 - val_loss: 87.6396\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 68.1160 - val_loss: 86.5854\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.8374 - val_loss: 84.1997\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3562 - val_loss: 83.2188\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2348 - val_loss: 81.9497\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.3345 - val_loss: 80.5629\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1424 - val_loss: 81.1476\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.2541 - val_loss: 80.1072\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7236 - val_loss: 77.1038\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5783 - val_loss: 78.5089\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3722 - val_loss: 78.3933\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7937 - val_loss: 77.3626\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3377 - val_loss: 77.3113\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7544 - val_loss: 77.4382\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7051 - val_loss: 76.1146\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1526 - val_loss: 75.7740\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3560 - val_loss: 75.3305\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1549 - val_loss: 74.5829\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3236 - val_loss: 72.0884\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7041 - val_loss: 71.3341\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3337 - val_loss: 72.6540\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5413 - val_loss: 74.3131\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2622 - val_loss: 73.7161\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6529 - val_loss: 71.3145\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2394 - val_loss: 69.9556\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7524 - val_loss: 69.7781\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7171 - val_loss: 69.8919\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3959 - val_loss: 70.0996\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4063 - val_loss: 69.9737\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6362 - val_loss: 69.7648\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6872 - val_loss: 69.4552\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3120 - val_loss: 68.1841\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9536 - val_loss: 67.0802\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9172 - val_loss: 67.0953\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1249 - val_loss: 68.5977\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1282 - val_loss: 66.5942\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2760 - val_loss: 66.2830\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4546 - val_loss: 67.4476\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6483 - val_loss: 66.6442\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1453 - val_loss: 66.3688\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.9414 - val_loss: 66.3387\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8828 - val_loss: 67.4559\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6723 - val_loss: 66.0022\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2848 - val_loss: 65.5124\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1012 - val_loss: 67.0234\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7781 - val_loss: 65.9114\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1613 - val_loss: 63.8017\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9886 - val_loss: 63.7579\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3298 - val_loss: 63.5341\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6285 - val_loss: 64.0149\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5297 - val_loss: 63.8900\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5053 - val_loss: 63.1591\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6974 - val_loss: 62.5337\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8452 - val_loss: 60.3939\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9675 - val_loss: 61.6022\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1689 - val_loss: 62.1535\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2662 - val_loss: 61.8868\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.5778 - val_loss: 61.7016\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3429 - val_loss: 60.2188\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4067 - val_loss: 60.2651\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4529 - val_loss: 63.4722\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0785 - val_loss: 60.6921\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6839 - val_loss: 58.0740\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4431 - val_loss: 57.5970\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3490 - val_loss: 58.1768\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7371 - val_loss: 60.1449\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0715 - val_loss: 57.8098\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3636 - val_loss: 57.0512\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1609 - val_loss: 57.7782\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8069 - val_loss: 58.0823\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6543 - val_loss: 55.6865\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7541 - val_loss: 56.8819\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1614 - val_loss: 54.7215\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5696 - val_loss: 55.7973\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7784 - val_loss: 55.9420\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1969 - val_loss: 56.7624\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4743 - val_loss: 53.5391\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0748 - val_loss: 53.0197\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7440 - val_loss: 53.9639\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8249 - val_loss: 54.2699\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5767 - val_loss: 55.0078\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1816 - val_loss: 54.4290\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1393 - val_loss: 53.1911\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0611 - val_loss: 50.8551\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9428 - val_loss: 50.9119\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2573 - val_loss: 53.2174\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7705 - val_loss: 50.0238\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5918 - val_loss: 52.2093\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0149 - val_loss: 51.3205\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2699 - val_loss: 49.0957\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9716 - val_loss: 51.2864\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6403 - val_loss: 49.8546\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6576 - val_loss: 48.8645\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9950 - val_loss: 49.2204\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2988 - val_loss: 48.3811\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.4158 - val_loss: 48.7734\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2718 - val_loss: 47.5948\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3103 - val_loss: 46.4556\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2169 - val_loss: 46.3628\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1718 - val_loss: 46.3563\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2187 - val_loss: 45.5361\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9827 - val_loss: 46.8998\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0133 - val_loss: 44.0501\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7016 - val_loss: 42.6433\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.8231 - val_loss: 44.6106\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8200 - val_loss: 43.2363\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5005 - val_loss: 45.9631\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3789 - val_loss: 41.9453\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1398 - val_loss: 44.9252\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2407 - val_loss: 42.6742\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1888 - val_loss: 40.4653\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9439 - val_loss: 44.9000\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5394 - val_loss: 41.9561\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4775 - val_loss: 41.6614\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.7929 - val_loss: 40.2349\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7048 - val_loss: 38.5286\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7598 - val_loss: 41.2402\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7358 - val_loss: 37.3107\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4334 - val_loss: 38.0144\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.1608 - val_loss: 39.6074\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6923 - val_loss: 39.7116\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7645 - val_loss: 38.9190\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2862 - val_loss: 38.1104\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.0933 - val_loss: 36.8183\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1320 - val_loss: 39.8344\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7484 - val_loss: 38.6473\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5254 - val_loss: 38.6429\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8234 - val_loss: 44.5793\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7111 - val_loss: 34.9776\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7447 - val_loss: 34.2849\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6956 - val_loss: 35.5529\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0198 - val_loss: 34.1164\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4015 - val_loss: 35.4353\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.3759 - val_loss: 34.0700\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9412 - val_loss: 33.9130\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8024 - val_loss: 36.0839\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.2679 - val_loss: 34.2828\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9989 - val_loss: 37.4785\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3225 - val_loss: 34.2865\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7663 - val_loss: 35.2368\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6431 - val_loss: 34.3333\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9970 - val_loss: 34.1498\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5772 - val_loss: 34.9101\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6427 - val_loss: 44.6297\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7529 - val_loss: 33.5494\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5201 - val_loss: 32.1394\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0058 - val_loss: 32.6615\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1081 - val_loss: 31.7218\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5051 - val_loss: 32.9958\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3435 - val_loss: 35.6088\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4638 - val_loss: 31.4175\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5305 - val_loss: 31.5333\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5633 - val_loss: 32.6456\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3172 - val_loss: 31.0637\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3949 - val_loss: 29.9052\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3104 - val_loss: 30.3205\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6793 - val_loss: 33.7081\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5350 - val_loss: 30.5651\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.9592 - val_loss: 29.7158\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6484 - val_loss: 33.1402\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0982 - val_loss: 30.3495\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.2332 - val_loss: 30.5456\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8918 - val_loss: 29.6895\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4952 - val_loss: 29.3248\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0702 - val_loss: 29.2761\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0262 - val_loss: 30.7141\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4597 - val_loss: 28.7553\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2656 - val_loss: 29.3074\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0113 - val_loss: 28.8722\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2168 - val_loss: 28.8031\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7360 - val_loss: 28.5631\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1943 - val_loss: 27.6604\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1050 - val_loss: 27.7813\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2304 - val_loss: 31.4025\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1395 - val_loss: 31.1333\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6805 - val_loss: 28.1420\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5387 - val_loss: 28.2823\n",
      "3/3 [==============================] - 0s 924us/step - loss: 31.9216\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 362.9356 - val_loss: 214.9932\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 130.7054 - val_loss: 134.0587\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.0815 - val_loss: 105.6360\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.3306 - val_loss: 95.6808\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.4647 - val_loss: 93.9290\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.9768 - val_loss: 90.0263\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7550 - val_loss: 88.3829\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3930 - val_loss: 87.2219\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3942 - val_loss: 85.6331\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.0943 - val_loss: 85.7949\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7516 - val_loss: 83.5744\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7277 - val_loss: 83.5017\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8174 - val_loss: 85.6438\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8374 - val_loss: 85.7693\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0029 - val_loss: 85.2084\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4458 - val_loss: 85.1919\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.2485 - val_loss: 84.4489\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1720 - val_loss: 80.1392\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5247 - val_loss: 77.7352\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0646 - val_loss: 76.9719\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9679 - val_loss: 75.4935\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0287 - val_loss: 75.4307\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1504 - val_loss: 76.7977\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7611 - val_loss: 79.3060\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2165 - val_loss: 82.0844\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0774 - val_loss: 75.7748\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8491 - val_loss: 73.3976\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2030 - val_loss: 77.6708\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8563 - val_loss: 73.5274\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8829 - val_loss: 71.2865\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3774 - val_loss: 70.9635\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3374 - val_loss: 72.6173\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.0663 - val_loss: 71.8841\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8966 - val_loss: 70.3069\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2602 - val_loss: 69.1893\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3743 - val_loss: 70.0128\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3583 - val_loss: 69.0482\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0577 - val_loss: 68.1156\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1297 - val_loss: 67.6815\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0869 - val_loss: 68.6205\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9762 - val_loss: 70.4934\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.2105 - val_loss: 71.2959\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5902 - val_loss: 70.4146\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0331 - val_loss: 66.6377\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6557 - val_loss: 67.5570\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1536 - val_loss: 66.8436\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7207 - val_loss: 64.8837\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7441 - val_loss: 69.6043\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8731 - val_loss: 63.5903\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9986 - val_loss: 64.6817\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 48.2271 - val_loss: 64.6096\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0292 - val_loss: 64.9483\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7426 - val_loss: 62.0806\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8896 - val_loss: 61.5438\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5762 - val_loss: 61.5614\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1609 - val_loss: 61.1761\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7508 - val_loss: 61.2886\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8015 - val_loss: 60.2478\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1494 - val_loss: 72.0822\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6119 - val_loss: 60.2668\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6977 - val_loss: 60.9535\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8611 - val_loss: 58.6905\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3703 - val_loss: 57.9777\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 43.8327 - val_loss: 56.4840\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.2176 - val_loss: 55.8219\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7035 - val_loss: 61.6207\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8849 - val_loss: 55.0315\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5586 - val_loss: 54.7243\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4731 - val_loss: 53.2593\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9061 - val_loss: 58.5669\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7725 - val_loss: 56.1687\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3349 - val_loss: 51.1650\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8354 - val_loss: 52.1191\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8364 - val_loss: 50.8386\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8642 - val_loss: 49.3114\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8931 - val_loss: 49.8521\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8944 - val_loss: 56.0816\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9259 - val_loss: 48.9008\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7115 - val_loss: 46.8252\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9933 - val_loss: 47.7131\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9095 - val_loss: 55.6597\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3052 - val_loss: 46.5497\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8144 - val_loss: 48.6481\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.8226 - val_loss: 54.4431\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0533 - val_loss: 44.9437\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8554 - val_loss: 46.0515\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1384 - val_loss: 43.5849\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2678 - val_loss: 43.0911\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3471 - val_loss: 48.7107\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7413 - val_loss: 42.2047\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7113 - val_loss: 40.4390\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2735 - val_loss: 42.4898\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.6811 - val_loss: 41.2924\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8302 - val_loss: 42.5176\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8525 - val_loss: 39.7371\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5796 - val_loss: 40.6139\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7986 - val_loss: 47.2693\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.0028 - val_loss: 40.7738\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3675 - val_loss: 39.8116\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.3693 - val_loss: 43.6167\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6384 - val_loss: 40.5607\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2104 - val_loss: 37.3881\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7571 - val_loss: 39.4093\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6373 - val_loss: 36.2910\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4081 - val_loss: 38.8508\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9960 - val_loss: 49.7953\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3618 - val_loss: 41.0666\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8200 - val_loss: 40.9494\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9549 - val_loss: 33.1583\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6050 - val_loss: 34.9769\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9451 - val_loss: 36.4607\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9747 - val_loss: 33.9785\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2521 - val_loss: 32.2563\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9900 - val_loss: 33.9388\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5707 - val_loss: 31.3789\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6805 - val_loss: 32.2713\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.0961 - val_loss: 31.1892\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0371 - val_loss: 31.1694\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4850 - val_loss: 36.4712\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2144 - val_loss: 37.9337\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7680 - val_loss: 34.3102\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5378 - val_loss: 35.8003\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5460 - val_loss: 31.4731\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2634 - val_loss: 30.1225\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7491 - val_loss: 30.3793\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6674 - val_loss: 31.7900\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.3348 - val_loss: 31.8722\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9964 - val_loss: 28.7831\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4155 - val_loss: 30.2991\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8531 - val_loss: 30.0983\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4686 - val_loss: 29.4730\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0353 - val_loss: 38.7263\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.5556 - val_loss: 51.1551\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7460 - val_loss: 31.4318\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0131 - val_loss: 33.1907\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.2850 - val_loss: 28.4416\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2941 - val_loss: 26.6169\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8931 - val_loss: 30.0150\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6499 - val_loss: 33.5985\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.9470 - val_loss: 26.2153\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8365 - val_loss: 27.9007\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7152 - val_loss: 26.0383\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5537 - val_loss: 24.5697\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5556 - val_loss: 25.8571\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3649 - val_loss: 29.8928\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0261 - val_loss: 29.8175\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1615 - val_loss: 28.8237\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7816 - val_loss: 26.6034\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1856 - val_loss: 25.8646\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9513 - val_loss: 29.4832\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2842 - val_loss: 24.3217\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5187 - val_loss: 36.6226\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5945 - val_loss: 24.2525\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1314 - val_loss: 28.6927\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1518 - val_loss: 24.6454\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2889 - val_loss: 27.1883\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2514 - val_loss: 32.6698\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3673 - val_loss: 33.1824\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8341 - val_loss: 24.2022\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7315 - val_loss: 23.0761\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4337 - val_loss: 24.2335\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2405 - val_loss: 26.3878\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9583 - val_loss: 25.8092\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4333 - val_loss: 23.2206\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8783 - val_loss: 23.9723\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9785 - val_loss: 23.9930\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9072 - val_loss: 25.1799\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2064 - val_loss: 28.1877\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2940 - val_loss: 24.6793\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.9134 - val_loss: 24.8688\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9388 - val_loss: 25.1802\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.7001 - val_loss: 24.6095\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1757 - val_loss: 23.2180\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5994 - val_loss: 22.2196\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3509 - val_loss: 23.2133\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9374 - val_loss: 22.1686\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0509 - val_loss: 20.6317\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8440 - val_loss: 24.7699\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.9886 - val_loss: 28.9570\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2555 - val_loss: 23.7644\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7507 - val_loss: 21.3669\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6435 - val_loss: 23.5499\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4953 - val_loss: 21.1201\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1960 - val_loss: 22.4598\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.3635 - val_loss: 21.3307\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2057 - val_loss: 23.5772\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6928 - val_loss: 21.4674\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.8228 - val_loss: 21.9463\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0820 - val_loss: 33.8116\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1485 - val_loss: 21.2018\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9793 - val_loss: 20.1238\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1602 - val_loss: 21.1994\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4331 - val_loss: 21.4580\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1945 - val_loss: 20.2121\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9050 - val_loss: 20.1651\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2949 - val_loss: 25.3036\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3486 - val_loss: 27.6259\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4543 - val_loss: 30.8253\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4134 - val_loss: 28.2417\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3718 - val_loss: 20.4752\n",
      "3/3 [==============================] - 0s 908us/step - loss: 25.2333\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 143.8593 - val_loss: 139.0594\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 97.7044 - val_loss: 99.7649\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 84.6641 - val_loss: 88.6782\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.5847 - val_loss: 84.3605\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.8404 - val_loss: 87.3204\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.5639 - val_loss: 84.4253\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.7070 - val_loss: 82.7304\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.6644 - val_loss: 82.7877\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.0225 - val_loss: 80.2437\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6856 - val_loss: 77.3541\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3169 - val_loss: 78.5942\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.5345 - val_loss: 76.5818\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3043 - val_loss: 78.2856\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7760 - val_loss: 79.0998\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9948 - val_loss: 69.2247\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0364 - val_loss: 71.4790\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9601 - val_loss: 70.5781\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2766 - val_loss: 70.9011\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5017 - val_loss: 67.4668\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2357 - val_loss: 67.6928\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.4141 - val_loss: 68.7798\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4212 - val_loss: 65.0085\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8678 - val_loss: 65.4033\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9966 - val_loss: 65.8289\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2646 - val_loss: 65.8896\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3833 - val_loss: 74.6791\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0608 - val_loss: 69.6062\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4639 - val_loss: 68.0804\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0800 - val_loss: 64.0753\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.9858 - val_loss: 63.0356\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8012 - val_loss: 61.9739\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4603 - val_loss: 66.6875\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9761 - val_loss: 65.8296\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4845 - val_loss: 65.1887\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1927 - val_loss: 63.8464\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1523 - val_loss: 60.9845\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9614 - val_loss: 60.1457\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3261 - val_loss: 60.9867\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7516 - val_loss: 62.0829\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4411 - val_loss: 60.7741\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0836 - val_loss: 74.9816\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1983 - val_loss: 63.2878\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4643 - val_loss: 55.7094\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4452 - val_loss: 56.6637\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7968 - val_loss: 59.7886\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6526 - val_loss: 60.8366\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0851 - val_loss: 55.1813\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1437 - val_loss: 56.3490\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2419 - val_loss: 55.9736\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3409 - val_loss: 57.6834\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8516 - val_loss: 55.0292\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1126 - val_loss: 55.1510\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3976 - val_loss: 55.4523\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9361 - val_loss: 55.1168\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8367 - val_loss: 53.2732\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3493 - val_loss: 52.4657\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9207 - val_loss: 52.1788\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 40.8124 - val_loss: 51.1825\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.7746 - val_loss: 50.0524\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5363 - val_loss: 49.3731\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3040 - val_loss: 51.5825\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7365 - val_loss: 50.6550\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2398 - val_loss: 51.6023\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7621 - val_loss: 62.1151\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5864 - val_loss: 50.6202\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1351 - val_loss: 50.0416\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5380 - val_loss: 52.7312\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7947 - val_loss: 47.2817\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5852 - val_loss: 47.9592\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2308 - val_loss: 49.1332\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4023 - val_loss: 47.1756\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.9565 - val_loss: 54.0822\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1925 - val_loss: 63.5232\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4048 - val_loss: 52.0897\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4383 - val_loss: 62.1830\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8932 - val_loss: 47.3403\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9301 - val_loss: 43.2819\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3580 - val_loss: 44.6841\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2734 - val_loss: 45.3131\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3388 - val_loss: 46.0670\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2603 - val_loss: 43.7075\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4762 - val_loss: 41.3006\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5310 - val_loss: 44.4765\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7201 - val_loss: 42.9404\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8986 - val_loss: 42.4100\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8165 - val_loss: 40.9863\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9208 - val_loss: 41.1026\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2926 - val_loss: 44.5787\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8822 - val_loss: 40.8368\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0943 - val_loss: 39.5240\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5301 - val_loss: 43.1795\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0537 - val_loss: 40.4174\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7311 - val_loss: 45.2798\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4463 - val_loss: 51.0487\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.1109 - val_loss: 40.0030\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3789 - val_loss: 39.3642\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7658 - val_loss: 41.0401\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7821 - val_loss: 38.8777\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7947 - val_loss: 39.2015\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1073 - val_loss: 43.3030\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4014 - val_loss: 36.7285\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1857 - val_loss: 40.1216\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3999 - val_loss: 42.7929\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6620 - val_loss: 38.4855\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.8527 - val_loss: 36.0708\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2169 - val_loss: 37.6516\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5964 - val_loss: 35.7009\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3751 - val_loss: 35.2826\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3488 - val_loss: 36.8872\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9110 - val_loss: 36.5303\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0294 - val_loss: 35.4283\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8237 - val_loss: 34.0895\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6224 - val_loss: 35.7835\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7239 - val_loss: 38.0923\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4341 - val_loss: 34.8826\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.9669 - val_loss: 36.1331\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9420 - val_loss: 34.8966\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1625 - val_loss: 34.5388\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3966 - val_loss: 36.9910\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0354 - val_loss: 36.5883\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3867 - val_loss: 33.0920\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9744 - val_loss: 36.3490\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3545 - val_loss: 34.3099\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9730 - val_loss: 32.1014\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9415 - val_loss: 30.7938\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1138 - val_loss: 35.0800\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5389 - val_loss: 33.4788\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8904 - val_loss: 31.6480\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0276 - val_loss: 32.0400\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7490 - val_loss: 41.1232\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1086 - val_loss: 38.1781\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7347 - val_loss: 35.2651\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4768 - val_loss: 32.6035\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2383 - val_loss: 32.2279\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1523 - val_loss: 36.8716\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0184 - val_loss: 35.5644\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6401 - val_loss: 29.6903\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2065 - val_loss: 32.7416\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1483 - val_loss: 31.8031\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0858 - val_loss: 30.1034\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4786 - val_loss: 32.2865\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0075 - val_loss: 30.3030\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0366 - val_loss: 30.7065\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9535 - val_loss: 32.6623\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2294 - val_loss: 30.3338\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4348 - val_loss: 31.1380\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4012 - val_loss: 29.9478\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0327 - val_loss: 33.5408\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5617 - val_loss: 30.9261\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3573 - val_loss: 30.4411\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5251 - val_loss: 31.5840\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7329 - val_loss: 29.4874\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9095 - val_loss: 30.3989\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4298 - val_loss: 30.6635\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0014 - val_loss: 28.1197\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8210 - val_loss: 28.1255\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7990 - val_loss: 36.2044\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8728 - val_loss: 29.2779\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6598 - val_loss: 28.0465\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5836 - val_loss: 28.1048\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9268 - val_loss: 27.4159\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4056 - val_loss: 33.1394\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5980 - val_loss: 28.1981\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9633 - val_loss: 28.7534\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6067 - val_loss: 28.2550\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6971 - val_loss: 28.4736\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.4617 - val_loss: 28.7107\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7896 - val_loss: 30.0876\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1270 - val_loss: 26.6762\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0201 - val_loss: 26.3213\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2436 - val_loss: 25.5305\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8808 - val_loss: 26.4616\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0517 - val_loss: 28.7878\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6461 - val_loss: 28.3256\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3865 - val_loss: 28.1548\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6200 - val_loss: 27.9186\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0453 - val_loss: 30.1337\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5216 - val_loss: 26.6370\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4229 - val_loss: 30.9885\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2896 - val_loss: 28.5131\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8617 - val_loss: 26.9407\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3545 - val_loss: 28.0323\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2483 - val_loss: 27.5973\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2878 - val_loss: 28.1070\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2748 - val_loss: 27.1016\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5222 - val_loss: 32.1217\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4403 - val_loss: 32.7421\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5547 - val_loss: 25.8343\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4982 - val_loss: 28.0909\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1686 - val_loss: 33.1808\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7334 - val_loss: 28.9447\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4033 - val_loss: 26.6519\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.8496 - val_loss: 26.1974\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7665 - val_loss: 26.9157\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7021 - val_loss: 27.1046\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1322 - val_loss: 26.3796\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4886 - val_loss: 28.9995\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7996 - val_loss: 27.7120\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3599 - val_loss: 31.7700\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6087 - val_loss: 29.4314\n",
      "3/3 [==============================] - 0s 961us/step - loss: 16.0220\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 8458.7236 - val_loss: 5832.0283\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4402.0044 - val_loss: 2742.2188\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1913.4189 - val_loss: 968.6458\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 602.5729 - val_loss: 220.8144\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 156.2800 - val_loss: 101.8380\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 109.1116 - val_loss: 97.9290\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.0059 - val_loss: 82.3791\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.1454 - val_loss: 80.6124\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5235 - val_loss: 81.6757\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.7820 - val_loss: 80.7666\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9776 - val_loss: 78.8760\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5383 - val_loss: 77.8735\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5127 - val_loss: 78.4554\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7721 - val_loss: 77.7852\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6197 - val_loss: 76.5074\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5537 - val_loss: 75.9820\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2662 - val_loss: 76.5414\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.3255 - val_loss: 76.3960\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6207 - val_loss: 77.2804\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8893 - val_loss: 76.0222\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2567 - val_loss: 77.3623\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7233 - val_loss: 78.0434\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6659 - val_loss: 76.8866\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0641 - val_loss: 76.9004\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1092 - val_loss: 76.8043\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7073 - val_loss: 78.9953\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3862 - val_loss: 76.8827\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1369 - val_loss: 77.3174\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6177 - val_loss: 79.1716\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0508 - val_loss: 76.6545\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.9488 - val_loss: 77.9124\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7345 - val_loss: 77.5960\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6224 - val_loss: 78.6950\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6455 - val_loss: 79.1509\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3592 - val_loss: 78.3592\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2199 - val_loss: 78.3844\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1282 - val_loss: 79.4728\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1800 - val_loss: 79.2189\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9374 - val_loss: 79.6412\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8763 - val_loss: 79.8330\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7149 - val_loss: 78.7778\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3821 - val_loss: 79.7850\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5119 - val_loss: 78.4024\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6296 - val_loss: 77.5441\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0812 - val_loss: 80.5372\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4258 - val_loss: 81.0239\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1875 - val_loss: 78.2265\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0055 - val_loss: 79.6644\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9809 - val_loss: 78.9980\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8335 - val_loss: 81.4228\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0950 - val_loss: 80.0351\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0323 - val_loss: 78.4531\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2553 - val_loss: 81.0922\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7204 - val_loss: 80.7340\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9249 - val_loss: 81.9672\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.8651 - val_loss: 80.2127\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5707 - val_loss: 78.9900\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7056 - val_loss: 79.5403\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.9210 - val_loss: 81.6794\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4188 - val_loss: 79.4912\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6822 - val_loss: 78.7388\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4785 - val_loss: 79.7466\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3993 - val_loss: 78.6733\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6826 - val_loss: 77.3758\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4369 - val_loss: 80.6893\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0385 - val_loss: 79.2483\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9633 - val_loss: 78.0590\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8796 - val_loss: 79.8357\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2940 - val_loss: 81.1259\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5396 - val_loss: 77.6664\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0688 - val_loss: 77.1217\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7128 - val_loss: 79.9091\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8866 - val_loss: 80.7651\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5732 - val_loss: 78.8808\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6832 - val_loss: 76.6436\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6090 - val_loss: 81.3605\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9732 - val_loss: 78.3277\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4195 - val_loss: 77.9511\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7638 - val_loss: 78.1737\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3122 - val_loss: 81.0046\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6501 - val_loss: 78.3833\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2108 - val_loss: 79.4358\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2923 - val_loss: 79.4107\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2917 - val_loss: 78.8058\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1955 - val_loss: 79.4945\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2914 - val_loss: 79.6754\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1809 - val_loss: 78.6033\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9819 - val_loss: 79.9594\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3335 - val_loss: 83.0094\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4255 - val_loss: 77.7853\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8745 - val_loss: 80.7032\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1199 - val_loss: 77.7577\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1062 - val_loss: 78.1598\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0016 - val_loss: 77.3825\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.9112 - val_loss: 77.9535\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1630 - val_loss: 80.3821\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7316 - val_loss: 78.3608\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3070 - val_loss: 77.1307\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5960 - val_loss: 80.3694\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0626 - val_loss: 78.1758\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6353 - val_loss: 85.4417\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8241 - val_loss: 81.4779\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2984 - val_loss: 79.3768\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2593 - val_loss: 78.1419\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1497 - val_loss: 79.6044\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9874 - val_loss: 79.3689\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6620 - val_loss: 79.5236\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9018 - val_loss: 78.7611\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4676 - val_loss: 77.1034\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8999 - val_loss: 76.2714\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7367 - val_loss: 76.2912\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8248 - val_loss: 79.9955\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3495 - val_loss: 78.3698\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8399 - val_loss: 76.4020\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1386 - val_loss: 76.0432\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5747 - val_loss: 79.7967\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8454 - val_loss: 80.6386\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1081 - val_loss: 77.5450\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8243 - val_loss: 79.4792\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4008 - val_loss: 77.8432\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0288 - val_loss: 75.7906\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7523 - val_loss: 78.0144\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4797 - val_loss: 77.8131\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7299 - val_loss: 76.4644\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1927 - val_loss: 76.5377\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4209 - val_loss: 76.5480\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3757 - val_loss: 74.0805\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.2167 - val_loss: 76.6439\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2957 - val_loss: 75.7068\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8454 - val_loss: 73.1450\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7741 - val_loss: 74.4819\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8943 - val_loss: 77.7705\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9259 - val_loss: 75.0284\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8140 - val_loss: 73.0646\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9451 - val_loss: 74.4260\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8267 - val_loss: 78.4859\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9203 - val_loss: 74.6194\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2731 - val_loss: 73.8838\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5982 - val_loss: 73.9342\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5687 - val_loss: 73.8674\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.0470 - val_loss: 75.9946\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3341 - val_loss: 75.6452\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5513 - val_loss: 72.5871\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8903 - val_loss: 75.2330\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4957 - val_loss: 77.8603\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8878 - val_loss: 73.9758\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1266 - val_loss: 74.0349\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6483 - val_loss: 72.1622\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4695 - val_loss: 72.7780\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9824 - val_loss: 74.9324\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4889 - val_loss: 74.3430\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5740 - val_loss: 72.3966\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1699 - val_loss: 74.4771\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4758 - val_loss: 71.3095\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5166 - val_loss: 72.4403\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0712 - val_loss: 73.2779\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8853 - val_loss: 70.6255\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4668 - val_loss: 71.5371\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7881 - val_loss: 72.3763\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6333 - val_loss: 73.6180\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9493 - val_loss: 73.2899\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3475 - val_loss: 73.8914\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3870 - val_loss: 69.8413\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3300 - val_loss: 71.2587\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.2926 - val_loss: 72.9425\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3806 - val_loss: 72.0351\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.2775 - val_loss: 72.4536\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8921 - val_loss: 70.2325\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4160 - val_loss: 71.2022\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5953 - val_loss: 73.4035\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2985 - val_loss: 69.3439\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8800 - val_loss: 71.8819\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7446 - val_loss: 72.2157\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3410 - val_loss: 70.1057\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0228 - val_loss: 68.3084\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4602 - val_loss: 69.7089\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2705 - val_loss: 70.8749\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4464 - val_loss: 68.7754\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8917 - val_loss: 71.3882\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0933 - val_loss: 68.7623\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2606 - val_loss: 72.4862\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0922 - val_loss: 68.7961\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8514 - val_loss: 67.4642\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5534 - val_loss: 69.7747\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5994 - val_loss: 69.6139\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3396 - val_loss: 71.4130\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5972 - val_loss: 71.0391\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1098 - val_loss: 68.2748\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7954 - val_loss: 70.3708\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7049 - val_loss: 66.5977\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2167 - val_loss: 70.3182\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1948 - val_loss: 69.4555\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3151 - val_loss: 66.3292\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7689 - val_loss: 65.2544\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2333 - val_loss: 69.2247\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1409 - val_loss: 67.5487\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1275 - val_loss: 64.7860\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2142 - val_loss: 67.2016\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2473 - val_loss: 64.8790\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3588 - val_loss: 66.4844\n",
      "3/3 [==============================] - 0s 933us/step - loss: 65.1987\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 8775.8115 - val_loss: 7124.5020\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 5980.2217 - val_loss: 4970.5259\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4216.1724 - val_loss: 3617.0012\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3106.2444 - val_loss: 2762.2485\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2387.7124 - val_loss: 2176.7915\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1879.1451 - val_loss: 1743.5619\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1500.3052 - val_loss: 1403.0537\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1195.5557 - val_loss: 1129.3657\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 944.0053 - val_loss: 885.7220\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 720.2892 - val_loss: 683.0255\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 540.4053 - val_loss: 517.5342\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 400.2234 - val_loss: 410.8188\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 316.9832 - val_loss: 358.3839\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 278.8211 - val_loss: 327.6992\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 252.5222 - val_loss: 297.7561\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 226.8546 - val_loss: 270.4613\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 203.6608 - val_loss: 245.7669\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 183.3234 - val_loss: 223.0083\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 163.1720 - val_loss: 202.6314\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 147.6271 - val_loss: 185.1349\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 133.8666 - val_loss: 168.9377\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 119.6763 - val_loss: 154.6427\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 108.3938 - val_loss: 143.2691\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.7253 - val_loss: 134.2854\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94.8370 - val_loss: 126.3762\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 90.9757 - val_loss: 120.1134\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.1733 - val_loss: 117.1379\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.5544 - val_loss: 115.3193\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.8153 - val_loss: 113.4322\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.9208 - val_loss: 112.7887\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 84.0202 - val_loss: 112.2585\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.3895 - val_loss: 112.7783\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 82.4750 - val_loss: 111.4287\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 81.7211 - val_loss: 110.8819\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.0062 - val_loss: 110.5976\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.4280 - val_loss: 111.0866\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.8755 - val_loss: 109.6250\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.3100 - val_loss: 108.4337\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.5159 - val_loss: 108.2128\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.8193 - val_loss: 107.8050\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.5023 - val_loss: 106.6495\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.9986 - val_loss: 105.8114\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.2927 - val_loss: 106.6457\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.7560 - val_loss: 106.2567\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.6026 - val_loss: 105.6930\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.0936 - val_loss: 106.0294\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.2675 - val_loss: 105.3163\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.0006 - val_loss: 105.1463\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.5181 - val_loss: 104.8435\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.6429 - val_loss: 102.8435\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.1261 - val_loss: 103.3041\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.0750 - val_loss: 101.9984\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.3959 - val_loss: 101.1578\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.4157 - val_loss: 100.2496\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.7902 - val_loss: 100.4352\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6820 - val_loss: 102.3224\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.3575 - val_loss: 101.1882\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.3463 - val_loss: 100.3124\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.9551 - val_loss: 98.9369\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.6841 - val_loss: 97.9452\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.3776 - val_loss: 96.8078\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.0982 - val_loss: 96.5519\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.2595 - val_loss: 95.9729\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.7763 - val_loss: 92.6794\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.6334 - val_loss: 90.8829\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.4926 - val_loss: 92.8212\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.0231 - val_loss: 95.1050\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.5070 - val_loss: 92.0374\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1768 - val_loss: 92.3130\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.1911 - val_loss: 91.1483\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.5759 - val_loss: 89.8272\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.3066 - val_loss: 90.1374\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.2269 - val_loss: 89.7754\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8744 - val_loss: 88.1690\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.3679 - val_loss: 88.8927\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.3769 - val_loss: 89.0859\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.8438 - val_loss: 86.5886\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.0964 - val_loss: 85.7982\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0879 - val_loss: 83.1674\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.1339 - val_loss: 81.7522\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8144 - val_loss: 81.7334\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2454 - val_loss: 81.8307\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2031 - val_loss: 81.3821\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6122 - val_loss: 81.2660\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3117 - val_loss: 79.7094\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9764 - val_loss: 79.1386\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1784 - val_loss: 77.2620\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.4537 - val_loss: 77.6335\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1401 - val_loss: 75.4644\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.8841 - val_loss: 74.7372\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5351 - val_loss: 73.8841\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7064 - val_loss: 75.4860\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.7149 - val_loss: 73.6269\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4707 - val_loss: 71.5629\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4487 - val_loss: 73.1679\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3914 - val_loss: 72.8012\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1014 - val_loss: 71.1806\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9987 - val_loss: 70.9072\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6509 - val_loss: 70.8990\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5320 - val_loss: 68.9254\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1599 - val_loss: 69.2955\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2426 - val_loss: 67.9956\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1374 - val_loss: 68.6931\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1141 - val_loss: 67.8160\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1179 - val_loss: 68.8395\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1165 - val_loss: 70.0648\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5920 - val_loss: 68.3972\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9305 - val_loss: 67.6652\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.8570 - val_loss: 68.5584\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6734 - val_loss: 67.9325\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5360 - val_loss: 67.8324\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3508 - val_loss: 67.4769\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2350 - val_loss: 66.2277\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0966 - val_loss: 66.3677\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3456 - val_loss: 67.4332\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7504 - val_loss: 66.8102\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6983 - val_loss: 65.9103\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.8292 - val_loss: 63.7244\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7374 - val_loss: 67.1503\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2419 - val_loss: 67.3865\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1894 - val_loss: 66.6006\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4497 - val_loss: 67.4560\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0451 - val_loss: 68.7426\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6505 - val_loss: 72.6091\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.9285 - val_loss: 67.8936\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6779 - val_loss: 64.9560\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3733 - val_loss: 66.4232\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2654 - val_loss: 67.0244\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1131 - val_loss: 66.7889\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6420 - val_loss: 66.7321\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2006 - val_loss: 65.6341\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6811 - val_loss: 63.7043\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3310 - val_loss: 63.4146\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0034 - val_loss: 66.0067\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6825 - val_loss: 68.2648\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0693 - val_loss: 65.8473\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6110 - val_loss: 65.7118\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4258 - val_loss: 65.2464\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3663 - val_loss: 71.2431\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5984 - val_loss: 68.5998\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3938 - val_loss: 64.7381\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.9800 - val_loss: 66.0996\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4994 - val_loss: 68.4076\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4961 - val_loss: 66.1313\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0104 - val_loss: 65.0648\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0084 - val_loss: 64.8290\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1468 - val_loss: 64.0040\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7061 - val_loss: 65.4343\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5104 - val_loss: 66.5855\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9173 - val_loss: 65.3965\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6996 - val_loss: 63.2866\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7008 - val_loss: 65.4861\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0147 - val_loss: 65.7891\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3587 - val_loss: 65.9356\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0246 - val_loss: 64.9543\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.9437 - val_loss: 65.3312\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4841 - val_loss: 63.8606\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6432 - val_loss: 62.2509\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0377 - val_loss: 66.1963\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3069 - val_loss: 63.2358\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0015 - val_loss: 61.7397\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1671 - val_loss: 62.8715\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6631 - val_loss: 65.3452\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7939 - val_loss: 64.0234\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3958 - val_loss: 62.0467\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2142 - val_loss: 61.8667\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7292 - val_loss: 64.2101\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0459 - val_loss: 62.4198\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6791 - val_loss: 61.1815\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5525 - val_loss: 62.0112\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4763 - val_loss: 63.3810\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5066 - val_loss: 61.8269\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0162 - val_loss: 61.6528\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5660 - val_loss: 65.3317\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8503 - val_loss: 62.6162\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5120 - val_loss: 58.1414\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2289 - val_loss: 62.5609\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3689 - val_loss: 65.5735\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1242 - val_loss: 61.9649\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.5486 - val_loss: 64.7231\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8944 - val_loss: 64.1581\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8816 - val_loss: 60.5809\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7132 - val_loss: 61.8686\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6794 - val_loss: 61.2052\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6371 - val_loss: 59.5652\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7453 - val_loss: 60.0931\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6731 - val_loss: 66.6822\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1240 - val_loss: 64.4880\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7684 - val_loss: 60.1894\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5614 - val_loss: 60.1470\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4157 - val_loss: 59.8825\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6027 - val_loss: 62.5771\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6723 - val_loss: 60.7529\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1783 - val_loss: 58.2995\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7702 - val_loss: 58.1087\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1084 - val_loss: 60.0000\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5975 - val_loss: 56.6744\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2325 - val_loss: 59.5788\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9600 - val_loss: 60.1243\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9243 - val_loss: 59.3472\n",
      "3/3 [==============================] - 0s 927us/step - loss: 53.0196\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1378.2360 - val_loss: 1241.6940\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 993.8091 - val_loss: 897.4787\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 720.3920 - val_loss: 664.7891\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 522.7293 - val_loss: 473.4282\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 375.1007 - val_loss: 331.8989\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 274.6363 - val_loss: 237.2889\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 201.4950 - val_loss: 174.6560\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 155.5625 - val_loss: 140.4616\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 132.4406 - val_loss: 117.4302\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 113.9307 - val_loss: 105.6050\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 103.8192 - val_loss: 97.3608\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 95.8066 - val_loss: 91.0373\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.8910 - val_loss: 86.6499\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 83.8849 - val_loss: 83.0789\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.6586 - val_loss: 80.0679\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.6746 - val_loss: 78.0268\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.7397 - val_loss: 76.5381\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.9868 - val_loss: 75.2964\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.0220 - val_loss: 74.3762\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.2157 - val_loss: 73.3963\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7529 - val_loss: 73.1090\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.0919 - val_loss: 72.0403\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.9684 - val_loss: 72.1151\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4817 - val_loss: 72.4538\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9435 - val_loss: 72.5968\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6618 - val_loss: 72.1989\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3366 - val_loss: 72.3630\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.0694 - val_loss: 72.3590\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5494 - val_loss: 71.8989\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0192 - val_loss: 71.9811\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4516 - val_loss: 71.6117\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4844 - val_loss: 71.5888\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1675 - val_loss: 72.0323\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9918 - val_loss: 71.8661\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8817 - val_loss: 71.6669\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6568 - val_loss: 71.7477\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6088 - val_loss: 72.3610\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5554 - val_loss: 72.0502\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4348 - val_loss: 71.5266\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2354 - val_loss: 71.1091\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9256 - val_loss: 71.2432\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7277 - val_loss: 71.3311\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6945 - val_loss: 71.6211\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5867 - val_loss: 70.8152\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4198 - val_loss: 70.4548\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3357 - val_loss: 70.1923\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9304 - val_loss: 70.5388\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9408 - val_loss: 70.9947\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8631 - val_loss: 70.2705\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.9711 - val_loss: 70.1473\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4975 - val_loss: 70.6768\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5044 - val_loss: 71.0288\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2899 - val_loss: 70.6470\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9927 - val_loss: 70.1794\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0943 - val_loss: 70.1192\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8832 - val_loss: 69.8854\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8777 - val_loss: 69.9382\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6073 - val_loss: 69.7782\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.8859 - val_loss: 69.9024\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.8717 - val_loss: 70.0759\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.1585 - val_loss: 70.4285\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5065 - val_loss: 70.7513\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4432 - val_loss: 71.3637\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1282 - val_loss: 70.6297\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5569 - val_loss: 69.9825\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1779 - val_loss: 70.2402\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6249 - val_loss: 70.1387\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0398 - val_loss: 70.3182\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.7074 - val_loss: 69.9963\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7742 - val_loss: 69.3931\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5735 - val_loss: 69.7102\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4316 - val_loss: 68.7577\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0030 - val_loss: 68.4146\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7922 - val_loss: 68.1249\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7058 - val_loss: 67.7759\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6355 - val_loss: 67.9449\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2701 - val_loss: 67.3021\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.2476 - val_loss: 66.6999\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5141 - val_loss: 66.6867\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6612 - val_loss: 67.2645\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4089 - val_loss: 68.0423\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.0010 - val_loss: 66.9646\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2702 - val_loss: 66.8971\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2690 - val_loss: 66.2805\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5866 - val_loss: 66.2738\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1630 - val_loss: 67.3497\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2603 - val_loss: 67.3416\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6863 - val_loss: 66.5265\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7607 - val_loss: 66.1825\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7631 - val_loss: 66.1695\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8230 - val_loss: 65.3131\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3797 - val_loss: 64.9605\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.4412 - val_loss: 66.8280\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2289 - val_loss: 66.5328\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8786 - val_loss: 65.3878\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6551 - val_loss: 64.9754\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5651 - val_loss: 64.6015\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6609 - val_loss: 65.0287\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2025 - val_loss: 65.3442\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3475 - val_loss: 65.4348\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6325 - val_loss: 64.9756\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1225 - val_loss: 64.4344\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8426 - val_loss: 64.1465\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6972 - val_loss: 64.4541\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6615 - val_loss: 63.9355\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4264 - val_loss: 64.3403\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2213 - val_loss: 63.1711\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0854 - val_loss: 63.6629\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1185 - val_loss: 63.5891\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1016 - val_loss: 64.0882\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4701 - val_loss: 63.7822\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8278 - val_loss: 63.3011\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0822 - val_loss: 63.3059\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1076 - val_loss: 62.5675\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5716 - val_loss: 63.1175\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0981 - val_loss: 63.1659\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1478 - val_loss: 62.4191\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.5065 - val_loss: 62.4916\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2052 - val_loss: 62.3408\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9052 - val_loss: 62.5125\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8918 - val_loss: 62.3118\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7141 - val_loss: 62.6672\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5245 - val_loss: 62.5014\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5465 - val_loss: 62.3430\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4903 - val_loss: 62.0581\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3539 - val_loss: 61.5711\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9444 - val_loss: 61.7614\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4654 - val_loss: 61.0478\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1249 - val_loss: 60.9177\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0675 - val_loss: 60.6445\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0405 - val_loss: 60.7534\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8623 - val_loss: 60.5073\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8458 - val_loss: 61.8157\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7547 - val_loss: 60.7458\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1827 - val_loss: 60.5413\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2005 - val_loss: 60.2201\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1439 - val_loss: 59.5810\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1575 - val_loss: 59.9660\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4913 - val_loss: 60.5508\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4398 - val_loss: 60.1876\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7638 - val_loss: 59.7103\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7542 - val_loss: 61.0255\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5857 - val_loss: 60.7216\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4473 - val_loss: 60.1000\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3942 - val_loss: 59.6615\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2328 - val_loss: 60.9045\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5180 - val_loss: 60.9842\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6539 - val_loss: 58.9934\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5751 - val_loss: 59.5428\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.0721 - val_loss: 59.8162\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9381 - val_loss: 59.9787\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8041 - val_loss: 59.9371\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6232 - val_loss: 58.9836\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7181 - val_loss: 59.1011\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3179 - val_loss: 58.7250\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6829 - val_loss: 57.9664\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4965 - val_loss: 57.6603\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6561 - val_loss: 57.3301\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0778 - val_loss: 57.8188\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2207 - val_loss: 57.9801\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9388 - val_loss: 58.3336\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0554 - val_loss: 57.7310\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7770 - val_loss: 57.8245\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6433 - val_loss: 56.2811\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.5116 - val_loss: 56.3296\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6965 - val_loss: 55.5558\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.7188 - val_loss: 55.7786\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4173 - val_loss: 57.1613\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0503 - val_loss: 57.6756\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0813 - val_loss: 56.5284\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9934 - val_loss: 57.1792\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7168 - val_loss: 56.4678\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7161 - val_loss: 56.1771\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5694 - val_loss: 56.1671\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5786 - val_loss: 55.8448\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5570 - val_loss: 55.1753\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4680 - val_loss: 55.9952\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3135 - val_loss: 57.1768\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5945 - val_loss: 57.6769\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1428 - val_loss: 55.9128\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5586 - val_loss: 55.8039\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1975 - val_loss: 54.5739\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0526 - val_loss: 54.5064\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9341 - val_loss: 60.2561\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4925 - val_loss: 62.1090\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9423 - val_loss: 60.8403\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6688 - val_loss: 59.6887\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4487 - val_loss: 57.5367\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7189 - val_loss: 56.6493\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7909 - val_loss: 56.6858\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6379 - val_loss: 56.2767\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.4220 - val_loss: 57.3783\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.8486 - val_loss: 58.0511\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8422 - val_loss: 55.2912\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6938 - val_loss: 54.3023\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6521 - val_loss: 55.0053\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0610 - val_loss: 54.6432\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8747 - val_loss: 53.9447\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4321 - val_loss: 54.7465\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2919 - val_loss: 55.1838\n",
      "3/3 [==============================] - 0s 918us/step - loss: 38.8482\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 332.8833 - val_loss: 326.6903\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 260.1750 - val_loss: 266.2607\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 204.0783 - val_loss: 218.4920\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 162.9787 - val_loss: 176.9960\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 124.6328 - val_loss: 147.0510\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 98.2038 - val_loss: 124.4756\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 81.7120 - val_loss: 111.4066\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.4695 - val_loss: 103.8158\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.2914 - val_loss: 97.0417\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.9976 - val_loss: 90.7951\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.6056 - val_loss: 87.7148\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.0829 - val_loss: 86.5341\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.4777 - val_loss: 85.2354\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6094 - val_loss: 84.8255\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1036 - val_loss: 84.2626\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8197 - val_loss: 83.8914\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8311 - val_loss: 81.7406\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4377 - val_loss: 81.1420\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.8820 - val_loss: 80.9993\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1105 - val_loss: 80.9569\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0152 - val_loss: 79.5310\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3750 - val_loss: 79.2976\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9312 - val_loss: 78.6188\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2482 - val_loss: 83.4556\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.8175 - val_loss: 79.4404\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2465 - val_loss: 78.5994\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8135 - val_loss: 77.0531\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9950 - val_loss: 77.1895\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4229 - val_loss: 77.1830\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1559 - val_loss: 77.1077\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5751 - val_loss: 77.2879\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9990 - val_loss: 77.5657\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.0341 - val_loss: 76.4843\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6241 - val_loss: 76.9545\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3041 - val_loss: 77.3702\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1365 - val_loss: 77.0200\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 57.9572 - val_loss: 74.3004\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3163 - val_loss: 73.3755\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2812 - val_loss: 73.8026\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8450 - val_loss: 73.8641\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7402 - val_loss: 74.3005\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5936 - val_loss: 74.7888\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2066 - val_loss: 75.4615\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.8804 - val_loss: 73.7089\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7270 - val_loss: 72.7608\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4651 - val_loss: 72.7691\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5576 - val_loss: 72.2840\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0830 - val_loss: 71.5303\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9510 - val_loss: 71.7330\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8233 - val_loss: 72.3960\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8353 - val_loss: 71.3906\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5607 - val_loss: 71.8287\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6842 - val_loss: 70.9325\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4130 - val_loss: 71.5669\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1808 - val_loss: 70.9259\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3065 - val_loss: 69.7776\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2158 - val_loss: 70.5969\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9457 - val_loss: 71.1936\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9992 - val_loss: 70.7324\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5709 - val_loss: 70.7868\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8971 - val_loss: 71.1470\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7495 - val_loss: 69.6736\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6081 - val_loss: 69.4036\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2926 - val_loss: 69.5506\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8780 - val_loss: 69.2545\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7408 - val_loss: 68.3255\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3722 - val_loss: 69.5428\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6026 - val_loss: 70.2425\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3997 - val_loss: 69.2658\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5588 - val_loss: 68.0813\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2397 - val_loss: 67.2926\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6934 - val_loss: 68.6307\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8150 - val_loss: 68.0343\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 52.6620 - val_loss: 66.8682\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4895 - val_loss: 66.5970\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4695 - val_loss: 69.5508\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4878 - val_loss: 66.4955\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5652 - val_loss: 65.1799\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1754 - val_loss: 65.0001\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6378 - val_loss: 66.7575\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8132 - val_loss: 64.8540\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4814 - val_loss: 64.7073\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8949 - val_loss: 64.3218\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8108 - val_loss: 65.1370\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8822 - val_loss: 66.4957\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0931 - val_loss: 67.2706\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2321 - val_loss: 62.9393\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7339 - val_loss: 62.5903\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5949 - val_loss: 62.1440\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6108 - val_loss: 62.4569\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8327 - val_loss: 61.7198\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7082 - val_loss: 62.1462\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4486 - val_loss: 62.5057\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2311 - val_loss: 62.4311\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1972 - val_loss: 60.0019\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7410 - val_loss: 59.3964\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5722 - val_loss: 60.2186\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0927 - val_loss: 58.8157\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6600 - val_loss: 58.3391\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9651 - val_loss: 58.8172\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8479 - val_loss: 57.4583\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0766 - val_loss: 56.4892\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6073 - val_loss: 58.2121\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1685 - val_loss: 59.8906\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8110 - val_loss: 58.1440\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3628 - val_loss: 56.6755\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1195 - val_loss: 57.2363\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9362 - val_loss: 56.8224\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6213 - val_loss: 57.0294\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5666 - val_loss: 55.9827\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1791 - val_loss: 57.0633\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.3159 - val_loss: 55.1750\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4220 - val_loss: 54.5302\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9940 - val_loss: 55.2303\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.8650 - val_loss: 55.5341\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.3565 - val_loss: 53.2727\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5564 - val_loss: 55.6222\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5493 - val_loss: 54.8103\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9607 - val_loss: 55.2307\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0033 - val_loss: 53.4990\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3046 - val_loss: 55.4222\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.8192 - val_loss: 54.5849\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3077 - val_loss: 53.8384\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3995 - val_loss: 52.6364\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8805 - val_loss: 51.4096\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0077 - val_loss: 55.4640\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6431 - val_loss: 52.5539\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5555 - val_loss: 50.8392\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0280 - val_loss: 50.8235\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9644 - val_loss: 51.3183\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0612 - val_loss: 52.1810\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3240 - val_loss: 50.9905\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2162 - val_loss: 50.6559\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8334 - val_loss: 50.4480\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2990 - val_loss: 50.2864\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5775 - val_loss: 51.0600\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5351 - val_loss: 50.4321\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5156 - val_loss: 49.7698\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4575 - val_loss: 48.3512\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9848 - val_loss: 49.9006\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.4249 - val_loss: 50.6087\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8758 - val_loss: 48.0987\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4193 - val_loss: 49.6650\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0305 - val_loss: 51.0676\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8496 - val_loss: 49.1142\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2538 - val_loss: 48.1859\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0094 - val_loss: 52.9539\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6863 - val_loss: 48.3548\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4991 - val_loss: 47.9132\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.0691 - val_loss: 48.8961\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4968 - val_loss: 50.6094\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2488 - val_loss: 50.0911\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2027 - val_loss: 48.4701\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8619 - val_loss: 48.1896\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8979 - val_loss: 47.5701\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6078 - val_loss: 46.4169\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6716 - val_loss: 46.7271\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6027 - val_loss: 47.4331\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3848 - val_loss: 46.0461\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2143 - val_loss: 46.9390\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4820 - val_loss: 48.9389\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9977 - val_loss: 48.1258\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0870 - val_loss: 47.2451\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1460 - val_loss: 46.9045\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2183 - val_loss: 45.6228\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9506 - val_loss: 46.2104\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5585 - val_loss: 44.7553\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9891 - val_loss: 44.6731\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.5924 - val_loss: 45.6992\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3366 - val_loss: 45.7617\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7499 - val_loss: 44.3860\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3161 - val_loss: 45.4545\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3899 - val_loss: 46.6025\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2609 - val_loss: 44.7711\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7144 - val_loss: 45.0121\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.8869 - val_loss: 43.6685\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4595 - val_loss: 44.8653\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7726 - val_loss: 43.5821\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6886 - val_loss: 44.4703\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0335 - val_loss: 44.0744\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6635 - val_loss: 42.2507\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3983 - val_loss: 43.5976\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3548 - val_loss: 44.2678\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.9613 - val_loss: 43.6247\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1296 - val_loss: 42.7079\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9731 - val_loss: 42.3903\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9463 - val_loss: 43.2294\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.8812 - val_loss: 41.7200\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9083 - val_loss: 42.0326\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3894 - val_loss: 42.0265\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5283 - val_loss: 42.0070\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7634 - val_loss: 42.4438\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5394 - val_loss: 41.5815\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7629 - val_loss: 42.1150\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2196 - val_loss: 42.0629\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.6412 - val_loss: 41.9349\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8548 - val_loss: 41.4590\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2010 - val_loss: 40.7532\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3122 - val_loss: 42.0630\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2348 - val_loss: 41.4672\n",
      "3/3 [==============================] - 0s 941us/step - loss: 34.1161\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 6321.1045 - val_loss: 5018.4019\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4236.2676 - val_loss: 3512.5999\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3087.9370 - val_loss: 2767.1655\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2512.2917 - val_loss: 2360.5120\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2137.7488 - val_loss: 2034.8632\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1835.9260 - val_loss: 1773.3396\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1599.0988 - val_loss: 1574.9226\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1419.6384 - val_loss: 1421.0603\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1284.8378 - val_loss: 1304.6150\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1179.9525 - val_loss: 1213.6724\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1094.9119 - val_loss: 1131.5583\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1013.6419 - val_loss: 1046.4768\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 924.4668 - val_loss: 965.2446\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 846.9696 - val_loss: 892.8439\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 771.2042 - val_loss: 815.3854\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 695.7914 - val_loss: 740.7927\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 609.2900 - val_loss: 654.4730\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 510.2062 - val_loss: 577.6130\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 432.4911 - val_loss: 502.8391\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 344.2590 - val_loss: 403.6056\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 264.3250 - val_loss: 327.7166\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 217.0066 - val_loss: 283.9881\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 195.9387 - val_loss: 259.0797\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 184.6382 - val_loss: 243.6294\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 175.5457 - val_loss: 230.2126\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 168.8848 - val_loss: 220.1388\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 162.0130 - val_loss: 211.7727\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 157.1282 - val_loss: 205.5509\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 153.1238 - val_loss: 199.7936\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 148.2736 - val_loss: 194.0348\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 144.6723 - val_loss: 188.8265\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 140.2648 - val_loss: 183.4462\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 136.4817 - val_loss: 178.5346\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 133.3807 - val_loss: 173.3663\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 129.4702 - val_loss: 168.7137\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126.0761 - val_loss: 164.1435\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122.7931 - val_loss: 159.9271\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 121.3118 - val_loss: 155.6992\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 117.8102 - val_loss: 152.2730\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114.3478 - val_loss: 147.0466\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 110.9571 - val_loss: 144.2379\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107.2162 - val_loss: 138.2701\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106.6995 - val_loss: 134.7302\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 101.1571 - val_loss: 130.4610\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99.1796 - val_loss: 126.7488\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.7176 - val_loss: 123.2681\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95.3647 - val_loss: 120.1660\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.0123 - val_loss: 117.5445\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.1698 - val_loss: 115.6559\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.0756 - val_loss: 113.2298\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.3578 - val_loss: 112.8494\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 89.7031 - val_loss: 109.3436\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.1102 - val_loss: 107.6057\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 84.7950 - val_loss: 105.6506\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.1084 - val_loss: 104.0112\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.5334 - val_loss: 102.8499\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.1852 - val_loss: 101.1526\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.6481 - val_loss: 99.6845\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 81.2441 - val_loss: 98.7628\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.1466 - val_loss: 97.2830\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.1991 - val_loss: 97.3579\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.1084 - val_loss: 95.0449\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.8060 - val_loss: 93.9474\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.3930 - val_loss: 93.2003\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.8103 - val_loss: 92.2930\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.4147 - val_loss: 91.3872\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.3976 - val_loss: 90.8171\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.5622 - val_loss: 89.7433\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.0582 - val_loss: 89.3535\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.5198 - val_loss: 88.8414\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.1472 - val_loss: 88.0966\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.6805 - val_loss: 87.6973\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.3968 - val_loss: 87.2761\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.0416 - val_loss: 86.7537\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.0308 - val_loss: 86.7516\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.9402 - val_loss: 85.9986\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.9888 - val_loss: 85.4544\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.3870 - val_loss: 84.9213\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.3836 - val_loss: 83.7565\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.9890 - val_loss: 83.2588\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.4061 - val_loss: 88.3588\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.4733 - val_loss: 83.3364\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7508 - val_loss: 83.6648\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.7467 - val_loss: 83.3421\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.5785 - val_loss: 81.7512\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.9488 - val_loss: 81.8593\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.4494 - val_loss: 81.9944\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5195 - val_loss: 81.0685\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1833 - val_loss: 80.7492\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.0174 - val_loss: 80.5707\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.0543 - val_loss: 80.9578\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6255 - val_loss: 81.6732\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.4718 - val_loss: 81.4727\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.3703 - val_loss: 80.5717\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.2791 - val_loss: 79.2146\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.9345 - val_loss: 79.1081\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.4535 - val_loss: 79.2747\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.7800 - val_loss: 80.1119\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.7516 - val_loss: 82.5247\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.6819 - val_loss: 78.2834\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8309 - val_loss: 77.3154\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5974 - val_loss: 77.0087\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9904 - val_loss: 76.7323\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 65.9757 - val_loss: 76.1192\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9643 - val_loss: 75.6875\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0900 - val_loss: 76.5743\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.8145 - val_loss: 76.3085\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1457 - val_loss: 76.0051\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8003 - val_loss: 76.9114\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.6740 - val_loss: 75.7704\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.3366 - val_loss: 75.5758\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1285 - val_loss: 75.5758\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5211 - val_loss: 75.8721\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4015 - val_loss: 75.4719\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.5265 - val_loss: 74.6812\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.4292 - val_loss: 74.1887\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2607 - val_loss: 74.3068\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0715 - val_loss: 73.7977\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.1011 - val_loss: 73.4991\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9971 - val_loss: 74.4641\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0646 - val_loss: 78.1577\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.4019 - val_loss: 74.6288\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7543 - val_loss: 74.9994\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5930 - val_loss: 74.7528\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6066 - val_loss: 74.6939\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.2880 - val_loss: 77.1500\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.3030 - val_loss: 75.6551\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1597 - val_loss: 75.1463\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4087 - val_loss: 75.2769\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2667 - val_loss: 75.1626\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1022 - val_loss: 74.5102\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1368 - val_loss: 74.1856\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 63.2810 - val_loss: 73.9996\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1178 - val_loss: 74.0759\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4958 - val_loss: 73.5545\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9719 - val_loss: 73.5337\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5633 - val_loss: 73.3953\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7879 - val_loss: 73.0004\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.1657 - val_loss: 72.5893\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3813 - val_loss: 71.9683\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3773 - val_loss: 71.9199\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.5477 - val_loss: 72.1072\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1038 - val_loss: 72.1909\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9020 - val_loss: 72.7722\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5490 - val_loss: 72.0161\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4958 - val_loss: 72.2527\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6413 - val_loss: 72.3499\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.0948 - val_loss: 71.9394\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3290 - val_loss: 72.7034\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1180 - val_loss: 71.7729\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.0817 - val_loss: 72.0419\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6474 - val_loss: 72.8498\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1942 - val_loss: 72.4062\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9526 - val_loss: 72.0947\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4031 - val_loss: 72.1899\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0884 - val_loss: 71.2817\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8100 - val_loss: 70.5034\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7230 - val_loss: 71.2027\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1712 - val_loss: 69.7241\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.9046 - val_loss: 69.9800\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0711 - val_loss: 70.1277\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.3735 - val_loss: 74.6111\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2203 - val_loss: 72.3383\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9469 - val_loss: 71.5807\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6263 - val_loss: 71.5046\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3064 - val_loss: 71.3291\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5143 - val_loss: 70.8700\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1888 - val_loss: 70.0938\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9910 - val_loss: 69.7807\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1954 - val_loss: 69.9190\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7614 - val_loss: 69.6136\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0936 - val_loss: 69.6756\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9003 - val_loss: 69.5547\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3920 - val_loss: 70.0046\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.0726 - val_loss: 70.6091\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2150 - val_loss: 69.4642\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7744 - val_loss: 69.2605\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8801 - val_loss: 69.0720\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7599 - val_loss: 69.1683\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.3078 - val_loss: 68.7152\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6947 - val_loss: 68.8933\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.0463 - val_loss: 69.4908\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0396 - val_loss: 69.2501\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.2756 - val_loss: 70.7049\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4716 - val_loss: 72.8602\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5476 - val_loss: 70.1460\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7963 - val_loss: 70.0503\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6185 - val_loss: 69.9064\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7124 - val_loss: 70.1687\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4974 - val_loss: 69.6417\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5020 - val_loss: 69.4729\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5704 - val_loss: 69.3296\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.6521 - val_loss: 69.2419\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3961 - val_loss: 70.9261\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.3571 - val_loss: 68.6470\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0764 - val_loss: 68.5214\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1671 - val_loss: 68.7764\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9158 - val_loss: 69.1075\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6755 - val_loss: 69.4566\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8880 - val_loss: 68.6955\n",
      "3/3 [==============================] - 0s 966us/step - loss: 36.6944\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 481.1721 - val_loss: 518.9377\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 416.0043 - val_loss: 448.0912\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 341.3586 - val_loss: 375.0997\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 271.4344 - val_loss: 326.6703\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 236.7119 - val_loss: 299.5887\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 217.5085 - val_loss: 278.6354\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 200.4164 - val_loss: 256.5198\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 182.8984 - val_loss: 237.3443\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 165.8457 - val_loss: 218.1028\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 151.5106 - val_loss: 202.3921\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 138.0347 - val_loss: 186.1397\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 126.0891 - val_loss: 174.7288\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 116.8598 - val_loss: 163.8320\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 108.3796 - val_loss: 154.1226\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.9735 - val_loss: 145.4681\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94.5292 - val_loss: 136.8163\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 88.5574 - val_loss: 129.5847\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 83.8909 - val_loss: 123.6769\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.4738 - val_loss: 117.8157\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.1437 - val_loss: 114.6391\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.5268 - val_loss: 108.3823\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.3947 - val_loss: 104.6105\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.4776 - val_loss: 101.2043\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.4374 - val_loss: 97.7741\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9104 - val_loss: 95.0383\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0198 - val_loss: 93.9949\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7036 - val_loss: 90.9548\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7431 - val_loss: 89.5517\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0590 - val_loss: 88.5436\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6322 - val_loss: 86.8473\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6802 - val_loss: 85.2892\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4722 - val_loss: 84.1709\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.0370 - val_loss: 83.8012\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9298 - val_loss: 82.6990\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2980 - val_loss: 82.9911\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3798 - val_loss: 82.2989\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4997 - val_loss: 81.0438\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6211 - val_loss: 80.4892\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1860 - val_loss: 80.5042\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0191 - val_loss: 79.9405\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5272 - val_loss: 79.4045\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2032 - val_loss: 79.5166\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0766 - val_loss: 79.4745\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9497 - val_loss: 78.2174\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4058 - val_loss: 77.6480\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3062 - val_loss: 77.9353\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3042 - val_loss: 77.1551\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3291 - val_loss: 76.9465\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8335 - val_loss: 76.8399\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0582 - val_loss: 76.5862\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6334 - val_loss: 76.2594\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6256 - val_loss: 76.5558\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3630 - val_loss: 76.2983\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0765 - val_loss: 76.3493\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1679 - val_loss: 76.2901\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8128 - val_loss: 76.2943\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1366 - val_loss: 75.5759\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.6496 - val_loss: 75.0962\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0752 - val_loss: 74.3189\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.1871 - val_loss: 76.1412\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2931 - val_loss: 74.1863\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.7189 - val_loss: 73.8789\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0158 - val_loss: 75.5999\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.0238 - val_loss: 73.6118\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7605 - val_loss: 74.2379\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2332 - val_loss: 74.0325\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3170 - val_loss: 74.2217\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1868 - val_loss: 73.6531\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9848 - val_loss: 73.2008\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6415 - val_loss: 73.8269\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.9083 - val_loss: 73.2888\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6988 - val_loss: 72.7769\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8572 - val_loss: 72.6900\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5486 - val_loss: 72.4904\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1962 - val_loss: 72.2655\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1513 - val_loss: 72.3207\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0269 - val_loss: 72.4284\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.9241 - val_loss: 71.7767\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7838 - val_loss: 71.9890\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4606 - val_loss: 71.5523\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7041 - val_loss: 71.0160\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5547 - val_loss: 71.1346\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3524 - val_loss: 71.1243\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4577 - val_loss: 70.9092\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3959 - val_loss: 70.8884\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6461 - val_loss: 70.7740\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8430 - val_loss: 70.9879\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7099 - val_loss: 70.6311\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7871 - val_loss: 70.4757\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2067 - val_loss: 71.2603\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5959 - val_loss: 70.9495\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.2388 - val_loss: 70.0295\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0683 - val_loss: 71.0910\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2621 - val_loss: 69.9890\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0731 - val_loss: 69.7612\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0235 - val_loss: 70.0866\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8101 - val_loss: 70.6552\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6850 - val_loss: 70.0171\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6012 - val_loss: 69.8440\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1391 - val_loss: 69.3582\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 49.0475 - val_loss: 70.7695\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2065 - val_loss: 69.1953\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4123 - val_loss: 71.9520\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3379 - val_loss: 69.2355\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2696 - val_loss: 69.1981\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1393 - val_loss: 69.2633\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0410 - val_loss: 69.8956\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5070 - val_loss: 70.8836\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3208 - val_loss: 68.8576\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7936 - val_loss: 68.8692\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5562 - val_loss: 69.2487\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5789 - val_loss: 69.7323\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6130 - val_loss: 69.0060\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4101 - val_loss: 68.7295\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.5124 - val_loss: 68.6382\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.8461 - val_loss: 68.5439\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4196 - val_loss: 67.9920\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8353 - val_loss: 68.2375\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1744 - val_loss: 70.2531\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2550 - val_loss: 68.2876\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0457 - val_loss: 68.0912\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.9599 - val_loss: 69.6801\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3019 - val_loss: 67.9268\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7349 - val_loss: 67.9221\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9804 - val_loss: 67.8698\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 46.5880 - val_loss: 67.1881\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6314 - val_loss: 66.7356\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1403 - val_loss: 67.3587\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4065 - val_loss: 67.2554\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.2389 - val_loss: 66.7600\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9875 - val_loss: 67.3811\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1593 - val_loss: 66.4925\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0721 - val_loss: 67.4310\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1787 - val_loss: 68.2534\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.8699 - val_loss: 66.7693\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2860 - val_loss: 66.7726\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.5314 - val_loss: 66.2663\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4605 - val_loss: 66.1003\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6278 - val_loss: 65.4949\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5953 - val_loss: 66.4323\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9220 - val_loss: 68.1979\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4762 - val_loss: 66.1943\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4082 - val_loss: 67.1302\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 45.5299 - val_loss: 66.3159\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9888 - val_loss: 65.8249\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8956 - val_loss: 65.5574\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0218 - val_loss: 65.5583\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 44.7234 - val_loss: 65.6453\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8518 - val_loss: 66.1978\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6751 - val_loss: 65.1831\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0199 - val_loss: 65.0954\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5685 - val_loss: 65.1266\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3312 - val_loss: 65.7025\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7782 - val_loss: 65.3075\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3097 - val_loss: 64.4775\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9793 - val_loss: 66.0786\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1927 - val_loss: 63.9496\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8935 - val_loss: 64.2121\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8054 - val_loss: 63.8408\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6616 - val_loss: 64.0847\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6981 - val_loss: 64.0014\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9693 - val_loss: 63.7046\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.2464 - val_loss: 64.0018\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5381 - val_loss: 63.5885\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3401 - val_loss: 63.0345\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.3055 - val_loss: 62.8648\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3294 - val_loss: 63.0126\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2039 - val_loss: 62.7804\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1598 - val_loss: 63.0906\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2168 - val_loss: 65.4429\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9282 - val_loss: 62.7854\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0795 - val_loss: 63.4135\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1058 - val_loss: 62.8777\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.7372 - val_loss: 62.7059\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6611 - val_loss: 63.4797\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3241 - val_loss: 62.5093\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.2852 - val_loss: 62.3757\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1120 - val_loss: 62.4187\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0756 - val_loss: 61.7826\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4740 - val_loss: 61.5327\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.3623 - val_loss: 63.9218\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1977 - val_loss: 62.3277\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3360 - val_loss: 61.7713\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4133 - val_loss: 63.1017\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2433 - val_loss: 61.8031\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6580 - val_loss: 61.2068\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0527 - val_loss: 62.9615\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0627 - val_loss: 61.0091\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6690 - val_loss: 60.3795\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5297 - val_loss: 60.2837\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5909 - val_loss: 61.4237\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9401 - val_loss: 59.6281\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8558 - val_loss: 60.8242\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.7923 - val_loss: 59.6024\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5943 - val_loss: 59.2947\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4967 - val_loss: 60.2479\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5145 - val_loss: 59.0882\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1035 - val_loss: 60.9527\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1071 - val_loss: 59.7830\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3598 - val_loss: 60.2582\n",
      "3/3 [==============================] - 0s 914us/step - loss: 67.0242\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 120.6383 - val_loss: 122.7287\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 83.2525 - val_loss: 98.7391\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6027 - val_loss: 87.4610\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.2655 - val_loss: 87.0839\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.0456 - val_loss: 92.1495\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.4806 - val_loss: 86.9532\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.4769 - val_loss: 84.7632\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9249 - val_loss: 85.9647\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.6349 - val_loss: 84.4113\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1270 - val_loss: 80.9282\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8711 - val_loss: 82.1007\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.9437 - val_loss: 81.6101\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0948 - val_loss: 77.1820\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.6521 - val_loss: 83.2405\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.3455 - val_loss: 100.4686\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3129 - val_loss: 79.6141\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2550 - val_loss: 84.5390\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.2694 - val_loss: 79.5089\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4704 - val_loss: 74.8235\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1917 - val_loss: 84.2913\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4515 - val_loss: 76.2732\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6801 - val_loss: 89.2032\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2725 - val_loss: 75.6857\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6412 - val_loss: 87.5158\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0614 - val_loss: 74.9459\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2617 - val_loss: 75.9484\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9350 - val_loss: 77.1772\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4228 - val_loss: 76.2225\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6697 - val_loss: 75.4794\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1904 - val_loss: 75.2197\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0036 - val_loss: 73.0467\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8058 - val_loss: 76.6049\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2961 - val_loss: 72.6154\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8165 - val_loss: 72.3313\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0791 - val_loss: 72.8389\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1919 - val_loss: 74.8005\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.1374 - val_loss: 73.8141\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4113 - val_loss: 80.0926\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7335 - val_loss: 70.9378\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3491 - val_loss: 72.9060\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6611 - val_loss: 73.9272\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3362 - val_loss: 68.3235\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9653 - val_loss: 79.1143\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6758 - val_loss: 72.0912\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0125 - val_loss: 73.2039\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3556 - val_loss: 68.7683\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7484 - val_loss: 78.6184\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.8742 - val_loss: 68.6961\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7325 - val_loss: 75.5050\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3487 - val_loss: 68.6479\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7093 - val_loss: 67.2495\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.0096 - val_loss: 69.8856\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3924 - val_loss: 66.8040\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1261 - val_loss: 71.8236\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5648 - val_loss: 65.0390\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1118 - val_loss: 69.8116\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7351 - val_loss: 66.6321\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1434 - val_loss: 69.5464\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2454 - val_loss: 67.9316\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7435 - val_loss: 73.3688\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4033 - val_loss: 68.8109\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0692 - val_loss: 69.6910\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3508 - val_loss: 62.8890\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0948 - val_loss: 62.2890\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.2183 - val_loss: 91.2737\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8807 - val_loss: 64.3637\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.0318 - val_loss: 71.6123\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9444 - val_loss: 61.8287\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1134 - val_loss: 64.2243\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2624 - val_loss: 62.5189\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7035 - val_loss: 60.8613\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0715 - val_loss: 59.8207\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.5077 - val_loss: 62.2280\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1283 - val_loss: 59.4472\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6268 - val_loss: 65.4291\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5831 - val_loss: 58.4940\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0433 - val_loss: 60.3077\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3966 - val_loss: 58.0021\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.0724 - val_loss: 58.6469\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0385 - val_loss: 74.0063\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8985 - val_loss: 58.4422\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8641 - val_loss: 64.1236\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7441 - val_loss: 55.7816\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5584 - val_loss: 67.2165\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1700 - val_loss: 56.0623\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1725 - val_loss: 56.5356\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.1385 - val_loss: 57.1599\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0076 - val_loss: 55.2053\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9761 - val_loss: 70.5423\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9720 - val_loss: 55.9123\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9568 - val_loss: 61.2581\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9289 - val_loss: 52.8622\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9120 - val_loss: 54.9260\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1509 - val_loss: 56.0439\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2821 - val_loss: 51.6337\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9114 - val_loss: 52.1235\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7911 - val_loss: 51.8761\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3570 - val_loss: 54.9856\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6265 - val_loss: 50.2969\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4334 - val_loss: 56.0945\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0881 - val_loss: 51.1991\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7980 - val_loss: 50.4946\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.1151 - val_loss: 51.5177\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4850 - val_loss: 51.7783\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0323 - val_loss: 48.7284\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7656 - val_loss: 50.6166\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.1749 - val_loss: 48.8033\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3006 - val_loss: 48.4786\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2225 - val_loss: 58.2548\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7268 - val_loss: 49.5501\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0224 - val_loss: 48.0850\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4812 - val_loss: 50.6892\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9397 - val_loss: 50.9650\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9837 - val_loss: 46.1780\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.7253 - val_loss: 49.6121\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.6125 - val_loss: 52.2261\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5892 - val_loss: 45.0949\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0475 - val_loss: 47.3581\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5593 - val_loss: 55.7526\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2391 - val_loss: 49.5209\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1387 - val_loss: 43.9081\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.6729 - val_loss: 48.8573\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3372 - val_loss: 44.5782\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3504 - val_loss: 42.0558\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.6972 - val_loss: 47.4027\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.8287 - val_loss: 41.3525\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.0366 - val_loss: 43.3759\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7600 - val_loss: 40.1092\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2951 - val_loss: 39.4076\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.0772 - val_loss: 38.3368\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7982 - val_loss: 40.1025\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4569 - val_loss: 69.4752\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6191 - val_loss: 45.2085\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.6478 - val_loss: 42.3692\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5978 - val_loss: 38.7904\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.6691 - val_loss: 38.8530\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9772 - val_loss: 39.7261\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7252 - val_loss: 39.4194\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.8368 - val_loss: 40.2877\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2572 - val_loss: 37.3418\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5317 - val_loss: 37.4398\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9647 - val_loss: 40.5790\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.2802 - val_loss: 41.0542\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7591 - val_loss: 36.5839\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2754 - val_loss: 41.0754\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.1894 - val_loss: 39.8861\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3038 - val_loss: 40.0713\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4478 - val_loss: 31.9429\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0531 - val_loss: 33.2374\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7820 - val_loss: 34.5900\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.4731 - val_loss: 40.7763\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.4247 - val_loss: 48.0918\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7454 - val_loss: 39.4368\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.0751 - val_loss: 41.8884\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0614 - val_loss: 39.9463\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1873 - val_loss: 35.8584\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0848 - val_loss: 33.9877\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2921 - val_loss: 31.5834\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2535 - val_loss: 33.6622\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8642 - val_loss: 35.7963\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.1715 - val_loss: 29.8710\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9035 - val_loss: 31.8899\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5100 - val_loss: 30.9531\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3386 - val_loss: 28.2294\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4166 - val_loss: 41.5712\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0342 - val_loss: 31.4210\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5609 - val_loss: 29.6178\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1775 - val_loss: 27.5598\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6451 - val_loss: 28.4573\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3758 - val_loss: 30.4790\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6458 - val_loss: 33.3571\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.2624 - val_loss: 28.0340\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7100 - val_loss: 30.1562\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7638 - val_loss: 26.9568\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0940 - val_loss: 32.9056\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7310 - val_loss: 33.6305\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3674 - val_loss: 28.5445\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.9512 - val_loss: 26.7785\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2506 - val_loss: 22.8473\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1922 - val_loss: 28.0130\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0074 - val_loss: 28.7678\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2687 - val_loss: 29.9607\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5513 - val_loss: 27.7158\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9819 - val_loss: 31.9030\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.6534 - val_loss: 33.6990\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7169 - val_loss: 26.4748\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0856 - val_loss: 29.9342\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2019 - val_loss: 28.8775\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5776 - val_loss: 24.3166\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2395 - val_loss: 23.6245\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7912 - val_loss: 23.0936\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7973 - val_loss: 37.1543\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9410 - val_loss: 35.2900\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1021 - val_loss: 39.2793\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.9240 - val_loss: 44.5489\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8761 - val_loss: 36.3748\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7737 - val_loss: 42.9564\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1261 - val_loss: 35.1319\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.8935 - val_loss: 33.0919\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.1913 - val_loss: 34.2216\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 36.4764\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1245.9651 - val_loss: 895.9287\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 606.1354 - val_loss: 490.1207\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 327.8791 - val_loss: 294.1650\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 188.7548 - val_loss: 182.3567\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 116.2187 - val_loss: 122.4090\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 83.4230 - val_loss: 100.0963\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.5402 - val_loss: 87.4140\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.6974 - val_loss: 83.4302\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.3606 - val_loss: 81.7033\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.2197 - val_loss: 81.2319\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5066 - val_loss: 81.9387\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7955 - val_loss: 80.6569\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1937 - val_loss: 78.5136\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0413 - val_loss: 76.9827\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 62.2001 - val_loss: 76.7932\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.0733 - val_loss: 77.4370\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6103 - val_loss: 79.2634\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2743 - val_loss: 78.7169\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5334 - val_loss: 74.9076\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.1980 - val_loss: 75.2723\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9258 - val_loss: 76.4703\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.1791 - val_loss: 76.7337\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3294 - val_loss: 75.3220\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9703 - val_loss: 74.7585\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3894 - val_loss: 75.0819\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.1155 - val_loss: 73.7183\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0264 - val_loss: 73.6730\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.4172 - val_loss: 73.6747\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9623 - val_loss: 73.3681\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2450 - val_loss: 72.8076\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4588 - val_loss: 71.2828\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6862 - val_loss: 71.4375\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 57.7106 - val_loss: 69.3665\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.7703 - val_loss: 72.0459\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1737 - val_loss: 77.2400\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0183 - val_loss: 70.5136\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.9274 - val_loss: 68.6294\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7799 - val_loss: 68.8261\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5108 - val_loss: 67.5643\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4500 - val_loss: 66.3749\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4502 - val_loss: 67.9099\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.9811 - val_loss: 70.1658\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3619 - val_loss: 68.0972\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2863 - val_loss: 71.5752\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8138 - val_loss: 67.7909\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7334 - val_loss: 66.5767\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3487 - val_loss: 67.3192\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9552 - val_loss: 65.0467\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.2887 - val_loss: 61.1597\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7683 - val_loss: 70.7004\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 55.4555 - val_loss: 71.0539\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.7599 - val_loss: 60.3702\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6264 - val_loss: 61.8872\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4350 - val_loss: 58.4161\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5362 - val_loss: 60.4558\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0645 - val_loss: 67.3616\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.3047 - val_loss: 77.8891\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0205 - val_loss: 59.1777\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7062 - val_loss: 56.8344\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0058 - val_loss: 58.0829\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0674 - val_loss: 57.1357\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9928 - val_loss: 54.9235\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.7365 - val_loss: 57.2943\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2338 - val_loss: 58.3573\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9450 - val_loss: 54.8547\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8423 - val_loss: 54.3571\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6305 - val_loss: 56.9498\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.3281 - val_loss: 54.7348\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.9660 - val_loss: 56.2065\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.3834 - val_loss: 51.1282\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.5731 - val_loss: 54.5392\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7364 - val_loss: 51.2313\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.8380 - val_loss: 55.2156\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.8632 - val_loss: 49.1306\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6600 - val_loss: 47.0249\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1456 - val_loss: 50.6093\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9407 - val_loss: 47.2120\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.5814 - val_loss: 50.7085\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3395 - val_loss: 47.2331\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3691 - val_loss: 44.6333\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2302 - val_loss: 44.8706\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.7447 - val_loss: 45.3022\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9466 - val_loss: 44.3681\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9400 - val_loss: 45.3946\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7867 - val_loss: 43.8959\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5894 - val_loss: 41.5949\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3856 - val_loss: 51.1898\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8156 - val_loss: 39.9185\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3448 - val_loss: 46.2579\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.6123 - val_loss: 40.4753\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7770 - val_loss: 41.6446\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2026 - val_loss: 39.6653\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3129 - val_loss: 38.6239\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4312 - val_loss: 38.1508\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8453 - val_loss: 38.3065\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.1545 - val_loss: 35.6592\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6502 - val_loss: 34.1387\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.7499 - val_loss: 35.3316\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.7020 - val_loss: 34.8836\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8541 - val_loss: 35.1273\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8685 - val_loss: 37.2006\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7735 - val_loss: 34.0008\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1279 - val_loss: 32.2202\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9958 - val_loss: 35.4846\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1274 - val_loss: 33.2677\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5779 - val_loss: 32.3357\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2613 - val_loss: 32.9563\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0024 - val_loss: 32.2106\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6919 - val_loss: 30.1312\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1100 - val_loss: 31.8401\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2716 - val_loss: 35.8310\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3616 - val_loss: 29.2244\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6703 - val_loss: 30.5252\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1725 - val_loss: 30.2935\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4669 - val_loss: 29.9334\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2613 - val_loss: 27.6220\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3392 - val_loss: 30.9150\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5638 - val_loss: 30.1648\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7883 - val_loss: 27.8836\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9180 - val_loss: 27.7422\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9395 - val_loss: 30.8719\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4549 - val_loss: 28.6362\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8419 - val_loss: 26.5660\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2089 - val_loss: 27.3998\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6457 - val_loss: 26.1424\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.1049 - val_loss: 32.9312\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0130 - val_loss: 26.5011\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3988 - val_loss: 26.3556\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.6202 - val_loss: 25.4827\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.6286 - val_loss: 26.3400\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0326 - val_loss: 28.5681\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1935 - val_loss: 27.3480\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0193 - val_loss: 28.9878\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8093 - val_loss: 30.3997\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.4292 - val_loss: 25.3972\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0980 - val_loss: 25.7255\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2054 - val_loss: 27.4622\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8967 - val_loss: 27.7138\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2446 - val_loss: 25.3934\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8208 - val_loss: 26.1622\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7266 - val_loss: 24.3763\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6713 - val_loss: 24.8204\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4563 - val_loss: 27.0012\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3128 - val_loss: 24.0735\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.2135 - val_loss: 26.2918\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3022 - val_loss: 24.9326\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4638 - val_loss: 22.8930\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4891 - val_loss: 23.8000\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5340 - val_loss: 23.0088\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1093 - val_loss: 24.7550\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.6207 - val_loss: 23.6275\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.6281 - val_loss: 22.0979\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2981 - val_loss: 24.1784\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.3159 - val_loss: 24.9225\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3567 - val_loss: 31.9233\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3101 - val_loss: 24.1086\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5363 - val_loss: 25.1389\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7208 - val_loss: 23.4282\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.5870 - val_loss: 31.0750\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7979 - val_loss: 23.2920\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2348 - val_loss: 23.9340\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0038 - val_loss: 23.4061\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.1276 - val_loss: 27.3544\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0636 - val_loss: 24.4821\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3893 - val_loss: 21.5063\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.3757 - val_loss: 23.3141\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.3572 - val_loss: 22.1396\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8384 - val_loss: 21.8453\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9581 - val_loss: 23.6569\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.0574 - val_loss: 23.1056\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2670 - val_loss: 21.9054\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7303 - val_loss: 21.5267\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3401 - val_loss: 27.2827\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7502 - val_loss: 20.7921\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.4933 - val_loss: 21.8068\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6132 - val_loss: 21.0224\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4467 - val_loss: 21.3293\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.3795 - val_loss: 20.6673\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1801 - val_loss: 20.4155\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.2038 - val_loss: 21.5945\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.8012 - val_loss: 20.1303\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3339 - val_loss: 23.1281\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9216 - val_loss: 21.5343\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8084 - val_loss: 19.4433\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.2455 - val_loss: 18.2999\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.8222 - val_loss: 22.3388\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5145 - val_loss: 21.9347\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1316 - val_loss: 19.9950\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6811 - val_loss: 20.1692\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.2184 - val_loss: 19.9395\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.2564 - val_loss: 22.2112\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8405 - val_loss: 20.3905\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.4705 - val_loss: 20.1421\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.7065 - val_loss: 20.1651\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9255 - val_loss: 20.2197\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6250 - val_loss: 19.7067\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.9742 - val_loss: 20.6604\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1634 - val_loss: 18.6370\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8309 - val_loss: 18.5424\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.0546 - val_loss: 19.2364\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 21.1685\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2549.3232 - val_loss: 1801.8097\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1484.5956 - val_loss: 1242.7952\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1039.1190 - val_loss: 915.7260\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 765.3069 - val_loss: 694.5259\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 571.0302 - val_loss: 541.7658\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 441.7046 - val_loss: 416.6370\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 317.4359 - val_loss: 311.0557\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 227.1488 - val_loss: 248.4689\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 181.7610 - val_loss: 223.0833\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 162.3058 - val_loss: 205.6044\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 148.8740 - val_loss: 190.5593\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 137.6395 - val_loss: 178.7226\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 127.4188 - val_loss: 166.6857\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 117.5108 - val_loss: 156.8248\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 110.3913 - val_loss: 147.4359\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104.1677 - val_loss: 139.8887\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94.6491 - val_loss: 130.4858\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.9782 - val_loss: 124.8314\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.8609 - val_loss: 118.4691\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.9939 - val_loss: 111.6093\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.4083 - val_loss: 106.7193\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.7221 - val_loss: 101.4753\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.2515 - val_loss: 96.8883\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.1993 - val_loss: 92.3678\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.6089 - val_loss: 89.2064\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.0425 - val_loss: 87.8142\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.1337 - val_loss: 85.7353\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8109 - val_loss: 84.3450\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.6414 - val_loss: 82.6859\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6864 - val_loss: 82.7293\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.9089 - val_loss: 81.8166\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5502 - val_loss: 83.3041\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2277 - val_loss: 83.0813\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7290 - val_loss: 82.5612\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8767 - val_loss: 80.5164\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.5934 - val_loss: 80.1455\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.6994 - val_loss: 79.1869\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3656 - val_loss: 79.0160\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2688 - val_loss: 79.4187\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4893 - val_loss: 79.9855\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7291 - val_loss: 79.4821\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1482 - val_loss: 78.2255\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.2087 - val_loss: 77.3764\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1766 - val_loss: 77.2298\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5311 - val_loss: 77.5918\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8695 - val_loss: 82.2804\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.7548 - val_loss: 80.4257\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0395 - val_loss: 78.1302\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2683 - val_loss: 80.7912\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0896 - val_loss: 78.6493\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7366 - val_loss: 76.4227\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.3646 - val_loss: 75.5311\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1136 - val_loss: 77.1540\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.7391 - val_loss: 76.6737\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1501 - val_loss: 74.8779\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.5305 - val_loss: 73.5603\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.3349 - val_loss: 74.3309\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9986 - val_loss: 74.3238\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0702 - val_loss: 74.1265\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7586 - val_loss: 73.7139\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0808 - val_loss: 72.9345\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.9264 - val_loss: 71.7690\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4101 - val_loss: 72.6857\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6150 - val_loss: 72.0860\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1910 - val_loss: 72.0030\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3598 - val_loss: 70.1017\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0161 - val_loss: 71.5790\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9711 - val_loss: 71.2994\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6566 - val_loss: 70.2684\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3979 - val_loss: 69.6603\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3471 - val_loss: 69.6589\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5541 - val_loss: 72.2428\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4526 - val_loss: 71.4975\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7398 - val_loss: 69.2620\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.4403 - val_loss: 69.0146\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.3513 - val_loss: 70.0991\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.5873 - val_loss: 69.8683\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2284 - val_loss: 71.1818\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.1611 - val_loss: 69.3285\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7336 - val_loss: 69.5232\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3083 - val_loss: 68.7250\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.1190 - val_loss: 69.5244\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0339 - val_loss: 68.4515\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2030 - val_loss: 67.4101\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 52.1876 - val_loss: 68.2775\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9895 - val_loss: 70.3968\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2621 - val_loss: 67.6755\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4568 - val_loss: 69.8208\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8075 - val_loss: 66.0171\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.5039 - val_loss: 65.5908\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.7665 - val_loss: 64.7893\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8695 - val_loss: 67.2408\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8200 - val_loss: 67.0127\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4054 - val_loss: 68.5494\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.0475 - val_loss: 66.7732\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2449 - val_loss: 66.9038\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7459 - val_loss: 64.0997\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3182 - val_loss: 63.2570\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6149 - val_loss: 64.6048\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0480 - val_loss: 64.9885\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7481 - val_loss: 69.0729\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0799 - val_loss: 67.3774\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8808 - val_loss: 66.2112\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.9942 - val_loss: 71.0161\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3983 - val_loss: 65.1977\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.9373 - val_loss: 62.6465\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0672 - val_loss: 62.8669\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4714 - val_loss: 65.6243\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2543 - val_loss: 61.3291\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4828 - val_loss: 61.6141\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6573 - val_loss: 62.1592\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6478 - val_loss: 62.4305\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2311 - val_loss: 59.8738\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7007 - val_loss: 59.5951\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4612 - val_loss: 60.5527\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7549 - val_loss: 61.0504\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4537 - val_loss: 65.7028\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2889 - val_loss: 60.6628\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9578 - val_loss: 60.5070\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2987 - val_loss: 61.7636\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1137 - val_loss: 66.4228\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8561 - val_loss: 59.9070\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2532 - val_loss: 58.2426\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3021 - val_loss: 59.7874\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8765 - val_loss: 57.2326\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4312 - val_loss: 57.1694\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4202 - val_loss: 58.1671\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6026 - val_loss: 57.0714\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9078 - val_loss: 61.0103\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5052 - val_loss: 56.8014\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4997 - val_loss: 58.1124\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7197 - val_loss: 56.3120\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4673 - val_loss: 59.0976\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9865 - val_loss: 58.7474\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4476 - val_loss: 54.5384\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6688 - val_loss: 53.8161\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7518 - val_loss: 61.9803\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1819 - val_loss: 56.3474\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2236 - val_loss: 55.0724\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1049 - val_loss: 54.7029\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1632 - val_loss: 53.8252\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1853 - val_loss: 53.4194\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7897 - val_loss: 55.9165\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5577 - val_loss: 59.5524\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4556 - val_loss: 51.5535\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6439 - val_loss: 53.1980\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4138 - val_loss: 56.7052\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8882 - val_loss: 55.0500\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.3218 - val_loss: 50.5498\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6342 - val_loss: 53.2016\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.8892 - val_loss: 51.9367\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1600 - val_loss: 51.5295\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2249 - val_loss: 51.0765\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.7602 - val_loss: 51.5203\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6589 - val_loss: 49.9731\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3239 - val_loss: 50.4085\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8227 - val_loss: 52.9135\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8614 - val_loss: 47.4719\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7031 - val_loss: 50.1396\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4817 - val_loss: 49.4062\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4653 - val_loss: 48.5005\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9069 - val_loss: 49.3071\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2150 - val_loss: 49.4540\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2344 - val_loss: 47.9223\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0692 - val_loss: 49.9891\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.3260 - val_loss: 47.2013\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1304 - val_loss: 46.7785\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3674 - val_loss: 44.7195\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7661 - val_loss: 49.1792\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.4162 - val_loss: 47.6657\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.4426 - val_loss: 44.6519\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7114 - val_loss: 44.0403\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8851 - val_loss: 45.9406\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0425 - val_loss: 45.0983\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1002 - val_loss: 46.4437\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.7346 - val_loss: 41.4649\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1774 - val_loss: 43.2932\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6669 - val_loss: 41.9237\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3917 - val_loss: 44.1092\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.7858 - val_loss: 41.5687\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.4401 - val_loss: 42.5490\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.9647 - val_loss: 41.7515\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1287 - val_loss: 46.3914\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4226 - val_loss: 40.3057\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2699 - val_loss: 54.4055\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7633 - val_loss: 65.7309\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2083 - val_loss: 37.0338\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9605 - val_loss: 42.1934\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2486 - val_loss: 37.6084\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4855 - val_loss: 42.4823\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.3020 - val_loss: 39.3234\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2815 - val_loss: 36.7372\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8634 - val_loss: 36.5832\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8575 - val_loss: 36.1273\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1580 - val_loss: 39.4871\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4665 - val_loss: 37.6488\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8929 - val_loss: 45.7999\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3640 - val_loss: 37.8530\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3553 - val_loss: 36.8664\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2174 - val_loss: 35.5496\n",
      "3/3 [==============================] - 0s 899us/step - loss: 30.1256\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3386.3154 - val_loss: 1941.4375\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1364.1499 - val_loss: 864.5026\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 587.6823 - val_loss: 425.6960\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 269.1676 - val_loss: 202.8723\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 132.6783 - val_loss: 148.5363\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 120.0205 - val_loss: 135.3744\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 102.6668 - val_loss: 120.9841\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.9482 - val_loss: 114.1397\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.6262 - val_loss: 106.8658\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 80.9114 - val_loss: 98.6531\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.8873 - val_loss: 90.8944\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.4932 - val_loss: 85.7627\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.1371 - val_loss: 83.2424\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1174 - val_loss: 80.0693\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.7121 - val_loss: 77.4338\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.4440 - val_loss: 77.2146\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8023 - val_loss: 75.4398\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.8380 - val_loss: 74.4143\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.0184 - val_loss: 75.6679\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4025 - val_loss: 75.0869\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3376 - val_loss: 73.6611\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4645 - val_loss: 73.5016\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3725 - val_loss: 72.2299\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5210 - val_loss: 72.0031\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1715 - val_loss: 72.2120\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1903 - val_loss: 72.2795\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5573 - val_loss: 71.0762\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0750 - val_loss: 71.4246\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4913 - val_loss: 74.5779\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4398 - val_loss: 75.2212\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7303 - val_loss: 70.7770\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1212 - val_loss: 70.2747\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.6013 - val_loss: 70.7933\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2250 - val_loss: 71.2971\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1728 - val_loss: 71.3743\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 58.2247 - val_loss: 70.2493\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0054 - val_loss: 69.9504\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.5800 - val_loss: 69.9149\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0447 - val_loss: 71.0877\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6371 - val_loss: 72.4596\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2643 - val_loss: 70.5742\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0670 - val_loss: 69.9197\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7560 - val_loss: 69.6440\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7242 - val_loss: 68.7623\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4804 - val_loss: 69.3450\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5143 - val_loss: 68.3689\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1264 - val_loss: 70.1549\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.2934 - val_loss: 69.6807\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3332 - val_loss: 70.3395\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4831 - val_loss: 69.0589\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1116 - val_loss: 69.0311\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.1782 - val_loss: 68.8550\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.7229 - val_loss: 68.5167\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9344 - val_loss: 69.3961\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2740 - val_loss: 67.9736\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8396 - val_loss: 68.3464\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8396 - val_loss: 68.3536\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9210 - val_loss: 67.4245\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7365 - val_loss: 67.1159\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.0885 - val_loss: 66.5514\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8662 - val_loss: 65.4392\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5091 - val_loss: 63.9007\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3982 - val_loss: 64.5364\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1042 - val_loss: 64.2491\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.5369 - val_loss: 63.7973\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1304 - val_loss: 64.3028\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8970 - val_loss: 63.5599\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3535 - val_loss: 63.4905\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3154 - val_loss: 63.9108\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0337 - val_loss: 63.1685\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4146 - val_loss: 62.6370\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9804 - val_loss: 62.1980\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8047 - val_loss: 62.7019\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6209 - val_loss: 62.4984\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4706 - val_loss: 59.9879\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8858 - val_loss: 60.4282\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7112 - val_loss: 59.1033\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5877 - val_loss: 58.6805\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7833 - val_loss: 64.8973\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5438 - val_loss: 58.0942\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5473 - val_loss: 61.8944\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5844 - val_loss: 56.2546\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.0673 - val_loss: 56.4786\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0254 - val_loss: 58.4565\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0530 - val_loss: 55.9298\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3193 - val_loss: 54.2959\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8088 - val_loss: 54.3650\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0070 - val_loss: 55.7535\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3958 - val_loss: 54.7259\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5263 - val_loss: 57.9741\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9307 - val_loss: 52.4140\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9116 - val_loss: 51.4516\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.3376 - val_loss: 48.7811\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.3237 - val_loss: 49.6994\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6479 - val_loss: 58.5009\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5254 - val_loss: 48.4849\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9508 - val_loss: 46.0193\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9816 - val_loss: 47.8417\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4212 - val_loss: 50.9966\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8973 - val_loss: 46.2226\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4254 - val_loss: 45.6359\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.1195 - val_loss: 55.3292\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5847 - val_loss: 44.3752\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3473 - val_loss: 42.9628\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.4999 - val_loss: 45.4411\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9112 - val_loss: 43.8317\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7309 - val_loss: 46.6542\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9077 - val_loss: 40.7706\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4123 - val_loss: 71.5471\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9792 - val_loss: 42.7698\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2325 - val_loss: 48.9842\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2979 - val_loss: 60.0211\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4652 - val_loss: 38.5752\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5460 - val_loss: 39.7255\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1240 - val_loss: 41.1547\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 30.7273 - val_loss: 38.6875\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4398 - val_loss: 40.2931\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7764 - val_loss: 41.3147\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6187 - val_loss: 38.4934\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1794 - val_loss: 35.7107\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.4877 - val_loss: 44.4224\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6692 - val_loss: 36.5194\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2198 - val_loss: 43.0341\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7272 - val_loss: 35.5806\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.0346 - val_loss: 43.1262\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.7916 - val_loss: 38.3110\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5170 - val_loss: 34.8261\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7056 - val_loss: 36.2868\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2218 - val_loss: 44.5012\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4280 - val_loss: 35.4830\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.7926 - val_loss: 34.7944\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5164 - val_loss: 48.2865\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.6435 - val_loss: 35.6745\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1456 - val_loss: 37.6207\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1415 - val_loss: 34.5936\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1928 - val_loss: 36.3593\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.3312 - val_loss: 37.0788\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7082 - val_loss: 36.7904\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5112 - val_loss: 34.8290\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1386 - val_loss: 36.2868\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0392 - val_loss: 33.0992\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4861 - val_loss: 31.6323\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2141 - val_loss: 43.0121\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6746 - val_loss: 35.9509\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7009 - val_loss: 31.8398\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8398 - val_loss: 32.5082\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9129 - val_loss: 56.0543\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.0514 - val_loss: 33.6164\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9846 - val_loss: 34.3035\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4167 - val_loss: 35.9833\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2746 - val_loss: 41.6401\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8757 - val_loss: 36.3052\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1260 - val_loss: 33.9770\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7943 - val_loss: 34.3595\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8027 - val_loss: 36.1301\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4099 - val_loss: 33.8751\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5024 - val_loss: 34.1541\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4371 - val_loss: 33.9517\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6647 - val_loss: 34.0058\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2760 - val_loss: 30.3202\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7713 - val_loss: 33.4458\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1169 - val_loss: 29.3832\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2002 - val_loss: 35.1798\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.6683 - val_loss: 33.2524\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.4812 - val_loss: 31.5197\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1718 - val_loss: 31.8145\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9949 - val_loss: 29.3684\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4886 - val_loss: 32.9025\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8628 - val_loss: 29.3533\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8080 - val_loss: 32.7737\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8678 - val_loss: 31.7901\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4689 - val_loss: 29.5690\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9559 - val_loss: 27.9010\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.3709 - val_loss: 31.2788\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1114 - val_loss: 37.2501\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9922 - val_loss: 27.6712\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2390 - val_loss: 35.3488\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9022 - val_loss: 27.3073\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8813 - val_loss: 28.8582\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7677 - val_loss: 27.5232\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0308 - val_loss: 26.5319\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6068 - val_loss: 43.1686\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.6469 - val_loss: 46.4278\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3726 - val_loss: 31.6166\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1678 - val_loss: 29.7444\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8775 - val_loss: 26.7398\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7090 - val_loss: 27.1854\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1592 - val_loss: 29.0130\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2792 - val_loss: 32.9937\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8739 - val_loss: 25.7854\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3765 - val_loss: 26.6222\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9209 - val_loss: 32.3620\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6541 - val_loss: 27.1308\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5423 - val_loss: 26.7160\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2413 - val_loss: 25.3387\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7057 - val_loss: 25.8660\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7585 - val_loss: 26.5661\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2908 - val_loss: 35.8609\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5172 - val_loss: 25.8258\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0394 - val_loss: 26.9091\n",
      "3/3 [==============================] - 0s 945us/step - loss: 18.6634\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3631.3118 - val_loss: 1413.3618\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 775.0698 - val_loss: 341.1492\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 173.0379 - val_loss: 138.2416\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.8028 - val_loss: 120.4117\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.0725 - val_loss: 100.2859\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.5983 - val_loss: 89.3534\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.8173 - val_loss: 82.4598\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6005 - val_loss: 78.7044\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9233 - val_loss: 78.3282\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9332 - val_loss: 77.2843\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2047 - val_loss: 75.6510\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8078 - val_loss: 74.9525\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3703 - val_loss: 74.6701\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.9624 - val_loss: 74.1895\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4070 - val_loss: 73.0039\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.4471 - val_loss: 73.8662\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2445 - val_loss: 73.5475\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4428 - val_loss: 71.8302\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3531 - val_loss: 72.0848\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1561 - val_loss: 71.4957\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1504 - val_loss: 70.7096\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4191 - val_loss: 71.5282\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1927 - val_loss: 68.7600\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0835 - val_loss: 72.5771\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1477 - val_loss: 70.5257\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5147 - val_loss: 70.9038\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9582 - val_loss: 68.2063\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3211 - val_loss: 66.6505\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4335 - val_loss: 69.6580\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6887 - val_loss: 69.1321\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6432 - val_loss: 67.2903\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6093 - val_loss: 65.9474\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1883 - val_loss: 65.0805\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9784 - val_loss: 67.7781\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6644 - val_loss: 66.5363\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4319 - val_loss: 67.8832\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6034 - val_loss: 67.6829\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7103 - val_loss: 67.9344\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3316 - val_loss: 65.2355\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9871 - val_loss: 65.8575\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.0237 - val_loss: 63.2995\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2851 - val_loss: 63.5320\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3530 - val_loss: 65.6023\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1685 - val_loss: 63.1415\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9791 - val_loss: 64.7926\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5420 - val_loss: 62.7368\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7962 - val_loss: 62.9418\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9086 - val_loss: 61.9067\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0626 - val_loss: 62.9538\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4940 - val_loss: 61.3325\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4820 - val_loss: 61.3844\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6161 - val_loss: 59.7350\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1993 - val_loss: 60.4184\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6373 - val_loss: 58.8762\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8065 - val_loss: 59.4904\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1832 - val_loss: 59.7556\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9111 - val_loss: 58.3309\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9693 - val_loss: 62.2241\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6632 - val_loss: 56.5607\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5061 - val_loss: 56.5352\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7644 - val_loss: 56.7593\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6880 - val_loss: 56.6606\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9659 - val_loss: 57.0783\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.3551 - val_loss: 55.2389\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3466 - val_loss: 56.1984\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1071 - val_loss: 53.1936\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8239 - val_loss: 55.4416\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2255 - val_loss: 54.1834\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3227 - val_loss: 53.6814\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1039 - val_loss: 54.5035\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3336 - val_loss: 52.5807\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5752 - val_loss: 53.4863\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1907 - val_loss: 50.6927\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9255 - val_loss: 51.2649\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7362 - val_loss: 51.7013\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.2829 - val_loss: 48.8190\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.4922 - val_loss: 49.3287\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5013 - val_loss: 50.1376\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8190 - val_loss: 52.1381\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.1864 - val_loss: 48.2458\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1355 - val_loss: 49.3406\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1170 - val_loss: 48.8343\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.3890 - val_loss: 47.0750\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5933 - val_loss: 45.4549\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1541 - val_loss: 47.4643\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 33.7670 - val_loss: 45.8341\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.3569 - val_loss: 45.2087\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2105 - val_loss: 44.5217\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6836 - val_loss: 49.2142\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3673 - val_loss: 45.6004\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4375 - val_loss: 41.9353\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8166 - val_loss: 50.0706\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.6593 - val_loss: 41.5988\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.0620 - val_loss: 41.4168\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.4616 - val_loss: 43.3100\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0796 - val_loss: 43.4789\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9232 - val_loss: 41.7897\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.4304 - val_loss: 44.5187\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.1746 - val_loss: 40.4096\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9862 - val_loss: 38.4766\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8729 - val_loss: 39.6358\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.6189 - val_loss: 40.2442\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9960 - val_loss: 41.5734\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0086 - val_loss: 37.5720\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.9805 - val_loss: 36.6928\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8647 - val_loss: 37.7175\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5766 - val_loss: 35.1956\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4653 - val_loss: 40.5929\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7460 - val_loss: 38.1372\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2320 - val_loss: 33.8172\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.0949 - val_loss: 35.9862\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5385 - val_loss: 35.1202\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9635 - val_loss: 36.7419\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8536 - val_loss: 33.5280\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.0951 - val_loss: 33.7012\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3123 - val_loss: 33.0709\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.8342 - val_loss: 31.5835\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5795 - val_loss: 37.6937\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1232 - val_loss: 36.4634\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.1350 - val_loss: 32.2325\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6335 - val_loss: 33.4762\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1877 - val_loss: 33.4348\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3693 - val_loss: 44.3931\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3891 - val_loss: 32.2132\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0804 - val_loss: 33.1412\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5402 - val_loss: 31.1082\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4419 - val_loss: 29.6863\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1557 - val_loss: 30.0792\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0657 - val_loss: 30.2760\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7994 - val_loss: 31.1750\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9537 - val_loss: 30.1502\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5750 - val_loss: 30.8557\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8467 - val_loss: 27.2847\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9741 - val_loss: 30.7467\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8202 - val_loss: 29.8219\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2693 - val_loss: 28.5528\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2587 - val_loss: 30.0785\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1040 - val_loss: 32.5526\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6664 - val_loss: 27.0415\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5284 - val_loss: 29.2980\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3385 - val_loss: 29.1122\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5124 - val_loss: 31.7316\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8974 - val_loss: 25.6805\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2327 - val_loss: 38.2388\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5338 - val_loss: 26.7024\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.9808 - val_loss: 27.3476\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1293 - val_loss: 25.8790\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5663 - val_loss: 26.0321\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6295 - val_loss: 25.9619\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4905 - val_loss: 26.1949\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7040 - val_loss: 25.3418\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7408 - val_loss: 26.6889\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1355 - val_loss: 25.8539\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4966 - val_loss: 24.1186\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.0516 - val_loss: 29.6527\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5145 - val_loss: 26.3654\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5723 - val_loss: 25.2876\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9141 - val_loss: 24.1679\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6290 - val_loss: 24.8193\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3618 - val_loss: 31.2641\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.0208 - val_loss: 29.3940\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3562 - val_loss: 24.5292\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8124 - val_loss: 25.3550\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8760 - val_loss: 23.8440\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0197 - val_loss: 23.8674\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7129 - val_loss: 24.8192\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3770 - val_loss: 22.8570\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3511 - val_loss: 22.1259\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.5463 - val_loss: 21.5361\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.3136 - val_loss: 24.5071\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2249 - val_loss: 22.2924\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1983 - val_loss: 22.1130\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6298 - val_loss: 32.9806\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4970 - val_loss: 24.5523\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3595 - val_loss: 23.2168\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1469 - val_loss: 23.2857\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7880 - val_loss: 20.5454\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.2648 - val_loss: 21.2968\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7776 - val_loss: 26.1933\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2610 - val_loss: 40.8664\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3438 - val_loss: 19.7736\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1885 - val_loss: 23.9531\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6669 - val_loss: 20.9501\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1888 - val_loss: 29.7344\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2983 - val_loss: 24.4891\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7450 - val_loss: 19.8960\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0723 - val_loss: 20.9874\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2186 - val_loss: 20.1115\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.5299 - val_loss: 19.8695\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.7146 - val_loss: 22.9843\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5171 - val_loss: 19.1544\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1609 - val_loss: 23.6686\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9882 - val_loss: 18.8042\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.1921 - val_loss: 19.5482\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1715 - val_loss: 19.8984\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5165 - val_loss: 19.6111\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7142 - val_loss: 20.4408\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.3805 - val_loss: 24.2119\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0424 - val_loss: 22.8766\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6365 - val_loss: 17.9602\n",
      "3/3 [==============================] - 0s 960us/step - loss: 34.0297\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 21749.9668 - val_loss: 16268.3750\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 13663.1670 - val_loss: 9867.6846\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8146.8608 - val_loss: 5538.1802\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4200.1167 - val_loss: 2321.9792\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1579.9613 - val_loss: 722.1699\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 509.7167 - val_loss: 375.3483\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 337.0375 - val_loss: 365.9404\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 289.6624 - val_loss: 280.0427\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 223.7315 - val_loss: 235.1291\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 194.6467 - val_loss: 210.5695\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 178.2791 - val_loss: 194.8795\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 163.4818 - val_loss: 184.8544\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 153.3705 - val_loss: 178.4165\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 145.7930 - val_loss: 171.6601\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 140.1784 - val_loss: 167.3767\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 134.5298 - val_loss: 161.5358\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 128.7160 - val_loss: 153.7692\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126.4630 - val_loss: 149.3693\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 121.9448 - val_loss: 145.3139\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 117.2238 - val_loss: 143.5473\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 113.3459 - val_loss: 140.6299\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 110.8794 - val_loss: 138.7111\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107.8135 - val_loss: 134.9153\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 105.1788 - val_loss: 132.3397\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 103.3933 - val_loss: 130.2907\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.3810 - val_loss: 125.6148\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.7220 - val_loss: 124.1931\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95.8627 - val_loss: 122.2454\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.6783 - val_loss: 119.4700\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.7685 - val_loss: 116.5580\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 89.6350 - val_loss: 115.8510\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.7793 - val_loss: 113.8171\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.0284 - val_loss: 111.9518\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.2711 - val_loss: 109.4850\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.4929 - val_loss: 106.4254\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.0073 - val_loss: 105.4690\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.3211 - val_loss: 104.0951\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.8693 - val_loss: 101.3397\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.5003 - val_loss: 100.3450\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.7655 - val_loss: 99.5566\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.6478 - val_loss: 98.0031\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.3335 - val_loss: 95.7236\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.5543 - val_loss: 95.4697\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7088 - val_loss: 93.0435\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.1112 - val_loss: 91.9202\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.8247 - val_loss: 91.3096\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1180 - val_loss: 91.2367\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.2844 - val_loss: 90.1768\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.2527 - val_loss: 88.2851\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3486 - val_loss: 87.3231\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7752 - val_loss: 86.3558\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3593 - val_loss: 85.1936\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6371 - val_loss: 85.9910\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3137 - val_loss: 85.8352\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4781 - val_loss: 83.6005\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6070 - val_loss: 82.8087\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.1635 - val_loss: 82.5510\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5386 - val_loss: 82.3988\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7942 - val_loss: 81.8645\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8737 - val_loss: 80.5820\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1904 - val_loss: 80.1937\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9646 - val_loss: 79.4165\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3991 - val_loss: 79.7829\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7276 - val_loss: 78.2647\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4526 - val_loss: 78.4369\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.5583 - val_loss: 78.1298\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 55.1362 - val_loss: 76.8219\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5868 - val_loss: 76.4790\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5829 - val_loss: 76.5491\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4281 - val_loss: 77.9669\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0720 - val_loss: 75.9794\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0381 - val_loss: 74.8896\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5676 - val_loss: 74.2920\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.9358 - val_loss: 75.0447\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5434 - val_loss: 73.9833\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8750 - val_loss: 73.2176\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3951 - val_loss: 72.9061\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3537 - val_loss: 72.8490\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1619 - val_loss: 72.4127\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2460 - val_loss: 72.8882\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5856 - val_loss: 71.9679\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8643 - val_loss: 71.9389\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5450 - val_loss: 71.4016\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1409 - val_loss: 70.7566\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3459 - val_loss: 70.4582\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3526 - val_loss: 71.0629\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5279 - val_loss: 70.3047\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5916 - val_loss: 69.9485\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6559 - val_loss: 69.9622\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6306 - val_loss: 69.5565\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9798 - val_loss: 69.1248\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2314 - val_loss: 69.8330\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8534 - val_loss: 69.2171\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9361 - val_loss: 68.5559\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5641 - val_loss: 68.5234\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3750 - val_loss: 68.4993\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2493 - val_loss: 67.5093\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2711 - val_loss: 67.0929\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5474 - val_loss: 67.8755\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0825 - val_loss: 66.8730\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9310 - val_loss: 66.5519\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9853 - val_loss: 67.7510\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2378 - val_loss: 70.6513\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2810 - val_loss: 66.6267\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8018 - val_loss: 65.4563\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2830 - val_loss: 65.4956\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8488 - val_loss: 64.9326\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8747 - val_loss: 64.7647\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0158 - val_loss: 64.7138\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0261 - val_loss: 64.6652\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1753 - val_loss: 65.3614\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5637 - val_loss: 64.5211\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2252 - val_loss: 65.4996\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3410 - val_loss: 64.1352\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4205 - val_loss: 63.6331\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4513 - val_loss: 63.8304\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7873 - val_loss: 65.1950\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5563 - val_loss: 63.8376\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3874 - val_loss: 63.6386\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5518 - val_loss: 64.0351\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3522 - val_loss: 62.8690\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0822 - val_loss: 63.6179\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9946 - val_loss: 62.2493\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1050 - val_loss: 61.8832\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4958 - val_loss: 61.9261\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2528 - val_loss: 61.7859\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2168 - val_loss: 62.4505\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6909 - val_loss: 61.8353\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5807 - val_loss: 61.6647\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7760 - val_loss: 61.7275\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1210 - val_loss: 61.5502\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6057 - val_loss: 60.7527\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6366 - val_loss: 61.0875\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3559 - val_loss: 60.1086\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3130 - val_loss: 60.4109\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1544 - val_loss: 60.5774\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0693 - val_loss: 60.5080\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7331 - val_loss: 60.2106\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1617 - val_loss: 59.6433\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1262 - val_loss: 61.2461\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3449 - val_loss: 59.3595\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7222 - val_loss: 59.4591\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3512 - val_loss: 59.3104\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1753 - val_loss: 59.6632\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3148 - val_loss: 59.0923\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9677 - val_loss: 59.1918\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4780 - val_loss: 60.6446\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7089 - val_loss: 62.2242\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8388 - val_loss: 59.2599\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9466 - val_loss: 59.5489\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2296 - val_loss: 57.9568\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1356 - val_loss: 58.5091\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7587 - val_loss: 57.3120\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7079 - val_loss: 57.7258\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4246 - val_loss: 57.9342\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9867 - val_loss: 56.7525\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4828 - val_loss: 56.6864\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1562 - val_loss: 56.9040\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.3344 - val_loss: 56.4830\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0988 - val_loss: 57.5682\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8636 - val_loss: 56.9311\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0306 - val_loss: 57.3523\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1163 - val_loss: 56.5252\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7349 - val_loss: 57.0286\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2520 - val_loss: 56.7951\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0352 - val_loss: 56.4838\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2306 - val_loss: 56.7551\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3142 - val_loss: 55.5790\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.0418 - val_loss: 55.8243\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2290 - val_loss: 56.7718\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7778 - val_loss: 55.4017\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0291 - val_loss: 56.6694\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2981 - val_loss: 55.5973\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7890 - val_loss: 56.1295\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8911 - val_loss: 54.8483\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6634 - val_loss: 55.6075\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9467 - val_loss: 54.9733\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8696 - val_loss: 56.0689\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6448 - val_loss: 54.2966\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1944 - val_loss: 54.8482\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9705 - val_loss: 54.2629\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8272 - val_loss: 54.9374\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6282 - val_loss: 54.9693\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4621 - val_loss: 55.0950\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2781 - val_loss: 54.4317\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1182 - val_loss: 53.4438\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1044 - val_loss: 53.7286\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8525 - val_loss: 54.1821\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7187 - val_loss: 53.8083\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0118 - val_loss: 54.1763\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7210 - val_loss: 53.8135\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3467 - val_loss: 55.4897\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8987 - val_loss: 53.7711\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2086 - val_loss: 54.2710\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9721 - val_loss: 53.3378\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7595 - val_loss: 52.7571\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6564 - val_loss: 52.6328\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6027 - val_loss: 52.7844\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1940 - val_loss: 53.3425\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2467 - val_loss: 53.4034\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 48.0079\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 888.0807 - val_loss: 562.2416\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 358.3205 - val_loss: 342.7054\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 252.3614 - val_loss: 302.4194\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 227.5070 - val_loss: 273.9514\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 201.9167 - val_loss: 250.4644\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 182.1722 - val_loss: 234.0950\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 168.4886 - val_loss: 218.0632\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 155.6404 - val_loss: 204.5240\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 143.8184 - val_loss: 191.7400\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 134.5010 - val_loss: 181.1732\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126.5919 - val_loss: 172.8283\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 118.0622 - val_loss: 163.3055\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 112.2295 - val_loss: 155.7343\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106.4199 - val_loss: 150.3088\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 101.9398 - val_loss: 144.7448\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.0936 - val_loss: 138.1315\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.2383 - val_loss: 133.3503\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 89.2679 - val_loss: 127.7332\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.5210 - val_loss: 123.9726\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.2305 - val_loss: 119.2657\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.6266 - val_loss: 115.7247\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.6742 - val_loss: 111.7013\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.7677 - val_loss: 108.5068\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.7485 - val_loss: 105.3422\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.1996 - val_loss: 102.5531\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.2832 - val_loss: 99.7195\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9425 - val_loss: 97.2010\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3806 - val_loss: 95.0105\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9913 - val_loss: 94.1123\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6791 - val_loss: 90.4154\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8023 - val_loss: 88.5176\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3926 - val_loss: 86.5650\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3526 - val_loss: 85.2187\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3107 - val_loss: 83.8667\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9290 - val_loss: 83.6030\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1713 - val_loss: 82.1408\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3108 - val_loss: 80.4750\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6141 - val_loss: 79.3803\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2201 - val_loss: 78.4074\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6837 - val_loss: 77.9513\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8674 - val_loss: 77.2570\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2879 - val_loss: 76.2757\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8912 - val_loss: 76.3997\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8498 - val_loss: 75.6510\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7116 - val_loss: 75.5775\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4325 - val_loss: 75.0517\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1351 - val_loss: 74.3559\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9428 - val_loss: 73.6799\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0186 - val_loss: 73.2811\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8260 - val_loss: 72.9378\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8465 - val_loss: 72.8743\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0930 - val_loss: 72.9476\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3108 - val_loss: 72.1081\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1426 - val_loss: 71.9566\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2503 - val_loss: 71.5976\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8763 - val_loss: 71.3923\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2959 - val_loss: 71.8237\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0723 - val_loss: 70.8243\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5690 - val_loss: 70.8980\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0651 - val_loss: 71.4322\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5518 - val_loss: 70.7088\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1272 - val_loss: 70.8552\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3928 - val_loss: 70.4049\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.7396 - val_loss: 69.9031\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7689 - val_loss: 69.8654\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6671 - val_loss: 69.4311\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5794 - val_loss: 69.1294\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6189 - val_loss: 69.1220\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8439 - val_loss: 70.0938\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3583 - val_loss: 69.2593\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.9282 - val_loss: 70.4997\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2153 - val_loss: 69.5185\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8904 - val_loss: 69.7271\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2778 - val_loss: 69.7995\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1307 - val_loss: 70.9521\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2972 - val_loss: 69.5681\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2754 - val_loss: 68.4110\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2685 - val_loss: 68.1796\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9329 - val_loss: 67.8561\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2795 - val_loss: 67.2035\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6216 - val_loss: 67.4046\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7000 - val_loss: 67.0872\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.1325 - val_loss: 68.5483\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8218 - val_loss: 70.5362\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4829 - val_loss: 67.5980\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6615 - val_loss: 67.1024\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5363 - val_loss: 66.5917\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9559 - val_loss: 65.9343\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0826 - val_loss: 66.7725\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7744 - val_loss: 65.3010\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4800 - val_loss: 65.1380\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8927 - val_loss: 67.0933\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4988 - val_loss: 64.0593\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1793 - val_loss: 64.0688\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4323 - val_loss: 63.8414\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4701 - val_loss: 63.1556\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3519 - val_loss: 62.7743\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8125 - val_loss: 63.8104\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9377 - val_loss: 62.7179\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3857 - val_loss: 61.8238\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6555 - val_loss: 61.0863\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1728 - val_loss: 60.8252\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7945 - val_loss: 60.3846\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9274 - val_loss: 60.1926\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9465 - val_loss: 65.7154\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7930 - val_loss: 60.4197\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9704 - val_loss: 58.5755\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5780 - val_loss: 58.7945\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4524 - val_loss: 57.7562\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7157 - val_loss: 58.6221\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4428 - val_loss: 59.3092\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4018 - val_loss: 58.1786\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8804 - val_loss: 56.3435\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6237 - val_loss: 57.4861\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0752 - val_loss: 57.2357\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5448 - val_loss: 55.5659\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3176 - val_loss: 57.5499\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8706 - val_loss: 57.2111\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5424 - val_loss: 56.1534\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2088 - val_loss: 57.2201\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0073 - val_loss: 54.7326\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0748 - val_loss: 55.8983\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9174 - val_loss: 54.0933\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4186 - val_loss: 54.0878\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9479 - val_loss: 52.9835\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1851 - val_loss: 55.4338\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2296 - val_loss: 55.5990\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3921 - val_loss: 53.9040\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8904 - val_loss: 52.2423\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6134 - val_loss: 52.3289\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6177 - val_loss: 51.1867\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2232 - val_loss: 50.9996\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8814 - val_loss: 50.5774\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2629 - val_loss: 50.6060\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2570 - val_loss: 49.9913\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9915 - val_loss: 49.7915\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4733 - val_loss: 49.1340\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8525 - val_loss: 48.1250\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4069 - val_loss: 46.5241\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6234 - val_loss: 47.2123\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1096 - val_loss: 46.1596\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8508 - val_loss: 45.9918\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2349 - val_loss: 44.8711\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8329 - val_loss: 45.3674\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9126 - val_loss: 44.3308\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8008 - val_loss: 45.0066\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1813 - val_loss: 46.8785\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1323 - val_loss: 43.8966\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6555 - val_loss: 46.2915\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8484 - val_loss: 42.8365\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1824 - val_loss: 45.8805\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3599 - val_loss: 43.5650\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.4165 - val_loss: 43.7677\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4070 - val_loss: 42.1241\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0420 - val_loss: 41.7315\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0986 - val_loss: 43.0961\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8359 - val_loss: 40.5777\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2209 - val_loss: 45.0114\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.0786 - val_loss: 40.3732\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6259 - val_loss: 40.7847\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6869 - val_loss: 42.8943\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4367 - val_loss: 39.3928\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0152 - val_loss: 40.5085\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1690 - val_loss: 40.1495\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3623 - val_loss: 42.1068\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0483 - val_loss: 38.6342\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0133 - val_loss: 38.2092\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.8359 - val_loss: 39.5006\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2998 - val_loss: 37.7871\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1466 - val_loss: 40.0383\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4673 - val_loss: 38.0007\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0920 - val_loss: 40.4731\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6863 - val_loss: 36.9968\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0901 - val_loss: 41.7682\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.0711 - val_loss: 37.9738\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4990 - val_loss: 43.7692\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7940 - val_loss: 37.1413\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8183 - val_loss: 38.4622\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5612 - val_loss: 38.0399\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4714 - val_loss: 40.8577\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8058 - val_loss: 38.3384\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9852 - val_loss: 39.3911\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7453 - val_loss: 36.0345\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.6396 - val_loss: 37.0510\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4420 - val_loss: 38.9844\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6723 - val_loss: 37.1925\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.1082 - val_loss: 36.3830\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2925 - val_loss: 35.8660\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9187 - val_loss: 37.1556\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7044 - val_loss: 35.5395\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2172 - val_loss: 40.2845\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3064 - val_loss: 35.8847\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7611 - val_loss: 37.6062\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4733 - val_loss: 35.4413\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4407 - val_loss: 37.8668\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 32.1693 - val_loss: 35.6194\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9656 - val_loss: 35.7006\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 32.7841 - val_loss: 41.8696\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4155 - val_loss: 36.1252\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5686 - val_loss: 36.3809\n",
      "3/3 [==============================] - 0s 865us/step - loss: 41.0160\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 201.5363 - val_loss: 101.3482\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.3366 - val_loss: 114.0099\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.8302 - val_loss: 97.7739\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.3200 - val_loss: 97.4209\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.1744 - val_loss: 97.1993\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.2317 - val_loss: 93.3587\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.1766 - val_loss: 92.5138\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.7234 - val_loss: 91.9865\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.4689 - val_loss: 91.0624\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.5882 - val_loss: 89.2951\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5262 - val_loss: 88.9178\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8704 - val_loss: 88.6334\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.1565 - val_loss: 87.2914\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.8473 - val_loss: 84.7587\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6657 - val_loss: 83.9370\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8247 - val_loss: 84.3048\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6324 - val_loss: 82.9825\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8008 - val_loss: 82.2909\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0503 - val_loss: 83.3392\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4694 - val_loss: 81.7109\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6039 - val_loss: 79.9333\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6198 - val_loss: 79.8141\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7244 - val_loss: 81.5896\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6830 - val_loss: 79.2695\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3147 - val_loss: 78.1558\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7753 - val_loss: 77.4208\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6578 - val_loss: 76.1285\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6526 - val_loss: 75.0197\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2968 - val_loss: 74.4683\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0677 - val_loss: 74.9220\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6013 - val_loss: 75.4523\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.2418 - val_loss: 74.7390\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6431 - val_loss: 72.4517\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9513 - val_loss: 72.4178\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.0271 - val_loss: 72.5219\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8267 - val_loss: 72.6454\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6177 - val_loss: 72.1050\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8222 - val_loss: 71.1430\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7488 - val_loss: 69.7196\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8752 - val_loss: 70.7375\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6211 - val_loss: 71.3341\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6682 - val_loss: 69.6379\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2484 - val_loss: 68.3851\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2926 - val_loss: 67.6986\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7566 - val_loss: 68.0524\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9124 - val_loss: 68.3058\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0524 - val_loss: 67.6598\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2004 - val_loss: 66.8790\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2400 - val_loss: 65.9391\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3375 - val_loss: 66.0635\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6491 - val_loss: 65.2180\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6497 - val_loss: 65.5615\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4417 - val_loss: 64.8046\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1447 - val_loss: 64.6740\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3983 - val_loss: 64.5435\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5063 - val_loss: 63.1724\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0490 - val_loss: 62.1068\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6396 - val_loss: 62.1279\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1081 - val_loss: 63.5073\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6600 - val_loss: 64.2571\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6437 - val_loss: 61.5209\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8802 - val_loss: 60.6649\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1628 - val_loss: 59.4520\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3727 - val_loss: 59.6472\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1710 - val_loss: 58.3093\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6343 - val_loss: 58.5499\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8968 - val_loss: 59.5986\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6261 - val_loss: 58.3181\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2541 - val_loss: 57.7736\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9381 - val_loss: 57.2137\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4855 - val_loss: 57.6875\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1728 - val_loss: 56.2432\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.2680 - val_loss: 56.6540\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4743 - val_loss: 56.1584\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3183 - val_loss: 55.5648\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1436 - val_loss: 55.0437\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8309 - val_loss: 54.2085\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8389 - val_loss: 53.2719\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1681 - val_loss: 54.2353\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3300 - val_loss: 54.3923\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4965 - val_loss: 53.3703\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4976 - val_loss: 53.1021\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2652 - val_loss: 53.4577\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0139 - val_loss: 52.3149\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2471 - val_loss: 51.1010\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6694 - val_loss: 51.5402\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4137 - val_loss: 50.0565\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6739 - val_loss: 50.5931\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9888 - val_loss: 50.4208\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4564 - val_loss: 51.1269\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9299 - val_loss: 49.4998\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.0906 - val_loss: 50.8934\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5013 - val_loss: 49.1407\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2658 - val_loss: 51.2502\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3722 - val_loss: 48.8511\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7966 - val_loss: 48.3091\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7380 - val_loss: 48.6193\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9082 - val_loss: 48.5765\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0861 - val_loss: 50.0488\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3039 - val_loss: 47.7044\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3522 - val_loss: 48.2491\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0553 - val_loss: 46.5464\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3574 - val_loss: 46.8123\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2798 - val_loss: 46.0642\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2524 - val_loss: 45.5435\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4545 - val_loss: 44.5861\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9814 - val_loss: 44.9550\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1241 - val_loss: 47.3344\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4971 - val_loss: 43.7977\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8356 - val_loss: 43.3947\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0620 - val_loss: 43.5023\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 34.4592 - val_loss: 44.7124\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9631 - val_loss: 44.8170\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7765 - val_loss: 44.7366\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1778 - val_loss: 47.1461\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0825 - val_loss: 45.2192\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1765 - val_loss: 44.8238\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7630 - val_loss: 43.8786\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1240 - val_loss: 42.0200\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2931 - val_loss: 42.1960\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.4478 - val_loss: 41.5133\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8145 - val_loss: 42.9437\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5481 - val_loss: 48.2534\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3912 - val_loss: 42.9727\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7542 - val_loss: 43.8792\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4870 - val_loss: 40.8752\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3105 - val_loss: 40.1168\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8056 - val_loss: 42.9549\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3075 - val_loss: 40.1342\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2707 - val_loss: 40.6284\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1354 - val_loss: 39.5478\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9546 - val_loss: 39.8415\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8814 - val_loss: 39.3684\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9198 - val_loss: 40.5745\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6759 - val_loss: 46.1142\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8497 - val_loss: 40.6071\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6831 - val_loss: 39.3232\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2490 - val_loss: 39.8830\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7793 - val_loss: 37.2262\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9477 - val_loss: 38.0924\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7543 - val_loss: 43.1845\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7422 - val_loss: 38.8802\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2210 - val_loss: 41.0963\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6135 - val_loss: 37.6670\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2924 - val_loss: 37.5401\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5460 - val_loss: 36.7938\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8025 - val_loss: 36.6887\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.6773 - val_loss: 36.4773\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5046 - val_loss: 36.4280\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6321 - val_loss: 37.4937\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4783 - val_loss: 37.0032\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8841 - val_loss: 36.8248\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4792 - val_loss: 37.2287\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0044 - val_loss: 37.2242\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1409 - val_loss: 37.0216\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9142 - val_loss: 36.3338\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3318 - val_loss: 35.9555\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4779 - val_loss: 36.1720\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1615 - val_loss: 35.7187\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8685 - val_loss: 35.8708\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1425 - val_loss: 38.2325\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3613 - val_loss: 34.2852\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1238 - val_loss: 34.8383\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.3449 - val_loss: 36.3683\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2279 - val_loss: 34.9087\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1460 - val_loss: 34.8133\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5036 - val_loss: 39.9635\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8399 - val_loss: 34.9591\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0944 - val_loss: 35.7808\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2251 - val_loss: 34.3731\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1447 - val_loss: 33.4939\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0337 - val_loss: 33.6870\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1292 - val_loss: 35.6451\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0279 - val_loss: 34.7896\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0335 - val_loss: 33.6870\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.9704 - val_loss: 34.2921\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8178 - val_loss: 32.6554\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3347 - val_loss: 32.9803\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1916 - val_loss: 32.5530\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3457 - val_loss: 33.8000\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0148 - val_loss: 34.7233\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5460 - val_loss: 32.4047\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7203 - val_loss: 35.0502\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3088 - val_loss: 32.6139\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.9813 - val_loss: 34.5962\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8207 - val_loss: 32.3128\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5565 - val_loss: 34.3564\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1475 - val_loss: 33.0705\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8775 - val_loss: 33.6320\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6962 - val_loss: 32.1529\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4921 - val_loss: 32.5996\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3726 - val_loss: 31.4381\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1378 - val_loss: 32.5739\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.2898 - val_loss: 31.3888\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.9668 - val_loss: 31.0162\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4602 - val_loss: 33.4056\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7171 - val_loss: 32.5391\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3546 - val_loss: 31.4292\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6824 - val_loss: 36.9371\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2220 - val_loss: 31.0944\n",
      "3/3 [==============================] - 0s 789us/step - loss: 29.4215\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1790.4487 - val_loss: 948.9998\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 590.4775 - val_loss: 322.7083\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 207.8213 - val_loss: 217.3288\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 155.7494 - val_loss: 189.0087\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 125.1921 - val_loss: 151.3299\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.6383 - val_loss: 133.6679\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 92.0211 - val_loss: 124.1309\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.2390 - val_loss: 118.2598\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.3532 - val_loss: 114.3364\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.5282 - val_loss: 111.8913\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.7398 - val_loss: 110.0500\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.9259 - val_loss: 108.0625\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.8809 - val_loss: 106.1655\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 80.0854 - val_loss: 104.2571\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.8678 - val_loss: 102.4449\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.4348 - val_loss: 100.9937\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.4889 - val_loss: 100.8311\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.9736 - val_loss: 100.4258\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.5702 - val_loss: 99.4953\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.2969 - val_loss: 98.4682\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.8736 - val_loss: 97.3376\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.5538 - val_loss: 95.1857\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.3062 - val_loss: 94.5749\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.8664 - val_loss: 94.7015\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.1533 - val_loss: 93.2941\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.9210 - val_loss: 92.2124\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.4071 - val_loss: 92.5198\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.5045 - val_loss: 91.8548\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.9281 - val_loss: 90.6022\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6212 - val_loss: 90.8856\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.7672 - val_loss: 90.4792\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.4608 - val_loss: 89.9628\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.4666 - val_loss: 89.1013\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.9217 - val_loss: 88.1901\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7219 - val_loss: 87.8721\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.2347 - val_loss: 86.9671\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7175 - val_loss: 90.7408\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.8104 - val_loss: 89.2505\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.6188 - val_loss: 88.2520\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.6776 - val_loss: 86.2124\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.2107 - val_loss: 84.6228\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.9808 - val_loss: 86.2951\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9963 - val_loss: 85.5735\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.0581 - val_loss: 89.1956\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.2889 - val_loss: 85.3887\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9906 - val_loss: 87.5524\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4919 - val_loss: 85.3958\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0054 - val_loss: 84.1979\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8496 - val_loss: 83.5126\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5122 - val_loss: 82.3085\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0991 - val_loss: 82.1838\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8017 - val_loss: 81.3096\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6915 - val_loss: 80.6347\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9382 - val_loss: 79.7126\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8695 - val_loss: 80.5778\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1726 - val_loss: 80.0438\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1833 - val_loss: 79.7636\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9928 - val_loss: 78.1785\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6836 - val_loss: 77.3561\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0336 - val_loss: 76.9538\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1841 - val_loss: 77.4022\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0049 - val_loss: 77.3951\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0043 - val_loss: 76.4044\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9439 - val_loss: 77.5492\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0539 - val_loss: 77.5222\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6288 - val_loss: 76.4435\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3805 - val_loss: 75.3755\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1063 - val_loss: 81.6537\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4391 - val_loss: 78.2461\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2383 - val_loss: 80.7551\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2843 - val_loss: 77.9455\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5288 - val_loss: 76.3153\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.7096 - val_loss: 75.9353\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3372 - val_loss: 74.4938\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1240 - val_loss: 74.0575\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6430 - val_loss: 73.8714\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7883 - val_loss: 76.0980\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7525 - val_loss: 74.2000\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1333 - val_loss: 73.3479\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7969 - val_loss: 72.5425\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5122 - val_loss: 71.7617\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3607 - val_loss: 71.9918\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3797 - val_loss: 71.4212\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0498 - val_loss: 72.0941\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6499 - val_loss: 72.2659\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3170 - val_loss: 70.7047\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7172 - val_loss: 69.7503\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0073 - val_loss: 70.8009\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5190 - val_loss: 71.0600\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0683 - val_loss: 71.5522\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0399 - val_loss: 70.1172\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0490 - val_loss: 68.9224\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7879 - val_loss: 68.3184\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2733 - val_loss: 68.4709\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8721 - val_loss: 66.7603\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3844 - val_loss: 67.7385\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1161 - val_loss: 69.4826\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8808 - val_loss: 71.3402\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9047 - val_loss: 68.1710\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0351 - val_loss: 65.8641\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7129 - val_loss: 65.5545\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.7955 - val_loss: 69.2145\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4661 - val_loss: 70.0635\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5075 - val_loss: 66.9218\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5990 - val_loss: 64.0616\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6360 - val_loss: 63.8958\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2286 - val_loss: 63.2108\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9258 - val_loss: 62.8449\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0599 - val_loss: 62.9006\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4915 - val_loss: 62.7509\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8568 - val_loss: 62.2459\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6288 - val_loss: 62.0563\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8106 - val_loss: 63.1029\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2717 - val_loss: 62.0432\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3846 - val_loss: 61.8420\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9861 - val_loss: 60.1668\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.8842 - val_loss: 60.2264\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7707 - val_loss: 60.8261\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9592 - val_loss: 59.6338\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2751 - val_loss: 59.8353\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2351 - val_loss: 60.2576\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9599 - val_loss: 59.4546\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0623 - val_loss: 59.4061\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4490 - val_loss: 59.3848\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3804 - val_loss: 57.5811\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2066 - val_loss: 57.6729\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0232 - val_loss: 58.2271\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2782 - val_loss: 57.3745\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6465 - val_loss: 57.2053\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8807 - val_loss: 56.4221\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8995 - val_loss: 55.8219\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4417 - val_loss: 55.4950\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3896 - val_loss: 56.2763\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4570 - val_loss: 54.8350\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3869 - val_loss: 53.5166\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2792 - val_loss: 53.5182\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4019 - val_loss: 54.3997\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4972 - val_loss: 54.1937\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4053 - val_loss: 52.3088\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4171 - val_loss: 52.2187\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3863 - val_loss: 52.0525\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2278 - val_loss: 53.7907\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6898 - val_loss: 53.2640\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5208 - val_loss: 52.3289\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.7812 - val_loss: 51.2705\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7874 - val_loss: 50.7209\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2001 - val_loss: 50.9437\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6063 - val_loss: 51.4013\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1046 - val_loss: 50.9232\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3726 - val_loss: 50.6268\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2602 - val_loss: 50.8741\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3095 - val_loss: 50.0695\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3658 - val_loss: 50.2850\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9527 - val_loss: 49.2932\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2033 - val_loss: 50.6228\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4178 - val_loss: 51.5915\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3804 - val_loss: 53.3990\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6550 - val_loss: 50.5792\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1136 - val_loss: 48.5140\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7221 - val_loss: 47.5316\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9323 - val_loss: 46.1995\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8496 - val_loss: 47.7003\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8922 - val_loss: 52.3539\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0561 - val_loss: 49.2646\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5616 - val_loss: 50.7458\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.4327 - val_loss: 47.3645\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5791 - val_loss: 45.5438\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3757 - val_loss: 45.0040\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1837 - val_loss: 44.5012\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5283 - val_loss: 44.0358\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3296 - val_loss: 44.7413\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1530 - val_loss: 45.9281\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7550 - val_loss: 44.5528\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1007 - val_loss: 43.6950\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9694 - val_loss: 43.0189\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8135 - val_loss: 43.7023\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2347 - val_loss: 43.7295\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0341 - val_loss: 43.4216\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3860 - val_loss: 42.8148\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7533 - val_loss: 42.5047\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0964 - val_loss: 43.1862\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2757 - val_loss: 41.2151\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7971 - val_loss: 41.3437\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0469 - val_loss: 41.1700\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.4788 - val_loss: 40.3665\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4383 - val_loss: 43.1883\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7395 - val_loss: 40.8692\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2083 - val_loss: 38.9518\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5766 - val_loss: 40.2360\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1293 - val_loss: 39.8607\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0653 - val_loss: 38.7800\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1271 - val_loss: 39.2404\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3576 - val_loss: 38.1984\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6051 - val_loss: 38.0468\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1437 - val_loss: 38.6287\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3608 - val_loss: 38.2019\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9493 - val_loss: 37.1766\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3034 - val_loss: 38.1665\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6340 - val_loss: 38.9252\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2489 - val_loss: 35.9937\n",
      "3/3 [==============================] - 0s 842us/step - loss: 18.8853\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 517.2631 - val_loss: 337.6768\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 239.6995 - val_loss: 170.4707\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 147.8001 - val_loss: 132.5853\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 127.2691 - val_loss: 121.3832\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 108.5054 - val_loss: 114.6475\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94.5269 - val_loss: 109.7422\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.3436 - val_loss: 105.5859\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.4702 - val_loss: 102.5799\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.4260 - val_loss: 98.1819\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6103 - val_loss: 97.5047\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.0281 - val_loss: 104.7546\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7569 - val_loss: 93.6520\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7652 - val_loss: 91.6806\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7081 - val_loss: 91.0685\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0773 - val_loss: 90.2308\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0412 - val_loss: 91.5967\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5933 - val_loss: 91.0401\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6573 - val_loss: 90.6124\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3643 - val_loss: 88.8407\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0163 - val_loss: 85.6891\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.8928 - val_loss: 91.1827\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0996 - val_loss: 83.8119\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7875 - val_loss: 84.8234\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5493 - val_loss: 82.7545\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9525 - val_loss: 86.5982\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9234 - val_loss: 82.1245\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1145 - val_loss: 82.0703\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3016 - val_loss: 80.2087\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9458 - val_loss: 85.4030\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6904 - val_loss: 79.3867\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2697 - val_loss: 78.4004\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1115 - val_loss: 81.0238\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3916 - val_loss: 78.7002\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1260 - val_loss: 80.0609\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3460 - val_loss: 78.1702\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2725 - val_loss: 78.2243\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7209 - val_loss: 74.8509\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5416 - val_loss: 73.6039\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3361 - val_loss: 72.6265\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6594 - val_loss: 73.0099\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7925 - val_loss: 74.9719\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6024 - val_loss: 75.1830\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9903 - val_loss: 75.0886\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1076 - val_loss: 68.4917\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8333 - val_loss: 71.6159\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2328 - val_loss: 69.6239\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8898 - val_loss: 67.8377\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9538 - val_loss: 66.0632\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1889 - val_loss: 65.7525\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3262 - val_loss: 65.9714\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3273 - val_loss: 65.5132\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.3394 - val_loss: 64.2998\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7706 - val_loss: 63.5175\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9076 - val_loss: 64.2971\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5677 - val_loss: 66.9079\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6296 - val_loss: 63.3261\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3805 - val_loss: 69.8731\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1337 - val_loss: 62.5828\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0173 - val_loss: 60.7386\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9349 - val_loss: 59.7600\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2589 - val_loss: 60.1717\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5210 - val_loss: 58.5963\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9134 - val_loss: 85.5772\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7785 - val_loss: 63.6268\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1299 - val_loss: 59.5671\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7824 - val_loss: 61.6449\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1577 - val_loss: 65.2032\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7276 - val_loss: 57.4979\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6713 - val_loss: 56.4888\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5682 - val_loss: 55.6052\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.3207 - val_loss: 58.7379\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4268 - val_loss: 53.4361\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9831 - val_loss: 52.7962\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1527 - val_loss: 55.4692\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7467 - val_loss: 60.7094\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8812 - val_loss: 63.5592\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7594 - val_loss: 51.4232\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9626 - val_loss: 49.7054\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5045 - val_loss: 52.8474\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9352 - val_loss: 50.4202\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0876 - val_loss: 49.4200\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4699 - val_loss: 51.4858\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2285 - val_loss: 47.6959\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5253 - val_loss: 51.8293\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8011 - val_loss: 50.1569\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7480 - val_loss: 49.0597\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0083 - val_loss: 47.8197\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2675 - val_loss: 53.2752\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3186 - val_loss: 49.7077\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2533 - val_loss: 47.9231\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2984 - val_loss: 47.2379\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1013 - val_loss: 56.6403\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5360 - val_loss: 48.9009\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0499 - val_loss: 50.9131\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2436 - val_loss: 49.3543\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4765 - val_loss: 43.9291\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2964 - val_loss: 45.5097\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5380 - val_loss: 46.7124\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.0704 - val_loss: 56.0810\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7611 - val_loss: 47.6447\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8525 - val_loss: 45.6473\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5925 - val_loss: 43.8582\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3937 - val_loss: 43.7677\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6812 - val_loss: 43.3285\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7669 - val_loss: 42.2358\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8854 - val_loss: 45.1590\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.3051 - val_loss: 44.4867\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0950 - val_loss: 44.3653\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8312 - val_loss: 41.9893\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6469 - val_loss: 41.8113\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5140 - val_loss: 39.9660\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0153 - val_loss: 46.8874\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8116 - val_loss: 44.5587\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2180 - val_loss: 49.5716\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0459 - val_loss: 40.4363\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9911 - val_loss: 40.8933\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8190 - val_loss: 40.6266\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.3388 - val_loss: 43.9154\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0530 - val_loss: 45.1853\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0641 - val_loss: 47.1679\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6957 - val_loss: 39.6009\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7541 - val_loss: 40.5326\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2318 - val_loss: 43.5062\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8564 - val_loss: 61.9245\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.5961 - val_loss: 45.7880\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8483 - val_loss: 40.5870\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0784 - val_loss: 40.0379\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.0277 - val_loss: 40.2143\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2568 - val_loss: 38.5899\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0959 - val_loss: 42.4338\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8717 - val_loss: 39.5436\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1084 - val_loss: 37.8960\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7841 - val_loss: 40.3713\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7403 - val_loss: 37.8949\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9800 - val_loss: 40.2725\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9923 - val_loss: 42.8738\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.4327 - val_loss: 37.4855\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4278 - val_loss: 38.0628\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0842 - val_loss: 41.4298\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6640 - val_loss: 40.6370\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3379 - val_loss: 42.5248\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2965 - val_loss: 40.0336\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4543 - val_loss: 37.7104\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5871 - val_loss: 44.7701\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5034 - val_loss: 42.0814\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9523 - val_loss: 51.8151\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.4530 - val_loss: 48.0082\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2152 - val_loss: 53.6617\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9532 - val_loss: 38.3429\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2772 - val_loss: 36.7508\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1449 - val_loss: 49.6126\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6627 - val_loss: 35.3425\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1667 - val_loss: 40.3818\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7927 - val_loss: 47.1191\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9935 - val_loss: 41.6210\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5670 - val_loss: 36.7637\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 27.0733 - val_loss: 35.8749\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7890 - val_loss: 37.3839\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9068 - val_loss: 38.8509\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0217 - val_loss: 36.5405\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6220 - val_loss: 40.1114\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2591 - val_loss: 35.5580\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3823 - val_loss: 34.5913\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8730 - val_loss: 35.0456\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1348 - val_loss: 35.6593\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8009 - val_loss: 35.1943\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0205 - val_loss: 34.8288\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2687 - val_loss: 39.1326\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4464 - val_loss: 34.4237\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3427 - val_loss: 46.8771\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1142 - val_loss: 41.3177\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4124 - val_loss: 37.8121\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5066 - val_loss: 36.3929\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3497 - val_loss: 35.3396\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5339 - val_loss: 37.1679\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2684 - val_loss: 38.7154\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8329 - val_loss: 34.2370\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5921 - val_loss: 34.3154\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8778 - val_loss: 36.3774\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8335 - val_loss: 35.7897\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6317 - val_loss: 34.9328\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6669 - val_loss: 34.3231\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7138 - val_loss: 35.5449\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3569 - val_loss: 34.0541\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6346 - val_loss: 50.2920\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6043 - val_loss: 35.7631\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0399 - val_loss: 35.2996\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2057 - val_loss: 33.7302\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5735 - val_loss: 40.0228\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2479 - val_loss: 33.8843\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3377 - val_loss: 36.4729\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8834 - val_loss: 40.1777\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7483 - val_loss: 35.6128\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6613 - val_loss: 33.5136\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9026 - val_loss: 44.6911\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1305 - val_loss: 37.0634\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0074 - val_loss: 32.7069\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3514 - val_loss: 34.8580\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7682 - val_loss: 35.3837\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2484 - val_loss: 33.3129\n",
      "3/3 [==============================] - 0s 866us/step - loss: 43.1262\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 524.9843 - val_loss: 213.2477\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 137.2395 - val_loss: 122.0305\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.7022 - val_loss: 102.2776\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.5652 - val_loss: 84.6120\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4738 - val_loss: 77.7869\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7822 - val_loss: 78.7467\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0489 - val_loss: 76.1793\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8910 - val_loss: 72.3245\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2211 - val_loss: 84.4425\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0556 - val_loss: 71.1151\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0975 - val_loss: 69.2267\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1642 - val_loss: 69.2869\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0100 - val_loss: 67.9997\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7336 - val_loss: 64.6861\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5722 - val_loss: 66.0030\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4945 - val_loss: 66.8634\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3510 - val_loss: 62.5690\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2558 - val_loss: 59.8883\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3981 - val_loss: 64.8833\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0630 - val_loss: 61.5454\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7451 - val_loss: 55.3398\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0472 - val_loss: 58.5458\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1352 - val_loss: 62.3326\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5143 - val_loss: 59.3979\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4260 - val_loss: 54.4292\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7892 - val_loss: 53.1872\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3869 - val_loss: 64.5598\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7068 - val_loss: 54.8593\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.3984 - val_loss: 51.1646\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6545 - val_loss: 58.2373\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6919 - val_loss: 53.0155\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1304 - val_loss: 53.1121\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6005 - val_loss: 49.5346\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.5351 - val_loss: 51.6894\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5406 - val_loss: 65.8160\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8350 - val_loss: 50.0920\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.8707 - val_loss: 48.8859\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1762 - val_loss: 47.4322\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.8739 - val_loss: 60.2169\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2305 - val_loss: 51.6624\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9989 - val_loss: 57.2416\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9924 - val_loss: 48.1191\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7874 - val_loss: 45.2462\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5602 - val_loss: 50.8151\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4434 - val_loss: 44.5606\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.2615 - val_loss: 41.6830\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3588 - val_loss: 43.7530\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4780 - val_loss: 51.7895\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6523 - val_loss: 48.3123\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1113 - val_loss: 43.9876\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.8693 - val_loss: 42.7904\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4420 - val_loss: 39.3969\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.6754 - val_loss: 44.5623\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.6719 - val_loss: 38.8442\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5748 - val_loss: 48.1512\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4752 - val_loss: 36.0136\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8982 - val_loss: 37.8443\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8800 - val_loss: 48.3273\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.4770 - val_loss: 44.2634\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.4515 - val_loss: 35.5921\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9138 - val_loss: 34.1083\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2323 - val_loss: 34.2074\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.4550 - val_loss: 34.4462\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.4750 - val_loss: 36.6023\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1683 - val_loss: 39.8053\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.3793 - val_loss: 36.8738\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3029 - val_loss: 33.9514\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5812 - val_loss: 36.1868\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.6696 - val_loss: 35.2593\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2950 - val_loss: 39.9802\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2023 - val_loss: 33.8568\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5842 - val_loss: 42.9983\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1747 - val_loss: 34.0124\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8671 - val_loss: 39.2291\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.7316 - val_loss: 42.5686\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5059 - val_loss: 34.8106\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.7829 - val_loss: 33.6305\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8125 - val_loss: 33.8861\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1152 - val_loss: 31.1320\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3999 - val_loss: 30.3405\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1047 - val_loss: 39.2443\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6089 - val_loss: 29.2316\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.6969 - val_loss: 44.4041\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.1529 - val_loss: 45.1218\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.5649 - val_loss: 40.2231\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8290 - val_loss: 27.5664\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2108 - val_loss: 27.1173\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7322 - val_loss: 28.1769\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2092 - val_loss: 24.7500\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2901 - val_loss: 27.1604\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4196 - val_loss: 31.3376\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5135 - val_loss: 27.1133\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4592 - val_loss: 28.9779\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.5063 - val_loss: 30.6942\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5323 - val_loss: 35.9254\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2141 - val_loss: 28.0685\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.6878 - val_loss: 25.2016\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9671 - val_loss: 26.1493\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3705 - val_loss: 30.1038\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6016 - val_loss: 32.6188\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8809 - val_loss: 24.7588\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.8804 - val_loss: 29.8294\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3614 - val_loss: 27.2484\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2597 - val_loss: 24.3304\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0531 - val_loss: 26.3817\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9526 - val_loss: 24.7029\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4698 - val_loss: 26.0272\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1374 - val_loss: 23.6384\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3118 - val_loss: 30.7606\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.2098 - val_loss: 22.7020\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4482 - val_loss: 22.2467\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3759 - val_loss: 21.1708\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.9987 - val_loss: 23.5037\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6829 - val_loss: 31.5711\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8897 - val_loss: 37.4050\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3678 - val_loss: 31.7067\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3381 - val_loss: 22.7749\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0988 - val_loss: 25.6180\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.6442 - val_loss: 28.3423\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8560 - val_loss: 35.1393\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4876 - val_loss: 32.4079\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9156 - val_loss: 38.5234\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4020 - val_loss: 32.2897\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0273 - val_loss: 26.3285\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2505 - val_loss: 24.5125\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.8167 - val_loss: 23.5213\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.2301 - val_loss: 22.9079\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.0164 - val_loss: 27.7484\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9800 - val_loss: 27.0315\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3090 - val_loss: 28.1017\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6274 - val_loss: 22.1911\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7008 - val_loss: 21.4671\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4429 - val_loss: 23.5237\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.5285 - val_loss: 25.4141\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8513 - val_loss: 22.4101\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.7509 - val_loss: 30.8284\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2431 - val_loss: 22.1144\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1493 - val_loss: 23.6389\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2576 - val_loss: 31.4181\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3387 - val_loss: 26.5169\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6006 - val_loss: 23.5674\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1090 - val_loss: 23.4210\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8318 - val_loss: 20.6414\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3914 - val_loss: 25.4441\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5070 - val_loss: 22.2700\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1713 - val_loss: 27.3238\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9076 - val_loss: 20.7915\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.0466 - val_loss: 22.4141\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9315 - val_loss: 23.5030\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3088 - val_loss: 21.0172\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.2754 - val_loss: 21.3357\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3883 - val_loss: 20.0746\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.8079 - val_loss: 20.9959\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.7204 - val_loss: 31.0149\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.4568 - val_loss: 19.2984\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0624 - val_loss: 42.7327\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5081 - val_loss: 32.8457\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8086 - val_loss: 22.3263\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3042 - val_loss: 22.1206\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9395 - val_loss: 23.1789\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.2209 - val_loss: 21.0843\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.3776 - val_loss: 20.4785\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.2319 - val_loss: 22.0298\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.2031 - val_loss: 22.3862\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6701 - val_loss: 19.9343\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.7052 - val_loss: 24.1679\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.8365 - val_loss: 29.1412\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6678 - val_loss: 21.8899\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9859 - val_loss: 21.2928\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.7835 - val_loss: 21.1451\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.3947 - val_loss: 24.0407\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1004 - val_loss: 21.2753\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.8231 - val_loss: 21.8301\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.0701 - val_loss: 20.8957\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.8860 - val_loss: 21.8865\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.6576 - val_loss: 22.8662\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6007 - val_loss: 30.6653\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1658 - val_loss: 23.8804\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.3224 - val_loss: 53.8610\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.6888 - val_loss: 26.9315\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1903 - val_loss: 24.5157\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7918 - val_loss: 18.7299\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.8128 - val_loss: 20.5664\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6112 - val_loss: 22.7545\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.0526 - val_loss: 21.9533\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9400 - val_loss: 22.2457\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3104 - val_loss: 25.3298\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.7612 - val_loss: 21.7025\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8395 - val_loss: 20.3849\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.9034 - val_loss: 20.2875\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.2086 - val_loss: 23.5814\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9095 - val_loss: 25.1611\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6581 - val_loss: 24.6048\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0706 - val_loss: 53.7890\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4607 - val_loss: 31.9458\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6823 - val_loss: 30.1483\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.0141 - val_loss: 37.5798\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7229 - val_loss: 28.3657\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.1464 - val_loss: 24.5292\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3895 - val_loss: 25.3791\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 31.5923\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 467.6720 - val_loss: 116.8193\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 89.0395 - val_loss: 102.2033\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.2995 - val_loss: 93.0407\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 61.5814 - val_loss: 81.4510\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3813 - val_loss: 79.7977\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3847 - val_loss: 76.8113\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.3992 - val_loss: 74.4430\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5906 - val_loss: 76.0972\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0733 - val_loss: 82.7421\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1889 - val_loss: 74.0513\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.9564 - val_loss: 84.4009\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.2779 - val_loss: 86.7459\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7973 - val_loss: 73.1039\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.9024 - val_loss: 72.9296\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2368 - val_loss: 72.0247\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 55.8641 - val_loss: 70.6843\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5185 - val_loss: 81.3210\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4591 - val_loss: 71.5976\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7600 - val_loss: 72.9884\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2278 - val_loss: 71.2252\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1332 - val_loss: 68.7834\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.4615 - val_loss: 69.6056\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0242 - val_loss: 68.5852\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7003 - val_loss: 78.6827\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.7742 - val_loss: 83.4376\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3465 - val_loss: 77.7674\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.8350 - val_loss: 76.6695\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8090 - val_loss: 65.7119\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.0277 - val_loss: 65.4862\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2008 - val_loss: 68.4084\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1330 - val_loss: 66.0468\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0543 - val_loss: 82.6756\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7484 - val_loss: 67.7910\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9556 - val_loss: 65.4358\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7364 - val_loss: 65.9632\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9689 - val_loss: 69.7435\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8684 - val_loss: 61.6904\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4976 - val_loss: 59.8069\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1354 - val_loss: 62.9324\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.8322 - val_loss: 60.5182\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0747 - val_loss: 59.7683\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.8168 - val_loss: 59.2554\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6623 - val_loss: 54.8463\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6666 - val_loss: 54.0492\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.3253 - val_loss: 61.3168\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.5871 - val_loss: 52.6797\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1376 - val_loss: 51.4158\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5131 - val_loss: 50.3778\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9861 - val_loss: 51.3961\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1512 - val_loss: 51.6280\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.3546 - val_loss: 50.5722\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5050 - val_loss: 50.6400\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6163 - val_loss: 44.2261\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1681 - val_loss: 61.7241\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.5007 - val_loss: 68.0728\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1699 - val_loss: 74.6932\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3508 - val_loss: 49.3133\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.7602 - val_loss: 41.8740\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2305 - val_loss: 43.0085\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8879 - val_loss: 45.2316\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1269 - val_loss: 41.8407\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4900 - val_loss: 45.8983\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0911 - val_loss: 67.8577\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.1669 - val_loss: 42.6123\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8309 - val_loss: 38.6841\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6385 - val_loss: 37.8094\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5149 - val_loss: 44.9095\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8739 - val_loss: 61.8797\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1276 - val_loss: 37.0682\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.4189 - val_loss: 42.9719\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1374 - val_loss: 44.8007\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2629 - val_loss: 35.8867\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7042 - val_loss: 35.5380\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5067 - val_loss: 34.1365\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8428 - val_loss: 35.0988\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2757 - val_loss: 35.0929\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.7297 - val_loss: 35.9709\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6830 - val_loss: 34.2724\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8590 - val_loss: 32.7395\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2100 - val_loss: 30.5861\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0110 - val_loss: 34.7542\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 26.7436 - val_loss: 31.6957\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7718 - val_loss: 31.3507\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6959 - val_loss: 31.5408\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4450 - val_loss: 41.0788\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8756 - val_loss: 31.1322\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7373 - val_loss: 29.2558\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9518 - val_loss: 38.5137\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1753 - val_loss: 55.6488\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7132 - val_loss: 37.6876\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.0922 - val_loss: 30.4313\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.9725 - val_loss: 32.1047\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1417 - val_loss: 43.5422\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.0290 - val_loss: 48.4561\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1784 - val_loss: 46.2342\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.9005 - val_loss: 33.0821\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6512 - val_loss: 29.3329\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.7686 - val_loss: 32.9905\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4142 - val_loss: 27.6543\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8006 - val_loss: 27.3177\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.6196 - val_loss: 31.0622\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.4330 - val_loss: 48.3863\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.5310 - val_loss: 64.3172\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.1087 - val_loss: 68.2560\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2671 - val_loss: 33.7646\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5738 - val_loss: 39.7037\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2694 - val_loss: 30.8424\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4536 - val_loss: 27.7340\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9397 - val_loss: 27.5660\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8125 - val_loss: 27.0628\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4999 - val_loss: 25.8261\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.9701 - val_loss: 29.2073\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.8802 - val_loss: 32.8434\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5889 - val_loss: 26.3673\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3874 - val_loss: 26.7311\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.2279 - val_loss: 38.0192\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5028 - val_loss: 29.8895\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.0945 - val_loss: 26.7982\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7812 - val_loss: 26.8915\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5419 - val_loss: 25.4414\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7204 - val_loss: 25.7507\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1564 - val_loss: 25.9993\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6699 - val_loss: 23.0497\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6584 - val_loss: 22.1366\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5176 - val_loss: 24.0401\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6764 - val_loss: 24.6076\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.4720 - val_loss: 28.1211\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6019 - val_loss: 22.3082\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9063 - val_loss: 29.4523\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7771 - val_loss: 48.9331\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4701 - val_loss: 50.8285\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9946 - val_loss: 63.2424\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0824 - val_loss: 25.9363\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3620 - val_loss: 23.5366\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4056 - val_loss: 24.6304\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8900 - val_loss: 23.8706\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8648 - val_loss: 21.6851\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2617 - val_loss: 20.9650\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2155 - val_loss: 25.5592\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4244 - val_loss: 23.3104\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3107 - val_loss: 34.4945\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2277 - val_loss: 21.8202\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3200 - val_loss: 26.3241\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2862 - val_loss: 31.0251\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2940 - val_loss: 38.0247\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.9503 - val_loss: 20.9320\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5867 - val_loss: 21.2469\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5040 - val_loss: 24.6893\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0390 - val_loss: 26.9037\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5646 - val_loss: 20.7580\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9894 - val_loss: 22.4971\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5343 - val_loss: 22.6584\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2124 - val_loss: 21.1142\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9164 - val_loss: 32.1537\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7921 - val_loss: 21.7180\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1427 - val_loss: 27.9657\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0648 - val_loss: 25.4026\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6282 - val_loss: 19.0854\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.8098 - val_loss: 19.2115\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1034 - val_loss: 21.2243\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1346 - val_loss: 48.9645\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1480 - val_loss: 41.0030\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7031 - val_loss: 27.9584\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.4646 - val_loss: 26.9949\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.9266 - val_loss: 20.8861\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4073 - val_loss: 25.0126\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4808 - val_loss: 19.8124\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.6794 - val_loss: 19.1182\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.8852 - val_loss: 22.6311\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1379 - val_loss: 18.0379\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7862 - val_loss: 18.4313\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5572 - val_loss: 19.5348\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.6358 - val_loss: 21.0373\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.1073 - val_loss: 19.9609\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6831 - val_loss: 22.0638\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5221 - val_loss: 18.3940\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9381 - val_loss: 20.6447\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 18.3594 - val_loss: 25.2791\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0954 - val_loss: 23.0128\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4965 - val_loss: 24.7427\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4105 - val_loss: 24.8155\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7918 - val_loss: 17.8119\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7343 - val_loss: 19.8801\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.3493 - val_loss: 18.6606\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.9441 - val_loss: 23.4016\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6092 - val_loss: 18.1029\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1040 - val_loss: 19.3785\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5918 - val_loss: 23.9889\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7269 - val_loss: 27.2182\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2718 - val_loss: 21.9419\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2572 - val_loss: 17.7887\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4054 - val_loss: 25.3235\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0846 - val_loss: 20.6898\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2005 - val_loss: 32.9784\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7148 - val_loss: 35.8882\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.9630 - val_loss: 34.2307\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9810 - val_loss: 18.4966\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.7795 - val_loss: 31.6025\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0766 - val_loss: 27.7926\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1586 - val_loss: 19.3207\n",
      "3/3 [==============================] - 0s 968us/step - loss: 23.9018\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 451.9093 - val_loss: 337.3160\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 182.4338 - val_loss: 104.9497\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.7495 - val_loss: 91.3414\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.4133 - val_loss: 78.0981\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.1775 - val_loss: 74.8014\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4957 - val_loss: 75.3340\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.7063 - val_loss: 76.5964\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.1062 - val_loss: 73.8736\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2012 - val_loss: 73.2968\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4107 - val_loss: 76.3327\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3473 - val_loss: 74.0683\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1847 - val_loss: 73.0162\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.3280 - val_loss: 71.5994\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1846 - val_loss: 72.7041\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3031 - val_loss: 72.3490\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4505 - val_loss: 68.4997\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9948 - val_loss: 73.6388\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9940 - val_loss: 71.5208\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9278 - val_loss: 69.2677\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9991 - val_loss: 69.3998\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.7376 - val_loss: 68.2891\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6927 - val_loss: 69.1095\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8712 - val_loss: 68.5499\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8678 - val_loss: 69.7371\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.4450 - val_loss: 69.5595\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.0905 - val_loss: 70.7874\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4137 - val_loss: 64.2324\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1548 - val_loss: 68.5151\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8075 - val_loss: 71.6675\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0947 - val_loss: 66.6975\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8354 - val_loss: 63.3603\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1080 - val_loss: 67.6558\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5822 - val_loss: 63.9933\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5568 - val_loss: 64.1073\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8812 - val_loss: 64.0550\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2146 - val_loss: 69.1106\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3934 - val_loss: 65.4430\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3167 - val_loss: 64.5054\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8182 - val_loss: 62.9552\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1862 - val_loss: 79.3522\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5917 - val_loss: 66.0859\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6907 - val_loss: 62.5782\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5073 - val_loss: 74.3962\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8690 - val_loss: 64.0993\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0685 - val_loss: 60.6288\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5407 - val_loss: 61.3078\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9853 - val_loss: 62.9848\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4776 - val_loss: 60.3229\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.9026 - val_loss: 59.2027\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.0443 - val_loss: 65.1720\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5765 - val_loss: 65.3418\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0495 - val_loss: 58.5973\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3038 - val_loss: 61.2449\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9064 - val_loss: 61.1580\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6299 - val_loss: 57.3879\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6996 - val_loss: 57.8130\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7476 - val_loss: 57.1400\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4660 - val_loss: 62.6000\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.8329 - val_loss: 57.2817\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6330 - val_loss: 56.0985\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1172 - val_loss: 67.9860\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1877 - val_loss: 55.7473\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0627 - val_loss: 55.9644\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6686 - val_loss: 52.6065\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4861 - val_loss: 61.6894\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.5425 - val_loss: 52.3179\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.1337 - val_loss: 55.5307\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4140 - val_loss: 52.5432\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0157 - val_loss: 55.9487\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6494 - val_loss: 50.7864\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.8123 - val_loss: 49.1158\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6751 - val_loss: 48.5062\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2244 - val_loss: 49.5233\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0431 - val_loss: 53.2597\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6537 - val_loss: 51.8566\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2093 - val_loss: 45.7973\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1475 - val_loss: 45.6378\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6038 - val_loss: 45.1566\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.2334 - val_loss: 44.0272\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7469 - val_loss: 45.0514\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3248 - val_loss: 49.1449\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8543 - val_loss: 48.0010\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9171 - val_loss: 47.8808\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9607 - val_loss: 61.6986\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8960 - val_loss: 42.6388\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1881 - val_loss: 44.3930\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.3493 - val_loss: 51.1639\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3378 - val_loss: 42.5597\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9462 - val_loss: 53.5080\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2617 - val_loss: 41.8607\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1995 - val_loss: 41.1948\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2322 - val_loss: 41.4524\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6483 - val_loss: 40.2288\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2491 - val_loss: 43.9460\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2797 - val_loss: 41.0620\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.9586 - val_loss: 41.4365\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.3037 - val_loss: 39.1130\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7581 - val_loss: 37.2575\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0266 - val_loss: 39.5379\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8907 - val_loss: 42.1958\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0546 - val_loss: 40.8838\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2200 - val_loss: 37.3587\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.3780 - val_loss: 38.0792\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.7220 - val_loss: 33.1311\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.2934 - val_loss: 35.3262\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.6044 - val_loss: 32.4790\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5297 - val_loss: 32.5772\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.7742 - val_loss: 46.6433\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.3909 - val_loss: 44.3175\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5657 - val_loss: 30.9526\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.3150 - val_loss: 36.8430\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.3362 - val_loss: 31.2964\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4074 - val_loss: 34.5249\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8129 - val_loss: 29.0217\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.0393 - val_loss: 33.2689\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9527 - val_loss: 29.1353\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.0528 - val_loss: 31.8319\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2934 - val_loss: 44.8115\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4609 - val_loss: 38.0706\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1308 - val_loss: 28.8210\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3910 - val_loss: 30.3582\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3348 - val_loss: 31.5028\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.1457 - val_loss: 34.9478\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5530 - val_loss: 29.3738\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8408 - val_loss: 27.7140\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9980 - val_loss: 26.7135\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2631 - val_loss: 26.1092\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7658 - val_loss: 26.3549\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8772 - val_loss: 26.3769\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3215 - val_loss: 33.4337\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8523 - val_loss: 32.0730\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1622 - val_loss: 39.3445\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.3208 - val_loss: 31.8435\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0384 - val_loss: 34.8823\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1582 - val_loss: 33.6990\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5283 - val_loss: 32.5154\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0494 - val_loss: 30.8509\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8024 - val_loss: 24.8618\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3568 - val_loss: 23.9597\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1973 - val_loss: 25.1658\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6885 - val_loss: 33.5301\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6199 - val_loss: 26.7692\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7063 - val_loss: 23.7019\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1413 - val_loss: 29.6270\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6465 - val_loss: 28.4446\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.4490 - val_loss: 30.1086\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2308 - val_loss: 32.2749\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6408 - val_loss: 29.9406\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2635 - val_loss: 27.2406\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5418 - val_loss: 22.9976\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9376 - val_loss: 23.0906\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7099 - val_loss: 25.2503\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1917 - val_loss: 24.7459\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4402 - val_loss: 29.5414\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1853 - val_loss: 25.1757\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6728 - val_loss: 24.3837\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7675 - val_loss: 21.6273\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3881 - val_loss: 24.4802\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4700 - val_loss: 28.0066\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4913 - val_loss: 48.1511\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6348 - val_loss: 59.7697\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1127 - val_loss: 47.4124\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.0361 - val_loss: 27.1873\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.2717 - val_loss: 29.3484\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8341 - val_loss: 23.2811\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5522 - val_loss: 41.5579\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4612 - val_loss: 36.2927\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4259 - val_loss: 25.8441\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4530 - val_loss: 22.9228\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9723 - val_loss: 21.1842\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7369 - val_loss: 32.7393\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1993 - val_loss: 36.5004\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2607 - val_loss: 22.0597\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6355 - val_loss: 24.4403\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9725 - val_loss: 25.0558\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3589 - val_loss: 23.7261\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7091 - val_loss: 23.8953\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1930 - val_loss: 25.2990\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5423 - val_loss: 21.6227\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.7541 - val_loss: 36.5142\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7295 - val_loss: 29.3384\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3473 - val_loss: 21.3041\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4853 - val_loss: 21.7352\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.8015 - val_loss: 20.4357\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.8386 - val_loss: 19.9529\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.0825 - val_loss: 26.9897\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0501 - val_loss: 20.8429\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5005 - val_loss: 22.3107\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4784 - val_loss: 22.8787\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9953 - val_loss: 27.3754\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9021 - val_loss: 27.0551\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.0706 - val_loss: 19.1238\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4073 - val_loss: 23.7210\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6855 - val_loss: 22.3137\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4320 - val_loss: 20.2462\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6441 - val_loss: 19.3809\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4021 - val_loss: 20.3161\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.0784 - val_loss: 23.0341\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.7335 - val_loss: 22.3518\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3098 - val_loss: 39.1900\n",
      "3/3 [==============================] - 0s 913us/step - loss: 25.4923\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 227.2249 - val_loss: 119.4412\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.6432 - val_loss: 98.2917\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 77.9787 - val_loss: 93.1195\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.2729 - val_loss: 90.3155\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.5960 - val_loss: 86.3308\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.4631 - val_loss: 82.3037\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.5162 - val_loss: 81.2272\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.2966 - val_loss: 84.0365\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2262 - val_loss: 81.5431\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2367 - val_loss: 78.5406\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.5291 - val_loss: 80.7087\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2550 - val_loss: 80.3760\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6200 - val_loss: 78.7003\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9455 - val_loss: 75.5339\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0496 - val_loss: 80.1396\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.9290 - val_loss: 78.4957\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2963 - val_loss: 75.9099\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.2090 - val_loss: 77.7361\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0354 - val_loss: 75.9357\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0648 - val_loss: 75.4457\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9024 - val_loss: 70.8924\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7204 - val_loss: 77.7534\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3568 - val_loss: 79.0836\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6419 - val_loss: 81.7340\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0502 - val_loss: 71.0447\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0177 - val_loss: 74.5295\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1487 - val_loss: 73.8806\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.2605 - val_loss: 70.2902\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1551 - val_loss: 72.1482\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6667 - val_loss: 85.3710\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3115 - val_loss: 65.1571\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1782 - val_loss: 66.0140\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8483 - val_loss: 72.0323\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0909 - val_loss: 63.1320\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5817 - val_loss: 68.0123\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8918 - val_loss: 63.1146\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0056 - val_loss: 64.0067\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7105 - val_loss: 70.7182\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3904 - val_loss: 65.3212\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.6237 - val_loss: 63.2860\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4483 - val_loss: 58.7605\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.8025 - val_loss: 60.7163\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7217 - val_loss: 59.5392\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3904 - val_loss: 54.0398\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2631 - val_loss: 54.9714\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8009 - val_loss: 54.6158\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2333 - val_loss: 54.3897\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0701 - val_loss: 66.1893\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8231 - val_loss: 48.0965\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4745 - val_loss: 52.6066\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5524 - val_loss: 50.8762\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6255 - val_loss: 45.8228\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.3348 - val_loss: 60.4375\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8553 - val_loss: 45.4304\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4401 - val_loss: 50.2523\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.3617 - val_loss: 49.9566\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2567 - val_loss: 45.4200\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1826 - val_loss: 50.4841\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2852 - val_loss: 62.4069\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4857 - val_loss: 48.6631\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2296 - val_loss: 48.5765\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6759 - val_loss: 42.1845\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0037 - val_loss: 43.2533\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.4681 - val_loss: 39.0699\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.0503 - val_loss: 56.3039\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2225 - val_loss: 38.0347\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8267 - val_loss: 41.3487\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0789 - val_loss: 46.3262\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8584 - val_loss: 48.8606\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9846 - val_loss: 41.3306\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3207 - val_loss: 37.6733\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7618 - val_loss: 34.5598\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8833 - val_loss: 30.9534\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.3696 - val_loss: 39.0907\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7528 - val_loss: 50.4650\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5008 - val_loss: 48.2420\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0627 - val_loss: 41.0795\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4365 - val_loss: 36.0818\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1990 - val_loss: 34.9850\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0802 - val_loss: 29.3908\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.4279 - val_loss: 30.1730\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0648 - val_loss: 31.4680\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 24.0526 - val_loss: 26.2986\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0375 - val_loss: 28.7535\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5093 - val_loss: 29.4414\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7289 - val_loss: 24.8093\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1454 - val_loss: 25.3069\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.8900 - val_loss: 25.9607\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.8292 - val_loss: 25.1613\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8423 - val_loss: 28.4265\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0091 - val_loss: 23.9803\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2988 - val_loss: 25.7538\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5385 - val_loss: 25.7622\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.9495 - val_loss: 24.2941\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.1990 - val_loss: 26.1143\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7275 - val_loss: 22.4446\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4694 - val_loss: 23.3959\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8229 - val_loss: 34.5727\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.9090 - val_loss: 37.2726\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9434 - val_loss: 33.0312\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.7714 - val_loss: 37.4586\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2584 - val_loss: 24.4824\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7060 - val_loss: 22.1866\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0420 - val_loss: 23.5520\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4531 - val_loss: 35.1326\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0531 - val_loss: 27.6436\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4449 - val_loss: 36.5994\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5142 - val_loss: 24.7026\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5104 - val_loss: 28.0656\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.6643 - val_loss: 25.3220\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1037 - val_loss: 26.7252\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1684 - val_loss: 24.8392\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5295 - val_loss: 27.9571\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5818 - val_loss: 22.6432\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4272 - val_loss: 22.9961\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.0357 - val_loss: 25.1965\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5149 - val_loss: 25.2061\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.7291 - val_loss: 20.4071\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3974 - val_loss: 24.9001\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2781 - val_loss: 19.0677\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4401 - val_loss: 26.8669\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5498 - val_loss: 35.1425\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7665 - val_loss: 32.3617\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.9041 - val_loss: 28.2376\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1361 - val_loss: 21.3225\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9950 - val_loss: 21.9850\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5642 - val_loss: 21.9378\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8027 - val_loss: 21.4771\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5872 - val_loss: 22.3256\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7923 - val_loss: 18.5371\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3564 - val_loss: 24.4803\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.1726 - val_loss: 22.3904\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.0040 - val_loss: 19.0439\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5987 - val_loss: 20.3841\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8789 - val_loss: 20.2895\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3571 - val_loss: 20.5702\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.9398 - val_loss: 21.8501\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6345 - val_loss: 22.6820\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8598 - val_loss: 20.2212\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.1024 - val_loss: 23.5660\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 18.0292 - val_loss: 18.3851\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1381 - val_loss: 22.6616\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3529 - val_loss: 23.5587\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2489 - val_loss: 24.2052\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.5237 - val_loss: 27.6907\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1559 - val_loss: 26.3350\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0855 - val_loss: 22.9672\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5215 - val_loss: 22.8665\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9612 - val_loss: 19.9527\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1364 - val_loss: 21.0218\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3606 - val_loss: 33.7341\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4946 - val_loss: 20.8244\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3608 - val_loss: 24.1955\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.4367 - val_loss: 18.1954\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1852 - val_loss: 19.7953\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9659 - val_loss: 15.6764\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9129 - val_loss: 20.0689\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9595 - val_loss: 31.0031\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5715 - val_loss: 34.4161\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6799 - val_loss: 28.5613\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8318 - val_loss: 21.3355\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1112 - val_loss: 23.9509\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8954 - val_loss: 21.3419\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.8497 - val_loss: 18.6379\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4477 - val_loss: 24.7566\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5651 - val_loss: 25.5711\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.6885 - val_loss: 21.2637\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.5621 - val_loss: 20.0941\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9486 - val_loss: 20.4407\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5812 - val_loss: 18.5855\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.9270 - val_loss: 26.4483\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3744 - val_loss: 24.8928\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.5346 - val_loss: 19.1398\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9953 - val_loss: 21.5907\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3610 - val_loss: 18.4613\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.1952 - val_loss: 18.1253\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.8186 - val_loss: 21.5081\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3684 - val_loss: 27.8372\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.7671 - val_loss: 21.4633\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4474 - val_loss: 18.4445\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.5974 - val_loss: 18.4232\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3033 - val_loss: 19.6534\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8760 - val_loss: 23.9094\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6442 - val_loss: 26.3094\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.2130 - val_loss: 18.7259\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6164 - val_loss: 18.3252\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5379 - val_loss: 19.2395\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.3634 - val_loss: 20.3889\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7634 - val_loss: 20.0403\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7109 - val_loss: 20.1994\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9407 - val_loss: 19.1942\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1808 - val_loss: 22.4927\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.5886 - val_loss: 20.4007\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.6992 - val_loss: 17.3775\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2273 - val_loss: 22.7558\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8208 - val_loss: 22.9105\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.4677 - val_loss: 17.2293\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.9568 - val_loss: 18.3955\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.6949 - val_loss: 18.7902\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4638 - val_loss: 20.0741\n",
      "3/3 [==============================] - 0s 975us/step - loss: 14.5459\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3255.6763 - val_loss: 1031.3047\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 553.9711 - val_loss: 294.4412\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 141.1120 - val_loss: 149.0983\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104.8309 - val_loss: 125.9063\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.8199 - val_loss: 94.9474\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.5941 - val_loss: 89.8843\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9347 - val_loss: 86.6007\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.9136 - val_loss: 85.8264\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7073 - val_loss: 84.9952\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5444 - val_loss: 82.6013\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9959 - val_loss: 81.7920\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6574 - val_loss: 81.9865\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9755 - val_loss: 83.6555\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7649 - val_loss: 82.7262\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.5834 - val_loss: 77.9758\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.8697 - val_loss: 78.5996\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4151 - val_loss: 81.6118\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3830 - val_loss: 78.7865\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.6839 - val_loss: 79.2762\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4352 - val_loss: 78.8064\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7406 - val_loss: 81.1435\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2488 - val_loss: 80.4684\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4322 - val_loss: 77.1656\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5319 - val_loss: 75.8050\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6038 - val_loss: 78.5239\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2690 - val_loss: 76.5628\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4917 - val_loss: 75.4250\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2863 - val_loss: 77.9520\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2550 - val_loss: 74.6837\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2175 - val_loss: 75.0980\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4478 - val_loss: 76.9454\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.8996 - val_loss: 75.8166\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3264 - val_loss: 73.7573\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9073 - val_loss: 75.2209\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7160 - val_loss: 73.1933\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5710 - val_loss: 74.0986\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8272 - val_loss: 73.4949\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2746 - val_loss: 71.1067\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6276 - val_loss: 71.3958\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5067 - val_loss: 70.3386\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5801 - val_loss: 69.1729\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2481 - val_loss: 70.4788\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1848 - val_loss: 70.5716\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8325 - val_loss: 68.7717\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5402 - val_loss: 71.9459\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8653 - val_loss: 67.0417\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1779 - val_loss: 70.2096\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6816 - val_loss: 67.0171\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5016 - val_loss: 67.5871\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6893 - val_loss: 65.8952\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4017 - val_loss: 65.9981\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9124 - val_loss: 63.7404\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0699 - val_loss: 70.8204\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9823 - val_loss: 62.3734\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.1907 - val_loss: 63.8707\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.9025 - val_loss: 63.9029\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.1941 - val_loss: 65.8459\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.7262 - val_loss: 60.6744\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6918 - val_loss: 59.4388\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2811 - val_loss: 58.9453\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7054 - val_loss: 58.9851\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.3241 - val_loss: 57.0786\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2769 - val_loss: 58.5605\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6989 - val_loss: 62.5532\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2826 - val_loss: 55.8631\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1317 - val_loss: 55.6815\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4726 - val_loss: 55.1679\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.4232 - val_loss: 53.5392\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9396 - val_loss: 54.0266\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2274 - val_loss: 53.8240\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2062 - val_loss: 52.5578\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.3374 - val_loss: 59.3426\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5393 - val_loss: 50.1488\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5344 - val_loss: 56.6176\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2276 - val_loss: 47.0898\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1246 - val_loss: 52.3441\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9385 - val_loss: 45.4551\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5431 - val_loss: 47.9471\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.0731 - val_loss: 43.3454\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5373 - val_loss: 46.7281\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2445 - val_loss: 53.3927\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9016 - val_loss: 55.4017\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2777 - val_loss: 39.6179\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5910 - val_loss: 44.9935\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.7864 - val_loss: 43.6620\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6790 - val_loss: 42.1551\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.3516 - val_loss: 38.6107\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3959 - val_loss: 35.9779\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0716 - val_loss: 37.7657\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9263 - val_loss: 35.7261\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4016 - val_loss: 40.8716\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2904 - val_loss: 41.0334\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 30.3556 - val_loss: 44.1445\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.8588 - val_loss: 43.2095\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7449 - val_loss: 37.9523\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2870 - val_loss: 39.0966\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.6148 - val_loss: 36.2949\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3546 - val_loss: 34.9583\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3454 - val_loss: 33.1563\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1235 - val_loss: 37.1982\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1844 - val_loss: 35.3482\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7890 - val_loss: 39.1492\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5664 - val_loss: 56.3660\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6791 - val_loss: 39.3912\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9487 - val_loss: 36.7313\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1091 - val_loss: 32.7746\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8406 - val_loss: 34.2697\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6201 - val_loss: 29.4952\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7345 - val_loss: 32.4334\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0876 - val_loss: 29.5867\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3270 - val_loss: 29.7666\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4903 - val_loss: 29.0071\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7657 - val_loss: 31.9830\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4559 - val_loss: 28.0443\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0666 - val_loss: 28.3560\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7780 - val_loss: 29.3663\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.8392 - val_loss: 29.3566\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2940 - val_loss: 30.7714\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0918 - val_loss: 27.3351\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8705 - val_loss: 31.1586\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7192 - val_loss: 30.0560\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8651 - val_loss: 29.5221\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4022 - val_loss: 27.9728\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2685 - val_loss: 28.1638\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3799 - val_loss: 32.0783\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6185 - val_loss: 33.6823\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.8100 - val_loss: 26.7069\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2039 - val_loss: 26.3837\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8687 - val_loss: 24.6146\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5802 - val_loss: 25.2601\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7849 - val_loss: 24.5047\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.4401 - val_loss: 27.7014\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2510 - val_loss: 30.8153\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4366 - val_loss: 34.6041\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8385 - val_loss: 28.1287\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.6510 - val_loss: 23.7370\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3805 - val_loss: 27.2571\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3719 - val_loss: 25.9600\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7416 - val_loss: 23.5091\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.6293 - val_loss: 24.4631\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7802 - val_loss: 29.3047\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8017 - val_loss: 30.1522\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4568 - val_loss: 24.9180\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1533 - val_loss: 27.0197\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3269 - val_loss: 21.9795\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.8281 - val_loss: 24.1478\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.6494 - val_loss: 24.6967\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7020 - val_loss: 25.0550\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9059 - val_loss: 23.8085\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6154 - val_loss: 22.4499\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.9276 - val_loss: 22.5296\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9236 - val_loss: 25.9690\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2592 - val_loss: 30.6446\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1218 - val_loss: 26.6892\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.6625 - val_loss: 22.7079\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.7028 - val_loss: 26.1024\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6956 - val_loss: 21.3522\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.2604 - val_loss: 23.1172\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3346 - val_loss: 22.6438\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.5387 - val_loss: 24.3782\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.5134 - val_loss: 24.4013\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1055 - val_loss: 27.7322\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1261 - val_loss: 23.7254\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.9993 - val_loss: 21.9367\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.2821 - val_loss: 20.8942\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.1567 - val_loss: 28.0445\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.1232 - val_loss: 27.5935\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.1975 - val_loss: 27.6308\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7481 - val_loss: 29.4768\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1435 - val_loss: 24.1686\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4816 - val_loss: 23.6911\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.7432 - val_loss: 21.0867\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.5948 - val_loss: 21.1654\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7106 - val_loss: 20.7719\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.7441 - val_loss: 21.5150\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.0590 - val_loss: 22.7561\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5381 - val_loss: 23.1401\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.2048 - val_loss: 20.4649\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.8447 - val_loss: 21.3238\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6330 - val_loss: 22.2448\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.8938 - val_loss: 24.2727\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4714 - val_loss: 21.1014\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.3258 - val_loss: 19.4517\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.2422 - val_loss: 21.9022\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.9844 - val_loss: 19.9604\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.5003 - val_loss: 21.6318\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.4416 - val_loss: 21.9132\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.8283 - val_loss: 18.6740\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.5463 - val_loss: 20.3618\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.5626 - val_loss: 27.2070\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.8674 - val_loss: 24.2480\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0060 - val_loss: 26.0501\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2366 - val_loss: 22.0119\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.7599 - val_loss: 21.8744\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.4345 - val_loss: 20.0550\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1641 - val_loss: 22.2970\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3787 - val_loss: 23.4344\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 14.3424 - val_loss: 19.3419\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.3163 - val_loss: 20.4603\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7105 - val_loss: 23.5508\n",
      "3/3 [==============================] - 0s 875us/step - loss: 36.7692\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 951.2249 - val_loss: 138.0358\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 191.9406 - val_loss: 153.6521\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 103.7162 - val_loss: 95.6089\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.6621 - val_loss: 94.4532\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7270 - val_loss: 83.2349\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5548 - val_loss: 83.4366\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7583 - val_loss: 86.1753\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7194 - val_loss: 85.7925\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7269 - val_loss: 81.8193\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6255 - val_loss: 82.9466\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9185 - val_loss: 83.5385\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2854 - val_loss: 78.4141\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0943 - val_loss: 81.5144\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6495 - val_loss: 72.7979\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5332 - val_loss: 75.3748\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7975 - val_loss: 72.6308\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1043 - val_loss: 71.0596\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4942 - val_loss: 68.8804\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5745 - val_loss: 73.1344\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.9747 - val_loss: 73.4053\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3743 - val_loss: 69.2885\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5426 - val_loss: 72.8356\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5056 - val_loss: 68.2885\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4657 - val_loss: 77.0660\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2275 - val_loss: 72.1195\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2217 - val_loss: 72.7931\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.6636 - val_loss: 74.1411\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9990 - val_loss: 70.2197\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3345 - val_loss: 69.0533\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3980 - val_loss: 69.6230\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8114 - val_loss: 68.2016\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5483 - val_loss: 67.9042\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1633 - val_loss: 66.5619\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1457 - val_loss: 70.7309\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3162 - val_loss: 65.9949\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4532 - val_loss: 69.2748\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7481 - val_loss: 63.5034\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4423 - val_loss: 70.9611\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6931 - val_loss: 64.6601\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3164 - val_loss: 71.9657\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0539 - val_loss: 61.2897\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7002 - val_loss: 65.1308\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3781 - val_loss: 66.9996\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6760 - val_loss: 63.1001\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4399 - val_loss: 70.6617\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3555 - val_loss: 63.3333\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3061 - val_loss: 63.5992\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8512 - val_loss: 64.5803\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5940 - val_loss: 63.2952\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.2989 - val_loss: 61.8589\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1763 - val_loss: 64.5340\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2164 - val_loss: 59.1804\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8339 - val_loss: 63.0841\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0148 - val_loss: 62.0624\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7860 - val_loss: 66.2408\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9722 - val_loss: 69.7479\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2585 - val_loss: 57.0468\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2180 - val_loss: 63.9860\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5104 - val_loss: 59.2072\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3874 - val_loss: 58.0811\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4876 - val_loss: 54.8430\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2587 - val_loss: 54.9367\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4964 - val_loss: 54.6656\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6458 - val_loss: 58.8515\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9930 - val_loss: 61.9242\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5010 - val_loss: 54.7800\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7731 - val_loss: 55.6782\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5723 - val_loss: 57.3343\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.1068 - val_loss: 50.6946\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0534 - val_loss: 50.3354\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2009 - val_loss: 61.4951\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3184 - val_loss: 50.0951\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8367 - val_loss: 49.4110\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6853 - val_loss: 48.1652\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1381 - val_loss: 54.3351\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9022 - val_loss: 48.7746\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5196 - val_loss: 48.0368\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.2948 - val_loss: 56.8818\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6567 - val_loss: 47.8124\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6529 - val_loss: 48.9886\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6822 - val_loss: 56.5071\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3320 - val_loss: 44.8950\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9360 - val_loss: 45.3957\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2458 - val_loss: 44.9291\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8330 - val_loss: 46.7875\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8449 - val_loss: 48.3751\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4168 - val_loss: 47.0957\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9760 - val_loss: 44.8890\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6257 - val_loss: 42.9000\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0885 - val_loss: 41.7225\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6676 - val_loss: 41.1791\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.7184 - val_loss: 38.6903\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9281 - val_loss: 52.7551\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6710 - val_loss: 41.3661\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2852 - val_loss: 54.9705\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8578 - val_loss: 50.7997\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 34.1015 - val_loss: 41.1431\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.5017 - val_loss: 40.2056\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4484 - val_loss: 37.8274\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4866 - val_loss: 60.6274\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2667 - val_loss: 39.7473\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7878 - val_loss: 44.2051\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4973 - val_loss: 37.1581\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1607 - val_loss: 37.5707\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7777 - val_loss: 36.2980\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0819 - val_loss: 39.9167\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3064 - val_loss: 34.9581\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3208 - val_loss: 40.9957\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3225 - val_loss: 36.2284\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2329 - val_loss: 36.5953\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8307 - val_loss: 35.2047\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4675 - val_loss: 38.6645\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3204 - val_loss: 35.4272\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3990 - val_loss: 34.4744\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.9212 - val_loss: 37.8558\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.3095 - val_loss: 37.0623\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4857 - val_loss: 32.8583\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3380 - val_loss: 35.2853\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.3202 - val_loss: 34.1881\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3379 - val_loss: 36.6879\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.0834 - val_loss: 30.9495\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6736 - val_loss: 32.3137\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8322 - val_loss: 31.9058\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0824 - val_loss: 31.2068\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6777 - val_loss: 30.7400\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.5239 - val_loss: 31.4579\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6666 - val_loss: 29.2685\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6813 - val_loss: 29.8379\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.3995 - val_loss: 28.0022\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8145 - val_loss: 33.7444\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7817 - val_loss: 29.6799\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3490 - val_loss: 34.7351\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0180 - val_loss: 28.5052\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2640 - val_loss: 34.0899\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.1757 - val_loss: 27.4226\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1666 - val_loss: 29.1039\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8435 - val_loss: 28.4542\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4416 - val_loss: 27.9946\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2609 - val_loss: 27.4835\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8263 - val_loss: 30.4823\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2660 - val_loss: 25.8096\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5102 - val_loss: 25.5490\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2186 - val_loss: 25.6897\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5191 - val_loss: 26.8866\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0676 - val_loss: 29.6457\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4926 - val_loss: 29.4712\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0255 - val_loss: 26.6841\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6973 - val_loss: 26.3194\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3587 - val_loss: 37.1018\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6170 - val_loss: 26.9821\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.5435 - val_loss: 28.3549\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2272 - val_loss: 25.6311\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7608 - val_loss: 25.7208\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.4505 - val_loss: 29.8300\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2863 - val_loss: 27.8667\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2401 - val_loss: 24.4300\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.3148 - val_loss: 28.3591\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9998 - val_loss: 25.1077\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1409 - val_loss: 24.9895\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6995 - val_loss: 24.8099\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0515 - val_loss: 25.5579\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5838 - val_loss: 22.7504\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3920 - val_loss: 22.4045\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9344 - val_loss: 26.4962\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7288 - val_loss: 21.5857\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3838 - val_loss: 49.8569\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1879 - val_loss: 23.9995\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2954 - val_loss: 25.3525\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3394 - val_loss: 21.4010\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4440 - val_loss: 28.6729\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0153 - val_loss: 25.0531\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5888 - val_loss: 23.6385\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.4209 - val_loss: 23.8227\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3617 - val_loss: 29.5655\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3147 - val_loss: 26.4260\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.9013 - val_loss: 22.3349\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 18.7065 - val_loss: 22.4849\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.6904 - val_loss: 22.7223\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.0754 - val_loss: 23.8965\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.0735 - val_loss: 21.6996\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9379 - val_loss: 28.8388\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9625 - val_loss: 27.9682\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.6854 - val_loss: 24.7847\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3155 - val_loss: 25.7241\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9283 - val_loss: 21.7280\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8241 - val_loss: 29.5475\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5155 - val_loss: 25.7198\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7528 - val_loss: 29.6706\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0747 - val_loss: 21.1277\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9959 - val_loss: 34.3186\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7000 - val_loss: 22.5558\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.9409 - val_loss: 24.5313\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.6991 - val_loss: 20.5411\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3685 - val_loss: 24.1753\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5464 - val_loss: 22.0469\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.0381 - val_loss: 21.8934\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3613 - val_loss: 24.8719\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7520 - val_loss: 23.0917\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4297 - val_loss: 22.7396\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.5166 - val_loss: 26.3356\n",
      "3/3 [==============================] - 0s 902us/step - loss: 25.2222\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 415.1573 - val_loss: 204.5447\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 118.4393 - val_loss: 117.0095\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.6869 - val_loss: 81.1342\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.3585 - val_loss: 75.6141\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.0935 - val_loss: 77.8937\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7019 - val_loss: 78.5920\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6772 - val_loss: 75.0009\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5323 - val_loss: 73.8548\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1587 - val_loss: 74.2965\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2993 - val_loss: 71.7296\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.7854 - val_loss: 73.4594\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0144 - val_loss: 74.1265\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1003 - val_loss: 77.8475\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0214 - val_loss: 72.0588\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9289 - val_loss: 73.7095\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8992 - val_loss: 70.7686\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9064 - val_loss: 70.7531\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5978 - val_loss: 70.4467\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8858 - val_loss: 69.0905\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4860 - val_loss: 68.7121\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0953 - val_loss: 69.0764\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3062 - val_loss: 67.3361\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9964 - val_loss: 69.1300\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2216 - val_loss: 67.2715\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5220 - val_loss: 64.4991\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3989 - val_loss: 64.2042\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5980 - val_loss: 77.0585\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0738 - val_loss: 71.0162\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5139 - val_loss: 63.2126\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 49.0538 - val_loss: 61.0082\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7416 - val_loss: 69.5567\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6229 - val_loss: 60.4314\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4776 - val_loss: 67.3264\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9043 - val_loss: 58.4279\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.8632 - val_loss: 59.7276\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3377 - val_loss: 58.5210\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0310 - val_loss: 57.4981\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0319 - val_loss: 54.6839\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4391 - val_loss: 54.8868\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3627 - val_loss: 62.8332\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7956 - val_loss: 55.2890\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7781 - val_loss: 53.2491\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1824 - val_loss: 54.0309\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4969 - val_loss: 58.0727\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5287 - val_loss: 51.3476\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2377 - val_loss: 58.9702\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8492 - val_loss: 51.8666\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.5966 - val_loss: 48.6578\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6046 - val_loss: 48.5063\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.8955 - val_loss: 46.1137\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7614 - val_loss: 58.4534\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9027 - val_loss: 49.5201\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3155 - val_loss: 46.9200\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8998 - val_loss: 48.1409\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9652 - val_loss: 48.3007\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3922 - val_loss: 42.5952\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2875 - val_loss: 45.1384\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1382 - val_loss: 42.5680\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9800 - val_loss: 46.1268\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7965 - val_loss: 40.6084\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3848 - val_loss: 41.5993\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0394 - val_loss: 36.9353\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0154 - val_loss: 45.2108\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9103 - val_loss: 42.5458\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0775 - val_loss: 44.7151\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5542 - val_loss: 38.8592\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5010 - val_loss: 36.2653\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.7399 - val_loss: 36.2017\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.9314 - val_loss: 42.2148\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5594 - val_loss: 43.0949\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6705 - val_loss: 34.8634\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9751 - val_loss: 33.4463\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0526 - val_loss: 34.4306\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3529 - val_loss: 36.1409\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.2682 - val_loss: 37.5714\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.6498 - val_loss: 30.0938\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.6994 - val_loss: 32.7112\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7593 - val_loss: 30.4590\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7222 - val_loss: 28.9156\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2992 - val_loss: 29.6933\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.1731 - val_loss: 31.4475\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7534 - val_loss: 29.0440\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2952 - val_loss: 28.9188\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5060 - val_loss: 30.2250\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1827 - val_loss: 39.9936\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1308 - val_loss: 27.7796\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6997 - val_loss: 27.4675\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2280 - val_loss: 27.9945\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8599 - val_loss: 32.7283\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8682 - val_loss: 30.3075\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8529 - val_loss: 29.5705\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1890 - val_loss: 37.0844\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7437 - val_loss: 33.8668\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.9099 - val_loss: 30.4257\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9682 - val_loss: 25.8522\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7716 - val_loss: 25.2914\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4320 - val_loss: 29.7429\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8552 - val_loss: 25.7538\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2102 - val_loss: 29.1217\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4777 - val_loss: 28.3158\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6096 - val_loss: 27.7196\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3305 - val_loss: 28.7636\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1255 - val_loss: 29.7528\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6801 - val_loss: 25.4202\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4413 - val_loss: 25.5210\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0133 - val_loss: 24.2635\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.9440 - val_loss: 25.4577\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8095 - val_loss: 26.1480\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3574 - val_loss: 42.7915\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9180 - val_loss: 33.5497\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6468 - val_loss: 34.5680\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6588 - val_loss: 39.6036\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.3303 - val_loss: 25.7767\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4305 - val_loss: 23.9706\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9803 - val_loss: 27.0177\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7026 - val_loss: 27.7757\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5059 - val_loss: 23.8497\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4445 - val_loss: 27.8400\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4967 - val_loss: 25.3487\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2512 - val_loss: 21.9336\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1930 - val_loss: 22.7794\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.8222 - val_loss: 23.7668\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.8654 - val_loss: 23.5433\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1701 - val_loss: 30.7145\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7459 - val_loss: 33.2336\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7332 - val_loss: 22.7616\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5451 - val_loss: 39.0368\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1446 - val_loss: 25.5410\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8297 - val_loss: 25.5694\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3121 - val_loss: 41.1143\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4520 - val_loss: 23.9186\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6535 - val_loss: 23.1282\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9506 - val_loss: 25.5248\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5147 - val_loss: 25.0320\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.3769 - val_loss: 23.9955\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5472 - val_loss: 23.3029\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5597 - val_loss: 23.1449\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2202 - val_loss: 24.1916\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0999 - val_loss: 22.3046\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1120 - val_loss: 22.4731\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.1560 - val_loss: 42.4908\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1595 - val_loss: 32.1842\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9700 - val_loss: 26.1910\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5171 - val_loss: 25.3393\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4611 - val_loss: 24.4847\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.5968 - val_loss: 26.5763\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6444 - val_loss: 22.3511\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.2325 - val_loss: 19.9700\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1270 - val_loss: 20.7087\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.8163 - val_loss: 21.0374\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.2430 - val_loss: 20.8783\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5435 - val_loss: 21.2374\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5150 - val_loss: 29.3752\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9813 - val_loss: 30.9431\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8531 - val_loss: 20.0439\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1062 - val_loss: 21.2443\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2155 - val_loss: 18.9644\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2080 - val_loss: 19.8673\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.1822 - val_loss: 25.9810\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.7646 - val_loss: 25.8024\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9862 - val_loss: 29.1953\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0130 - val_loss: 20.0945\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.7779 - val_loss: 28.4922\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3962 - val_loss: 19.6704\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.4743 - val_loss: 19.6579\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.1220 - val_loss: 19.2538\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.1984 - val_loss: 19.2889\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1151 - val_loss: 24.3989\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.2815 - val_loss: 20.5956\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.0845 - val_loss: 21.0621\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7487 - val_loss: 21.5543\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.9812 - val_loss: 23.6625\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.9914 - val_loss: 24.2604\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6545 - val_loss: 23.3645\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.5788 - val_loss: 20.3123\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4663 - val_loss: 19.5167\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7277 - val_loss: 19.2369\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7388 - val_loss: 21.0170\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.2960 - val_loss: 20.0870\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.5800 - val_loss: 19.8057\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.2100 - val_loss: 22.5054\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.0496 - val_loss: 22.7099\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.2291 - val_loss: 23.2178\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.1510 - val_loss: 22.8067\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 15.6845 - val_loss: 23.2126\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.7659 - val_loss: 21.9438\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.1728 - val_loss: 23.1861\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 16.1274 - val_loss: 19.3452\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.0102 - val_loss: 18.8026\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.3678 - val_loss: 21.9096\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6073 - val_loss: 28.5358\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.5522 - val_loss: 25.0525\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.2566 - val_loss: 25.1262\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1083 - val_loss: 23.2737\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1880 - val_loss: 29.4245\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.7563 - val_loss: 19.7568\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.0571 - val_loss: 19.5812\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 17.3118 - val_loss: 19.4245\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.4814 - val_loss: 22.1987\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.1919 - val_loss: 19.7427\n",
      "3/3 [==============================] - 0s 906us/step - loss: 22.1359\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 126.0106 - val_loss: 110.0694\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.3047 - val_loss: 97.1390\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.7713 - val_loss: 87.0118\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.3087 - val_loss: 78.9330\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.3094 - val_loss: 77.1155\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1163 - val_loss: 83.2128\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0855 - val_loss: 74.5470\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.3075 - val_loss: 73.0903\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1229 - val_loss: 72.6334\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1805 - val_loss: 73.8366\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0012 - val_loss: 75.5759\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.3438 - val_loss: 71.6842\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8204 - val_loss: 72.0523\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9020 - val_loss: 83.8090\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1007 - val_loss: 72.3594\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8245 - val_loss: 68.3441\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8442 - val_loss: 69.2712\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2909 - val_loss: 68.0536\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9087 - val_loss: 70.9086\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.3457 - val_loss: 69.8109\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7206 - val_loss: 66.6691\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6089 - val_loss: 67.8424\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7224 - val_loss: 67.4877\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4403 - val_loss: 64.3411\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2629 - val_loss: 69.7973\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.5199 - val_loss: 103.6512\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7910 - val_loss: 68.6443\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3124 - val_loss: 64.2983\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4815 - val_loss: 72.9963\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7073 - val_loss: 63.2902\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7209 - val_loss: 62.2374\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7790 - val_loss: 66.3191\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6992 - val_loss: 62.9935\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4880 - val_loss: 68.6011\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1911 - val_loss: 63.9448\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4621 - val_loss: 63.5390\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7993 - val_loss: 61.8768\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4897 - val_loss: 59.8425\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0407 - val_loss: 59.4280\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0219 - val_loss: 65.0107\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6898 - val_loss: 58.7308\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1899 - val_loss: 57.2834\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6422 - val_loss: 59.4351\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0987 - val_loss: 74.8344\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.4854 - val_loss: 57.7056\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2132 - val_loss: 56.8771\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2126 - val_loss: 56.8676\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4151 - val_loss: 54.7349\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.7676 - val_loss: 54.0642\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8373 - val_loss: 52.5208\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3113 - val_loss: 55.6841\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5104 - val_loss: 52.0077\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3147 - val_loss: 56.5282\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1841 - val_loss: 59.5451\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8691 - val_loss: 50.8088\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9012 - val_loss: 50.9132\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9421 - val_loss: 50.9820\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6648 - val_loss: 50.9392\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7979 - val_loss: 51.2322\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5893 - val_loss: 63.8441\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1015 - val_loss: 57.1609\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6904 - val_loss: 51.2633\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7118 - val_loss: 48.1914\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.7212 - val_loss: 46.7918\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8976 - val_loss: 49.2237\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6639 - val_loss: 45.6293\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7012 - val_loss: 45.7695\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6114 - val_loss: 45.0313\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2776 - val_loss: 46.6109\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6266 - val_loss: 45.1652\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3368 - val_loss: 45.2226\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5293 - val_loss: 42.8853\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3355 - val_loss: 52.5076\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9350 - val_loss: 43.6788\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5380 - val_loss: 44.7521\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8503 - val_loss: 43.0366\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5884 - val_loss: 45.0434\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3009 - val_loss: 45.8687\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.1047 - val_loss: 43.6022\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7553 - val_loss: 42.7676\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4205 - val_loss: 43.5931\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5846 - val_loss: 41.6735\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.4056 - val_loss: 39.7754\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9575 - val_loss: 39.2028\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5852 - val_loss: 39.1929\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4385 - val_loss: 39.2211\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6152 - val_loss: 41.1898\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5920 - val_loss: 41.2085\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7760 - val_loss: 42.1235\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7983 - val_loss: 44.0967\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3226 - val_loss: 37.6423\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1369 - val_loss: 38.7481\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9772 - val_loss: 38.1838\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9956 - val_loss: 39.0132\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5450 - val_loss: 36.6495\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2914 - val_loss: 38.1770\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0370 - val_loss: 39.0656\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4667 - val_loss: 38.0527\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2277 - val_loss: 36.1738\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.6828 - val_loss: 38.0423\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7233 - val_loss: 34.1801\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8663 - val_loss: 42.6497\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.1616 - val_loss: 38.9233\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0971 - val_loss: 38.9471\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1269 - val_loss: 43.2996\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4659 - val_loss: 56.2501\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9811 - val_loss: 41.8430\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6303 - val_loss: 34.1348\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1079 - val_loss: 34.0632\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5024 - val_loss: 38.4899\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.2638 - val_loss: 36.9478\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2911 - val_loss: 36.3851\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4828 - val_loss: 36.0211\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8208 - val_loss: 39.9184\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9550 - val_loss: 37.4705\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9089 - val_loss: 33.9365\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2551 - val_loss: 36.3856\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9963 - val_loss: 35.3146\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7552 - val_loss: 32.4410\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.1038 - val_loss: 36.4386\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0021 - val_loss: 38.6270\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6444 - val_loss: 36.7018\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3671 - val_loss: 36.6703\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2973 - val_loss: 33.1723\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2414 - val_loss: 31.7905\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4847 - val_loss: 30.3295\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4758 - val_loss: 32.1371\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2706 - val_loss: 35.2323\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9726 - val_loss: 42.6938\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.3848 - val_loss: 29.3445\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2957 - val_loss: 33.5291\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1665 - val_loss: 28.1446\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6466 - val_loss: 30.1377\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5488 - val_loss: 33.0903\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9355 - val_loss: 29.6788\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8365 - val_loss: 30.1465\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2549 - val_loss: 38.1399\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8801 - val_loss: 30.9422\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.5350 - val_loss: 28.9263\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9112 - val_loss: 30.1180\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9026 - val_loss: 33.1355\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9310 - val_loss: 28.5848\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0781 - val_loss: 27.1178\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6664 - val_loss: 28.5453\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3802 - val_loss: 30.4930\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2582 - val_loss: 31.6643\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7510 - val_loss: 31.8059\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7245 - val_loss: 30.0910\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1889 - val_loss: 29.3532\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3999 - val_loss: 27.0564\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4328 - val_loss: 24.9929\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2090 - val_loss: 35.0950\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2297 - val_loss: 37.8255\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2683 - val_loss: 33.5696\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0387 - val_loss: 34.1802\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3387 - val_loss: 30.2427\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.8326 - val_loss: 30.8074\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.3168 - val_loss: 27.1256\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6471 - val_loss: 26.4389\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4110 - val_loss: 26.7385\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0859 - val_loss: 23.6579\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3234 - val_loss: 24.9760\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1182 - val_loss: 26.5263\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2770 - val_loss: 25.3298\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2513 - val_loss: 27.4192\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1386 - val_loss: 24.7570\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0657 - val_loss: 23.9708\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5368 - val_loss: 25.5983\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0397 - val_loss: 25.8223\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2528 - val_loss: 25.2179\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.9189 - val_loss: 26.3025\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9174 - val_loss: 24.1497\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.4594 - val_loss: 28.0406\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.2277 - val_loss: 24.1982\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2212 - val_loss: 28.4885\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8544 - val_loss: 28.1528\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.3054 - val_loss: 25.9405\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5923 - val_loss: 25.4228\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5498 - val_loss: 25.3186\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.7578 - val_loss: 25.2384\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1277 - val_loss: 24.5046\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.4768 - val_loss: 24.4705\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0958 - val_loss: 28.6118\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2231 - val_loss: 24.6905\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6340 - val_loss: 25.2006\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.1889 - val_loss: 28.7057\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.9742 - val_loss: 29.9190\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7980 - val_loss: 28.1392\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6793 - val_loss: 28.4647\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9897 - val_loss: 26.9421\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8855 - val_loss: 23.6334\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2063 - val_loss: 23.7711\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.7884 - val_loss: 22.6445\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.9517 - val_loss: 23.3617\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5583 - val_loss: 22.2032\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.1099 - val_loss: 21.6190\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0028 - val_loss: 28.4078\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8818 - val_loss: 24.8788\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1706 - val_loss: 22.9928\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.6344 - val_loss: 25.2426\n",
      "3/3 [==============================] - 0s 809us/step - loss: 25.1955\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1106.5061 - val_loss: 659.7169\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 360.8738 - val_loss: 162.3087\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 169.8415 - val_loss: 113.4985\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95.0445 - val_loss: 103.6436\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.2267 - val_loss: 81.4752\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.8931 - val_loss: 75.4976\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.0422 - val_loss: 78.9955\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.1579 - val_loss: 81.1063\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.4008 - val_loss: 78.9975\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.6901 - val_loss: 81.9767\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.3031 - val_loss: 77.9573\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1664 - val_loss: 76.0993\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5537 - val_loss: 74.4110\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4517 - val_loss: 77.0777\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.7076 - val_loss: 76.5922\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3400 - val_loss: 74.6220\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6478 - val_loss: 74.2662\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8610 - val_loss: 76.2224\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1835 - val_loss: 73.8617\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7946 - val_loss: 76.3092\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9487 - val_loss: 74.6608\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7830 - val_loss: 75.3655\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.4617 - val_loss: 71.6252\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7300 - val_loss: 73.2099\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6581 - val_loss: 68.0479\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8228 - val_loss: 70.7782\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1886 - val_loss: 73.7200\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7490 - val_loss: 74.9943\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2362 - val_loss: 82.6474\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7180 - val_loss: 71.0354\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7774 - val_loss: 67.2618\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5309 - val_loss: 67.8535\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1449 - val_loss: 69.5588\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3731 - val_loss: 68.0986\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.8002 - val_loss: 67.1859\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4230 - val_loss: 67.8685\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.7560 - val_loss: 68.9370\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8542 - val_loss: 67.0120\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0876 - val_loss: 71.2698\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0438 - val_loss: 64.7323\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6696 - val_loss: 63.2038\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0137 - val_loss: 66.5241\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.3014 - val_loss: 63.4420\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3837 - val_loss: 65.5650\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0584 - val_loss: 70.2381\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7721 - val_loss: 62.6941\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1814 - val_loss: 62.9592\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8475 - val_loss: 61.5781\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6026 - val_loss: 67.2178\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7276 - val_loss: 60.4764\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7103 - val_loss: 62.1536\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1302 - val_loss: 61.7611\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8139 - val_loss: 61.1409\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8098 - val_loss: 59.7737\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3172 - val_loss: 62.2421\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5309 - val_loss: 60.2257\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4243 - val_loss: 55.1755\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0889 - val_loss: 59.3453\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1547 - val_loss: 60.4556\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1893 - val_loss: 60.3952\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4867 - val_loss: 60.4122\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9254 - val_loss: 59.6195\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.1327 - val_loss: 85.7297\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7023 - val_loss: 60.3044\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.4016 - val_loss: 55.9334\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0946 - val_loss: 55.7686\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8290 - val_loss: 55.5678\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8984 - val_loss: 51.7695\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2996 - val_loss: 56.9512\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0285 - val_loss: 54.0980\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3857 - val_loss: 51.4508\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.0580 - val_loss: 55.5324\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5521 - val_loss: 56.6374\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5781 - val_loss: 65.9714\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.0294 - val_loss: 56.4989\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0116 - val_loss: 51.7987\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7494 - val_loss: 63.4235\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4844 - val_loss: 49.3295\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9488 - val_loss: 49.8018\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6854 - val_loss: 56.0209\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6632 - val_loss: 55.3311\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5933 - val_loss: 53.9236\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2181 - val_loss: 51.3432\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9957 - val_loss: 47.4104\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4442 - val_loss: 54.9039\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9104 - val_loss: 66.9669\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1494 - val_loss: 57.2944\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1546 - val_loss: 53.1196\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1236 - val_loss: 46.1565\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1932 - val_loss: 48.2531\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9422 - val_loss: 48.8841\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6274 - val_loss: 49.9697\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7668 - val_loss: 48.3222\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1269 - val_loss: 48.8681\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5898 - val_loss: 54.5817\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4166 - val_loss: 54.8960\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3145 - val_loss: 44.5627\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9449 - val_loss: 44.7262\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8249 - val_loss: 46.8857\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2430 - val_loss: 46.4111\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 46.3166 - val_loss: 49.2904\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4709 - val_loss: 49.9395\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5946 - val_loss: 48.5781\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9957 - val_loss: 44.2555\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2697 - val_loss: 68.8864\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.2830 - val_loss: 51.2928\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8362 - val_loss: 57.1417\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3432 - val_loss: 44.6718\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.9629 - val_loss: 44.5870\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0062 - val_loss: 44.1114\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0231 - val_loss: 49.7471\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5154 - val_loss: 45.8311\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3881 - val_loss: 44.5437\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2332 - val_loss: 48.7777\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1645 - val_loss: 55.4637\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3636 - val_loss: 44.9223\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6529 - val_loss: 43.5638\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7794 - val_loss: 42.7818\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.0615 - val_loss: 50.2845\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2682 - val_loss: 41.9948\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5476 - val_loss: 41.8448\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4881 - val_loss: 53.3883\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4246 - val_loss: 59.6374\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1520 - val_loss: 46.1466\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9397 - val_loss: 42.5700\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.0019 - val_loss: 41.2215\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4544 - val_loss: 46.0491\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.0032 - val_loss: 47.7469\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5441 - val_loss: 48.7914\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7923 - val_loss: 61.4910\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3276 - val_loss: 40.0564\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9537 - val_loss: 41.0766\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5447 - val_loss: 42.1534\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6307 - val_loss: 39.6778\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1429 - val_loss: 44.2873\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9706 - val_loss: 54.4963\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.9895 - val_loss: 39.8369\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3458 - val_loss: 44.5201\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1440 - val_loss: 40.2271\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5263 - val_loss: 47.8576\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9729 - val_loss: 40.3124\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9581 - val_loss: 44.7778\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9275 - val_loss: 44.4336\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4813 - val_loss: 42.8018\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0020 - val_loss: 39.3405\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.4255 - val_loss: 39.2630\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0490 - val_loss: 48.1541\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1623 - val_loss: 40.7090\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5577 - val_loss: 45.0102\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3552 - val_loss: 49.5212\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.4417 - val_loss: 43.3148\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5577 - val_loss: 45.6176\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0715 - val_loss: 39.7181\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4988 - val_loss: 39.9255\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.8851 - val_loss: 47.1617\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.1716 - val_loss: 39.8542\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0996 - val_loss: 42.3898\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.7393 - val_loss: 40.9475\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.4801 - val_loss: 41.8225\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1109 - val_loss: 42.6030\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4145 - val_loss: 41.7963\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.8081 - val_loss: 40.4126\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4985 - val_loss: 49.8534\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4496 - val_loss: 40.5634\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1339 - val_loss: 40.9616\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6106 - val_loss: 46.4684\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4930 - val_loss: 36.9913\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.0581 - val_loss: 35.6144\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3039 - val_loss: 40.5316\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.4808 - val_loss: 35.5740\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6306 - val_loss: 36.4793\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1458 - val_loss: 40.8789\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1615 - val_loss: 37.8752\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0656 - val_loss: 40.2508\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6216 - val_loss: 40.3443\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8665 - val_loss: 39.0769\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1522 - val_loss: 47.5763\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4007 - val_loss: 39.2690\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2713 - val_loss: 37.8841\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4831 - val_loss: 38.7314\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2194 - val_loss: 35.6741\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1399 - val_loss: 36.2740\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2014 - val_loss: 34.8902\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.7988 - val_loss: 40.0518\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3772 - val_loss: 34.2379\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3673 - val_loss: 39.6385\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2112 - val_loss: 50.3501\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2714 - val_loss: 40.1932\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8022 - val_loss: 38.2196\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4314 - val_loss: 37.3913\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1115 - val_loss: 47.9703\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2574 - val_loss: 40.6447\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.9243 - val_loss: 37.3375\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1023 - val_loss: 36.2455\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6289 - val_loss: 43.5967\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1788 - val_loss: 38.9369\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5317 - val_loss: 36.8164\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0373 - val_loss: 36.7155\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8716 - val_loss: 38.1162\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5781 - val_loss: 41.4788\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 20.2102\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 503.4471 - val_loss: 232.3963\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 147.3439 - val_loss: 120.2655\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107.5334 - val_loss: 105.3811\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99.5464 - val_loss: 102.0082\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.4649 - val_loss: 93.2630\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.4909 - val_loss: 95.2288\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.8875 - val_loss: 86.1247\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6986 - val_loss: 85.1674\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0724 - val_loss: 81.4302\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9344 - val_loss: 80.4627\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1854 - val_loss: 79.8410\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.5914 - val_loss: 81.8961\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3400 - val_loss: 77.9948\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8423 - val_loss: 88.1573\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.0579 - val_loss: 75.9663\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0552 - val_loss: 76.2769\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1597 - val_loss: 73.8222\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8723 - val_loss: 75.8262\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3130 - val_loss: 73.7407\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0542 - val_loss: 72.5588\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0470 - val_loss: 72.8698\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0201 - val_loss: 70.9240\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1004 - val_loss: 85.2801\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4015 - val_loss: 66.6666\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9628 - val_loss: 67.6225\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9822 - val_loss: 66.3752\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2852 - val_loss: 65.7618\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5014 - val_loss: 65.3347\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0839 - val_loss: 64.8258\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1628 - val_loss: 61.2046\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6353 - val_loss: 62.6874\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1992 - val_loss: 62.8174\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0311 - val_loss: 66.4770\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.8876 - val_loss: 62.3374\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7416 - val_loss: 62.4054\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6454 - val_loss: 58.5866\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2430 - val_loss: 65.2123\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8396 - val_loss: 57.4360\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0525 - val_loss: 63.8825\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0101 - val_loss: 79.9222\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2230 - val_loss: 58.8693\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1173 - val_loss: 57.5616\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1847 - val_loss: 52.1344\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0965 - val_loss: 51.3904\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5135 - val_loss: 56.6163\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0035 - val_loss: 51.9083\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2660 - val_loss: 54.0538\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6146 - val_loss: 73.1195\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2680 - val_loss: 54.4206\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4720 - val_loss: 49.2930\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9964 - val_loss: 47.5465\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1620 - val_loss: 47.8671\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3852 - val_loss: 50.7428\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5283 - val_loss: 58.2601\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1654 - val_loss: 54.1059\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8272 - val_loss: 56.8652\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7029 - val_loss: 56.0862\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3560 - val_loss: 49.6999\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8670 - val_loss: 46.6988\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2691 - val_loss: 43.6144\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5358 - val_loss: 46.1539\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5935 - val_loss: 41.1701\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3703 - val_loss: 49.6822\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9537 - val_loss: 47.8246\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4633 - val_loss: 51.8176\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.0615 - val_loss: 41.0559\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.3278 - val_loss: 41.2894\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.1162 - val_loss: 45.1669\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7762 - val_loss: 44.8589\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2773 - val_loss: 45.6626\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4669 - val_loss: 39.5927\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8258 - val_loss: 41.2470\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5644 - val_loss: 42.0491\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2616 - val_loss: 44.6621\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5462 - val_loss: 44.7334\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2489 - val_loss: 42.4463\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8187 - val_loss: 44.6770\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.5047 - val_loss: 43.9518\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3428 - val_loss: 44.9244\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5884 - val_loss: 38.6989\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3540 - val_loss: 40.2729\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0070 - val_loss: 47.5142\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8172 - val_loss: 37.6272\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5741 - val_loss: 47.3651\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9229 - val_loss: 44.5467\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0857 - val_loss: 47.5255\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.8992 - val_loss: 36.7566\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5801 - val_loss: 35.9414\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.2478 - val_loss: 34.2268\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4873 - val_loss: 34.1886\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1607 - val_loss: 35.1427\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2684 - val_loss: 34.0331\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9259 - val_loss: 34.1864\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0911 - val_loss: 33.2159\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9049 - val_loss: 36.9027\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8403 - val_loss: 35.8567\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.3477 - val_loss: 33.4888\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7973 - val_loss: 32.8709\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9271 - val_loss: 43.0618\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8235 - val_loss: 47.7544\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4544 - val_loss: 34.7090\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6229 - val_loss: 31.6777\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4349 - val_loss: 32.1636\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6083 - val_loss: 32.0117\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3603 - val_loss: 33.9600\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2777 - val_loss: 37.7828\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6999 - val_loss: 35.2405\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.3748 - val_loss: 30.6058\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6854 - val_loss: 31.2164\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2083 - val_loss: 31.8545\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9492 - val_loss: 37.7230\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.1638 - val_loss: 34.1913\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8625 - val_loss: 32.4510\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9014 - val_loss: 29.6472\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1165 - val_loss: 32.4212\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5049 - val_loss: 30.0576\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.5060 - val_loss: 32.0670\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4503 - val_loss: 32.4928\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2767 - val_loss: 28.2486\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2713 - val_loss: 35.3586\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8684 - val_loss: 32.6770\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.0950 - val_loss: 32.8123\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4179 - val_loss: 30.1605\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9427 - val_loss: 31.2143\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4879 - val_loss: 31.6619\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8612 - val_loss: 27.5881\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0179 - val_loss: 30.3798\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3425 - val_loss: 31.9590\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9364 - val_loss: 30.5065\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1429 - val_loss: 27.7298\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6395 - val_loss: 29.3187\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5454 - val_loss: 37.4710\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7531 - val_loss: 30.4846\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2651 - val_loss: 35.4288\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.4525 - val_loss: 45.8761\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4041 - val_loss: 58.1022\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7670 - val_loss: 39.8196\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7531 - val_loss: 36.8671\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2846 - val_loss: 30.4934\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1159 - val_loss: 27.8072\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5366 - val_loss: 31.2284\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9861 - val_loss: 32.0187\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8602 - val_loss: 29.1551\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.9146 - val_loss: 30.9262\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6551 - val_loss: 32.9429\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5219 - val_loss: 32.7826\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5166 - val_loss: 36.8520\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4099 - val_loss: 36.9438\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0287 - val_loss: 28.9009\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6754 - val_loss: 32.5724\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9703 - val_loss: 30.7114\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9571 - val_loss: 27.6551\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9346 - val_loss: 30.1665\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0754 - val_loss: 27.0159\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4276 - val_loss: 27.0532\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1793 - val_loss: 28.2300\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.5661 - val_loss: 27.8284\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1916 - val_loss: 28.8331\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8411 - val_loss: 28.7115\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5672 - val_loss: 28.8549\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1227 - val_loss: 33.2197\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9393 - val_loss: 41.5963\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1723 - val_loss: 31.5662\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0100 - val_loss: 27.9609\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9839 - val_loss: 31.1121\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4906 - val_loss: 30.7609\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4165 - val_loss: 29.8372\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2909 - val_loss: 36.4707\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1652 - val_loss: 32.0423\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0176 - val_loss: 32.7438\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.6329 - val_loss: 32.9222\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.9869 - val_loss: 26.4201\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.0208 - val_loss: 29.2955\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.8347 - val_loss: 29.0850\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3931 - val_loss: 28.2268\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.1165 - val_loss: 26.9277\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2128 - val_loss: 30.0542\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.3696 - val_loss: 27.7133\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9361 - val_loss: 28.2637\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6669 - val_loss: 30.4339\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0272 - val_loss: 26.7583\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.8669 - val_loss: 26.7123\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7973 - val_loss: 28.0108\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.9934 - val_loss: 28.5077\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0999 - val_loss: 27.5914\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.8016 - val_loss: 26.8016\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.0906 - val_loss: 27.2149\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 19.4540 - val_loss: 26.5009\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6347 - val_loss: 31.3913\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6021 - val_loss: 26.9345\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2637 - val_loss: 28.6683\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0565 - val_loss: 27.4098\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3543 - val_loss: 31.4176\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2596 - val_loss: 32.8897\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.2819 - val_loss: 31.7681\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.8030 - val_loss: 29.9849\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0908 - val_loss: 28.8990\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.4027 - val_loss: 31.2995\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.6370 - val_loss: 25.1002\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0708 - val_loss: 30.1172\n",
      "3/3 [==============================] - 0s 998us/step - loss: 47.6684\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 558.5901 - val_loss: 613.5953\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 538.0508 - val_loss: 585.0432\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 507.2428 - val_loss: 534.0524\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 450.5551 - val_loss: 458.2245\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 370.4307 - val_loss: 366.0912\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 280.8337 - val_loss: 288.6508\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 204.2763 - val_loss: 218.8154\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 147.0858 - val_loss: 162.2762\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 103.3376 - val_loss: 128.9183\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 83.0302 - val_loss: 112.5459\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.8500 - val_loss: 104.9093\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8591 - val_loss: 101.5028\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.6895 - val_loss: 99.1533\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9351 - val_loss: 97.9695\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2934 - val_loss: 96.8231\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.8220 - val_loss: 95.4572\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2978 - val_loss: 94.8666\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 62.6233 - val_loss: 94.6979\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7993 - val_loss: 94.3108\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1694 - val_loss: 94.0618\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6652 - val_loss: 94.1190\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.2319 - val_loss: 92.9356\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7746 - val_loss: 92.3772\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5801 - val_loss: 91.9416\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4974 - val_loss: 91.0443\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.2163 - val_loss: 91.5775\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9475 - val_loss: 90.5107\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6729 - val_loss: 89.7458\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.1795 - val_loss: 90.5823\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7087 - val_loss: 89.7883\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.3889 - val_loss: 87.9603\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9208 - val_loss: 88.4987\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7723 - val_loss: 88.8805\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.4636 - val_loss: 87.3677\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.4193 - val_loss: 87.4039\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1426 - val_loss: 87.0462\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1066 - val_loss: 87.8564\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7860 - val_loss: 88.5317\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.4025 - val_loss: 85.7945\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.9267 - val_loss: 85.0732\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6115 - val_loss: 84.8104\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8975 - val_loss: 84.3330\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1082 - val_loss: 85.3180\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5906 - val_loss: 83.4581\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3902 - val_loss: 83.5380\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.0298 - val_loss: 82.9889\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7950 - val_loss: 84.1211\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.0940 - val_loss: 82.8417\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4351 - val_loss: 81.5005\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.5417 - val_loss: 81.5225\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0396 - val_loss: 81.6617\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2462 - val_loss: 83.6792\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2484 - val_loss: 80.6882\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6987 - val_loss: 82.0579\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.5823 - val_loss: 80.2997\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.2878 - val_loss: 79.8799\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.7223 - val_loss: 79.8782\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2996 - val_loss: 82.1603\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0980 - val_loss: 79.5512\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4522 - val_loss: 79.4948\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4255 - val_loss: 78.0903\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.0483 - val_loss: 78.9420\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.1805 - val_loss: 78.6165\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.7378 - val_loss: 77.7651\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5649 - val_loss: 77.4236\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5943 - val_loss: 76.5257\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2491 - val_loss: 77.5004\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5660 - val_loss: 75.8782\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8616 - val_loss: 77.3332\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1470 - val_loss: 76.7400\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4981 - val_loss: 75.1506\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8526 - val_loss: 74.9091\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1180 - val_loss: 75.5250\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6578 - val_loss: 75.4444\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8842 - val_loss: 73.9476\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.0344 - val_loss: 73.2181\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1128 - val_loss: 73.6877\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3608 - val_loss: 73.3579\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3620 - val_loss: 73.3337\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5817 - val_loss: 73.8304\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5318 - val_loss: 75.1239\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8152 - val_loss: 73.9638\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5706 - val_loss: 74.5648\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6861 - val_loss: 73.7856\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1960 - val_loss: 73.0943\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4935 - val_loss: 73.4732\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.9784 - val_loss: 71.8688\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1199 - val_loss: 71.5014\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6932 - val_loss: 71.2265\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7556 - val_loss: 71.2032\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5528 - val_loss: 70.4077\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6254 - val_loss: 70.2150\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4829 - val_loss: 71.1082\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 47.9689 - val_loss: 69.5064\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.5210 - val_loss: 69.4993\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6779 - val_loss: 74.0046\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6191 - val_loss: 69.7652\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4449 - val_loss: 69.9110\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6162 - val_loss: 69.7680\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1137 - val_loss: 69.1777\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8311 - val_loss: 68.8405\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6795 - val_loss: 68.1521\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6784 - val_loss: 68.0193\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6170 - val_loss: 67.3961\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3740 - val_loss: 67.2820\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.0615 - val_loss: 68.9425\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2344 - val_loss: 70.4552\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.5364 - val_loss: 67.7363\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4979 - val_loss: 69.8140\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7858 - val_loss: 66.9990\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.0120 - val_loss: 67.8915\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0653 - val_loss: 66.9034\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0775 - val_loss: 66.7148\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8023 - val_loss: 66.9558\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1820 - val_loss: 66.5449\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4854 - val_loss: 66.0543\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2957 - val_loss: 65.1110\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5166 - val_loss: 64.7414\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.0328 - val_loss: 65.3644\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1140 - val_loss: 65.6162\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7061 - val_loss: 64.4468\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6154 - val_loss: 65.1801\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6293 - val_loss: 64.7910\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6186 - val_loss: 64.4227\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8353 - val_loss: 62.9887\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2020 - val_loss: 63.1508\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.8045 - val_loss: 62.3556\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4006 - val_loss: 65.4534\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6048 - val_loss: 61.9885\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1356 - val_loss: 62.5905\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.4380 - val_loss: 62.7201\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.2481 - val_loss: 62.5238\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9258 - val_loss: 61.5038\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9262 - val_loss: 61.9599\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0114 - val_loss: 62.5691\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.0638 - val_loss: 61.1222\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4679 - val_loss: 62.1562\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6739 - val_loss: 61.5236\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.8360 - val_loss: 62.2625\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4113 - val_loss: 60.7421\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8920 - val_loss: 61.6022\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 40.6777 - val_loss: 60.3355\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5507 - val_loss: 59.9382\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.8196 - val_loss: 59.7220\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.5267 - val_loss: 61.3749\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0538 - val_loss: 58.4901\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.6055 - val_loss: 59.4143\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.8826 - val_loss: 58.4312\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9399 - val_loss: 59.3790\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6017 - val_loss: 57.7495\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.7725 - val_loss: 57.2837\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.1541 - val_loss: 59.9251\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5950 - val_loss: 58.4848\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3867 - val_loss: 57.2897\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1375 - val_loss: 58.5851\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9367 - val_loss: 57.3771\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.3004 - val_loss: 57.0219\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6016 - val_loss: 56.8690\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4221 - val_loss: 57.8412\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9002 - val_loss: 57.1293\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1821 - val_loss: 56.4500\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9377 - val_loss: 56.3315\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9159 - val_loss: 55.9903\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9212 - val_loss: 57.8723\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4393 - val_loss: 55.8261\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.6900 - val_loss: 54.9238\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.3454 - val_loss: 53.7268\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.6637 - val_loss: 56.0422\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 37.4585 - val_loss: 54.8052\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.1252 - val_loss: 55.4542\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5625 - val_loss: 55.0820\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.9418 - val_loss: 54.6868\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3204 - val_loss: 55.6330\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5139 - val_loss: 54.8342\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7343 - val_loss: 53.8985\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4306 - val_loss: 52.1766\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7174 - val_loss: 53.9141\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6030 - val_loss: 52.7294\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.1830 - val_loss: 53.1204\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2351 - val_loss: 52.7665\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8764 - val_loss: 53.2324\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1255 - val_loss: 51.6383\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8556 - val_loss: 51.9559\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9727 - val_loss: 51.3914\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7828 - val_loss: 51.2737\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7049 - val_loss: 52.1399\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.3750 - val_loss: 50.4371\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.6523 - val_loss: 51.4301\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.1608 - val_loss: 50.5324\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1301 - val_loss: 50.0320\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2239 - val_loss: 51.7683\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.4426 - val_loss: 52.6814\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.2561 - val_loss: 49.4614\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.7019 - val_loss: 50.5901\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.6102 - val_loss: 50.6025\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.2749 - val_loss: 49.5208\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5752 - val_loss: 48.9731\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9326 - val_loss: 48.8924\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.9839 - val_loss: 49.9741\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0902 - val_loss: 49.7442\n",
      "3/3 [==============================] - 0s 834us/step - loss: 31.6971\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 891.2943 - val_loss: 844.6647\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 729.7867 - val_loss: 723.0037\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 630.0641 - val_loss: 648.1359\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 579.7877 - val_loss: 637.7541\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 577.9346 - val_loss: 637.2982\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 577.4931 - val_loss: 636.8371\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 577.0483 - val_loss: 636.3738\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 576.5975 - val_loss: 635.8997\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 576.1423 - val_loss: 635.4318\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 575.6910 - val_loss: 634.9624\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 575.2378 - val_loss: 634.4850\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 574.7704 - val_loss: 634.0031\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 574.2997 - val_loss: 633.5133\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 573.8342 - val_loss: 633.0229\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 573.3586 - val_loss: 632.5397\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 572.8912 - val_loss: 632.0569\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 572.4231 - val_loss: 631.5668\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 571.9516 - val_loss: 631.0701\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 571.4753 - val_loss: 630.5867\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 571.0112 - val_loss: 630.0978\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 570.5397 - val_loss: 629.6200\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 570.0743 - val_loss: 629.1373\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 569.6035 - val_loss: 628.6406\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 569.1294 - val_loss: 628.1487\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 568.6573 - val_loss: 627.6667\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 568.1929 - val_loss: 627.1817\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 567.7254 - val_loss: 626.7002\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 567.2609 - val_loss: 626.2090\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 566.7837 - val_loss: 625.7261\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 566.3212 - val_loss: 625.2435\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 565.8553 - val_loss: 624.7562\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 565.3807 - val_loss: 624.2750\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 564.9163 - val_loss: 623.7827\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 564.4468 - val_loss: 623.3016\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 563.9773 - val_loss: 622.8175\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 563.4976 - val_loss: 622.3154\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 563.0196 - val_loss: 621.8123\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 562.5421 - val_loss: 621.3193\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 562.0654 - val_loss: 620.8309\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 561.5952 - val_loss: 620.3414\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 561.1242 - val_loss: 619.8569\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 560.6594 - val_loss: 619.3717\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 560.1889 - val_loss: 618.8881\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 559.7266 - val_loss: 618.4087\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 559.2634 - val_loss: 617.9288\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 558.8022 - val_loss: 617.4471\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 558.3359 - val_loss: 616.9679\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 557.8719 - val_loss: 616.4813\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 557.3979 - val_loss: 615.9905\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 556.9306 - val_loss: 615.5054\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 556.4601 - val_loss: 615.0237\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 555.9850 - val_loss: 614.5193\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 555.5032 - val_loss: 614.0247\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 555.0338 - val_loss: 613.5385\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 554.5591 - val_loss: 613.0426\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 554.0815 - val_loss: 612.5596\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 553.6165 - val_loss: 612.0649\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 553.1433 - val_loss: 611.5844\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 552.6800 - val_loss: 611.1038\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 552.2140 - val_loss: 610.6256\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 551.7550 - val_loss: 610.1461\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 551.2893 - val_loss: 609.6633\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 550.8261 - val_loss: 609.1824\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 550.3590 - val_loss: 608.7020\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 549.8936 - val_loss: 608.2062\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 549.4148 - val_loss: 607.7134\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 548.9432 - val_loss: 607.2228\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 548.4702 - val_loss: 606.7426\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 548.0105 - val_loss: 606.2517\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 547.5386 - val_loss: 605.7737\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 547.0839 - val_loss: 605.2948\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 546.6193 - val_loss: 604.8194\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 546.1603 - val_loss: 604.3430\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 545.7013 - val_loss: 603.8546\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 545.2307 - val_loss: 603.3848\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 544.7692 - val_loss: 602.8954\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 544.3035 - val_loss: 602.4188\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 543.8408 - val_loss: 601.9368\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 543.3801 - val_loss: 601.4581\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 542.9225 - val_loss: 600.9764\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 542.4607 - val_loss: 600.5053\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 542.0033 - val_loss: 600.0311\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 541.5468 - val_loss: 599.5640\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 541.0952 - val_loss: 599.0939\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 540.6384 - val_loss: 598.6098\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 540.1760 - val_loss: 598.1309\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 539.7144 - val_loss: 597.6536\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 539.2537 - val_loss: 597.1799\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 538.7970 - val_loss: 596.7014\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 538.3332 - val_loss: 596.2213\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 537.8679 - val_loss: 595.7330\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 537.4033 - val_loss: 595.2580\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 536.9488 - val_loss: 594.7795\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 536.4868 - val_loss: 594.3007\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 536.0159 - val_loss: 593.8196\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 535.5579 - val_loss: 593.3471\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 535.0961 - val_loss: 592.8651\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 534.6315 - val_loss: 592.3832\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 534.1796 - val_loss: 591.9069\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 533.7207 - val_loss: 591.4439\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 533.2667 - val_loss: 590.9694\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 532.8143 - val_loss: 590.4977\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 532.3599 - val_loss: 590.0321\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 531.9102 - val_loss: 589.5651\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 531.4603 - val_loss: 589.0886\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 531.0009 - val_loss: 588.6175\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 530.5526 - val_loss: 588.1570\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 530.1053 - val_loss: 587.6813\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 529.6422 - val_loss: 587.2026\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 529.1815 - val_loss: 586.7321\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 528.7319 - val_loss: 586.2572\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 528.2692 - val_loss: 585.7809\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 527.8082 - val_loss: 585.2991\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 527.3448 - val_loss: 584.8180\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 526.8875 - val_loss: 584.3475\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 526.4360 - val_loss: 583.8873\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 525.9929 - val_loss: 583.4236\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 525.5425 - val_loss: 582.9505\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 525.0801 - val_loss: 582.4688\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 524.6252 - val_loss: 582.0001\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 524.1746 - val_loss: 581.5406\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 523.7340 - val_loss: 581.0807\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 523.2889 - val_loss: 580.6176\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 522.8509 - val_loss: 580.1635\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 522.4028 - val_loss: 579.6923\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 521.9484 - val_loss: 579.2250\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 521.4979 - val_loss: 578.7499\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 521.0358 - val_loss: 578.2711\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 520.5855 - val_loss: 577.8105\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 520.1494 - val_loss: 577.3554\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 519.7092 - val_loss: 576.9027\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 519.2697 - val_loss: 576.4426\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 518.8240 - val_loss: 575.9779\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 518.3799 - val_loss: 575.5159\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 517.9370 - val_loss: 575.0572\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 517.4948 - val_loss: 574.6013\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 517.0511 - val_loss: 574.1351\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 516.6039 - val_loss: 573.6748\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 516.1597 - val_loss: 573.2214\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 515.7285 - val_loss: 572.7678\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 515.2910 - val_loss: 572.3138\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 514.8482 - val_loss: 571.8628\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 514.4186 - val_loss: 571.3967\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 513.9711 - val_loss: 570.9404\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 513.5223 - val_loss: 570.4766\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 513.0854 - val_loss: 570.0183\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 512.6403 - val_loss: 569.5598\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 512.1953 - val_loss: 569.0980\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 511.7526 - val_loss: 568.6377\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 511.3105 - val_loss: 568.1702\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 510.8643 - val_loss: 567.7200\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 510.4283 - val_loss: 567.2618\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 509.9861 - val_loss: 566.8016\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 509.5387 - val_loss: 566.3322\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 509.0932 - val_loss: 565.8662\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 508.6426 - val_loss: 565.4080\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 508.2073 - val_loss: 564.9553\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 507.7735 - val_loss: 564.4978\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 507.3326 - val_loss: 564.0496\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 506.9025 - val_loss: 563.6007\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 506.4700 - val_loss: 563.1555\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 506.0395 - val_loss: 562.7048\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 505.6030 - val_loss: 562.2505\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 505.1638 - val_loss: 561.7871\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 504.7206 - val_loss: 561.3359\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 504.2872 - val_loss: 560.8859\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 503.8575 - val_loss: 560.4391\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 503.4292 - val_loss: 560.0004\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 503.0067 - val_loss: 559.5485\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 502.5678 - val_loss: 559.1020\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 502.1381 - val_loss: 558.6454\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 501.7007 - val_loss: 558.1972\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 501.2681 - val_loss: 557.7437\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 500.8336 - val_loss: 557.2975\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 500.4020 - val_loss: 556.8578\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 499.9816 - val_loss: 556.4110\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 499.5436 - val_loss: 555.9578\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 499.1083 - val_loss: 555.5005\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 498.6687 - val_loss: 555.0397\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 498.2288 - val_loss: 554.5922\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 497.8008 - val_loss: 554.1453\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 497.3679 - val_loss: 553.7009\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 496.9417 - val_loss: 553.2562\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 496.5117 - val_loss: 552.8005\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 496.0754 - val_loss: 552.3470\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 495.6354 - val_loss: 551.8907\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 495.2014 - val_loss: 551.4369\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 494.7663 - val_loss: 550.9932\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 494.3416 - val_loss: 550.5613\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 493.9237 - val_loss: 550.1156\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 493.4908 - val_loss: 549.6645\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 493.0597 - val_loss: 549.2192\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 492.6266 - val_loss: 548.7634\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 492.1943 - val_loss: 548.3107\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 491.7584 - val_loss: 547.8649\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 491.3327 - val_loss: 547.4297\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 490.9086 - val_loss: 546.9803\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 490.4726 - val_loss: 546.5219\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 490.0306 - val_loss: 546.0726\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 489.6036 - val_loss: 545.6170\n",
      "3/3 [==============================] - 0s 840us/step - loss: 489.1314\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 11215.7373 - val_loss: 8124.4492\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 6633.8481 - val_loss: 4757.3984\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3793.3755 - val_loss: 2652.0842\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2108.0896 - val_loss: 1519.0750\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1266.0109 - val_loss: 1099.5487\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 856.3892 - val_loss: 806.8393\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 619.9633 - val_loss: 646.0054\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 477.5148 - val_loss: 527.5453\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 385.8374 - val_loss: 435.6519\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 312.4672 - val_loss: 357.7220\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 250.9824 - val_loss: 292.3717\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 202.0910 - val_loss: 242.4238\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 167.2379 - val_loss: 205.9295\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 143.9278 - val_loss: 180.4866\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 129.1436 - val_loss: 164.0182\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 120.2382 - val_loss: 150.6135\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 112.2520 - val_loss: 141.3133\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 106.1834 - val_loss: 131.8240\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 100.4074 - val_loss: 125.2389\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 95.8781 - val_loss: 118.9117\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 92.2269 - val_loss: 113.7678\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 88.8670 - val_loss: 110.4623\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.6409 - val_loss: 107.2571\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 84.2309 - val_loss: 104.5581\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.1615 - val_loss: 102.3790\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.2168 - val_loss: 100.4813\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.5326 - val_loss: 99.1149\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.7428 - val_loss: 97.4722\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.9811 - val_loss: 96.2628\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.2868 - val_loss: 95.4872\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.8665 - val_loss: 94.6755\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.4067 - val_loss: 94.4132\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.9807 - val_loss: 94.2271\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.5145 - val_loss: 94.3479\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.2122 - val_loss: 94.1033\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.9928 - val_loss: 93.8231\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.6626 - val_loss: 93.2178\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.5381 - val_loss: 92.9407\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.2273 - val_loss: 92.9323\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.9497 - val_loss: 92.7298\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.6614 - val_loss: 92.6932\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.5134 - val_loss: 92.4312\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.1863 - val_loss: 92.0091\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.0743 - val_loss: 91.9435\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.8597 - val_loss: 91.8169\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.8130 - val_loss: 91.6615\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.5661 - val_loss: 91.6097\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.1672 - val_loss: 92.1833\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.4586 - val_loss: 92.2178\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.4115 - val_loss: 91.8110\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.9782 - val_loss: 91.4667\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.8407 - val_loss: 91.2878\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.5705 - val_loss: 91.0978\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.6309 - val_loss: 90.9372\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.4334 - val_loss: 90.7914\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.3613 - val_loss: 90.5833\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.1773 - val_loss: 90.4954\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.0399 - val_loss: 90.4357\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.2654 - val_loss: 90.4993\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.9670 - val_loss: 90.3023\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.7763 - val_loss: 90.0926\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.7452 - val_loss: 90.0464\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5882 - val_loss: 89.8726\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.4291 - val_loss: 89.9015\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5826 - val_loss: 90.0753\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5654 - val_loss: 89.7355\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.2491 - val_loss: 89.5896\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.2370 - val_loss: 89.5173\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1254 - val_loss: 89.5563\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.2591 - val_loss: 89.5777\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.1876 - val_loss: 89.3862\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9381 - val_loss: 89.3357\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.8478 - val_loss: 89.5041\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9043 - val_loss: 89.3352\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.7777 - val_loss: 89.1988\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.7964 - val_loss: 89.2165\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.8474 - val_loss: 89.1919\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.6292 - val_loss: 89.2174\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.7540 - val_loss: 89.1886\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.7684 - val_loss: 89.2968\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.7253 - val_loss: 88.9984\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5148 - val_loss: 88.9505\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5246 - val_loss: 88.9589\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.4525 - val_loss: 88.7419\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.3729 - val_loss: 88.5931\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.4836 - val_loss: 89.0116\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5936 - val_loss: 88.6424\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.3631 - val_loss: 88.6824\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5647 - val_loss: 88.6888\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.0595 - val_loss: 88.5778\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1489 - val_loss: 88.5714\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.4327 - val_loss: 88.8920\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.9542 - val_loss: 89.1115\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1987 - val_loss: 88.8891\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8997 - val_loss: 88.6697\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8506 - val_loss: 88.5252\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.5740 - val_loss: 88.9927\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1913 - val_loss: 88.3666\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.0998 - val_loss: 88.3481\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.5495 - val_loss: 88.4018\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.7876 - val_loss: 88.4989\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.6606 - val_loss: 88.3870\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8357 - val_loss: 88.3679\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6961 - val_loss: 88.3622\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.6701 - val_loss: 89.8353\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.6450 - val_loss: 88.5056\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8205 - val_loss: 88.2972\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.5667 - val_loss: 88.3494\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.4434 - val_loss: 88.0637\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3588 - val_loss: 87.9055\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.3785 - val_loss: 87.9492\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.3605 - val_loss: 87.8897\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3818 - val_loss: 87.8309\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.2058 - val_loss: 87.7963\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.0912 - val_loss: 87.7915\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.1135 - val_loss: 87.7393\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.0810 - val_loss: 87.6125\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.0003 - val_loss: 87.6149\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.9869 - val_loss: 87.6415\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.0023 - val_loss: 87.6157\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1007 - val_loss: 87.5121\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.0759 - val_loss: 87.6261\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.8313 - val_loss: 87.4502\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.0307 - val_loss: 87.6538\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9635 - val_loss: 87.3693\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.9422 - val_loss: 87.4965\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9852 - val_loss: 87.5797\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.7994 - val_loss: 87.6138\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.6086 - val_loss: 87.4338\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.5742 - val_loss: 87.1742\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4734 - val_loss: 87.4158\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.5846 - val_loss: 87.8621\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.4794 - val_loss: 87.5303\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.2940 - val_loss: 87.7959\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.3717 - val_loss: 87.5767\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.7455 - val_loss: 87.8603\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.6025 - val_loss: 87.5455\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.2433 - val_loss: 87.7058\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.6425 - val_loss: 88.0378\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9571 - val_loss: 87.8228\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9469 - val_loss: 87.5996\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0298 - val_loss: 87.6518\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6391 - val_loss: 87.7816\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7641 - val_loss: 87.9751\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6295 - val_loss: 87.6569\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7407 - val_loss: 87.4272\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.5456 - val_loss: 87.7806\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6684 - val_loss: 87.8406\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6962 - val_loss: 87.8355\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.5314 - val_loss: 87.8653\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8363 - val_loss: 87.4817\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6698 - val_loss: 87.5533\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 63.5053 - val_loss: 87.8882\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7786 - val_loss: 87.3118\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2328 - val_loss: 87.3723\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2862 - val_loss: 87.5144\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2306 - val_loss: 87.3572\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1924 - val_loss: 87.1715\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3386 - val_loss: 87.5101\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1657 - val_loss: 87.2632\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0768 - val_loss: 87.2212\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0179 - val_loss: 86.9761\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0822 - val_loss: 87.0903\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.8352 - val_loss: 86.9411\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2501 - val_loss: 87.3738\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.8665 - val_loss: 90.6617\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9930 - val_loss: 88.5409\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0914 - val_loss: 87.1107\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8995 - val_loss: 86.9176\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9342 - val_loss: 86.9168\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7173 - val_loss: 86.7607\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 62.6802 - val_loss: 86.4174\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4361 - val_loss: 86.4119\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2905 - val_loss: 86.5051\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.5724 - val_loss: 86.4950\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.9411 - val_loss: 86.2123\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3870 - val_loss: 86.2805\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.3045 - val_loss: 86.2171\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3637 - val_loss: 86.2292\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2348 - val_loss: 86.4184\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.4157 - val_loss: 86.3423\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 62.9848 - val_loss: 86.3659\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1082 - val_loss: 86.0832\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.1689 - val_loss: 85.9329\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.3077 - val_loss: 85.9270\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9817 - val_loss: 85.8230\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.5150 - val_loss: 86.0726\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9013 - val_loss: 85.8135\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2081 - val_loss: 86.0711\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2810 - val_loss: 85.7657\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.0630 - val_loss: 85.5987\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9796 - val_loss: 85.4966\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.7644 - val_loss: 85.4670\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9065 - val_loss: 85.2908\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.7573 - val_loss: 85.2485\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9874 - val_loss: 85.2705\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7733 - val_loss: 85.4460\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6439 - val_loss: 85.2035\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6274 - val_loss: 85.2803\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.7412 - val_loss: 86.7595\n",
      "3/3 [==============================] - 0s 963us/step - loss: 59.4905\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1151.5131 - val_loss: 829.4683\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 625.8120 - val_loss: 551.1699\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 434.3601 - val_loss: 431.2465\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 347.0832 - val_loss: 357.6268\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 283.7210 - val_loss: 298.0840\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 234.6087 - val_loss: 251.4779\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 195.9885 - val_loss: 209.8820\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 160.1890 - val_loss: 171.8645\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 130.6437 - val_loss: 142.9100\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 110.9777 - val_loss: 122.2133\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.6107 - val_loss: 105.6436\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 87.0588 - val_loss: 93.4745\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.1249 - val_loss: 85.0811\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.6878 - val_loss: 79.3439\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.0090 - val_loss: 74.1805\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.8319 - val_loss: 74.2876\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.1252 - val_loss: 73.3504\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.4102 - val_loss: 72.7630\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.0130 - val_loss: 72.9404\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.9074 - val_loss: 73.4213\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8416 - val_loss: 73.8651\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8716 - val_loss: 73.7681\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9793 - val_loss: 73.5176\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.0090 - val_loss: 72.8373\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.7524 - val_loss: 73.0927\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.0549 - val_loss: 73.7526\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.3974 - val_loss: 72.9337\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.3584 - val_loss: 72.8975\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6568 - val_loss: 73.6671\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1874 - val_loss: 73.6990\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.4211 - val_loss: 73.2271\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3456 - val_loss: 71.1819\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2294 - val_loss: 71.3565\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2826 - val_loss: 71.0040\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.6844 - val_loss: 72.6083\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 62.1000 - val_loss: 71.1319\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6807 - val_loss: 71.2321\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.0981 - val_loss: 71.5199\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.4710 - val_loss: 71.6339\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.8524 - val_loss: 71.3836\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.2625 - val_loss: 72.1799\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.4155 - val_loss: 72.7776\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3949 - val_loss: 72.4591\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9436 - val_loss: 74.6030\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5516 - val_loss: 71.6954\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3659 - val_loss: 71.0041\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7284 - val_loss: 71.4455\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1992 - val_loss: 72.5332\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3230 - val_loss: 72.1940\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9573 - val_loss: 70.6573\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1121 - val_loss: 70.9412\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5375 - val_loss: 70.6634\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1463 - val_loss: 69.8455\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4244 - val_loss: 69.5295\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7837 - val_loss: 69.8651\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9494 - val_loss: 70.5193\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0250 - val_loss: 69.8563\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9100 - val_loss: 67.5943\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5020 - val_loss: 69.0044\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3035 - val_loss: 68.8375\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9955 - val_loss: 68.3318\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0427 - val_loss: 68.0376\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.7706 - val_loss: 68.5324\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8269 - val_loss: 68.2169\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5179 - val_loss: 67.6967\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.3411 - val_loss: 68.2573\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.4535 - val_loss: 69.0639\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2434 - val_loss: 68.3645\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8533 - val_loss: 67.4142\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.6087 - val_loss: 66.3638\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5079 - val_loss: 66.2223\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4250 - val_loss: 66.2897\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5393 - val_loss: 69.6275\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6439 - val_loss: 70.6177\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8929 - val_loss: 70.5198\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.2875 - val_loss: 67.4281\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1467 - val_loss: 66.0466\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0133 - val_loss: 65.8023\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9390 - val_loss: 67.8101\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2879 - val_loss: 67.3369\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.0305 - val_loss: 66.4400\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7558 - val_loss: 66.0394\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1367 - val_loss: 66.5205\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.1756 - val_loss: 68.2055\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5148 - val_loss: 67.8098\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.4296 - val_loss: 66.7895\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8234 - val_loss: 65.6079\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9991 - val_loss: 66.2092\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.3967 - val_loss: 64.5254\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9189 - val_loss: 65.6301\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 54.9585 - val_loss: 63.6137\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3081 - val_loss: 63.7056\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7011 - val_loss: 63.6537\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.1487 - val_loss: 64.1496\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2909 - val_loss: 63.9874\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3386 - val_loss: 64.0507\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7589 - val_loss: 64.6783\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4774 - val_loss: 63.7232\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8829 - val_loss: 62.0771\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9906 - val_loss: 62.8826\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8663 - val_loss: 64.0021\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9727 - val_loss: 62.1175\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.0597 - val_loss: 61.1940\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2165 - val_loss: 61.8255\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1554 - val_loss: 61.3304\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.8292 - val_loss: 62.8263\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.9386 - val_loss: 61.8507\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8964 - val_loss: 61.1282\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4745 - val_loss: 62.7409\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3771 - val_loss: 59.9790\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.3476 - val_loss: 64.3131\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0772 - val_loss: 74.6349\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1783 - val_loss: 64.4768\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2442 - val_loss: 59.6375\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0345 - val_loss: 59.4914\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3304 - val_loss: 61.3928\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7498 - val_loss: 60.0192\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4268 - val_loss: 59.1600\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0485 - val_loss: 60.1958\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0674 - val_loss: 58.6779\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1495 - val_loss: 60.1276\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.8593 - val_loss: 59.5724\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.5628 - val_loss: 58.1378\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9676 - val_loss: 59.0664\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9085 - val_loss: 59.2111\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5081 - val_loss: 57.0512\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.4579 - val_loss: 56.4458\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7235 - val_loss: 57.2226\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3982 - val_loss: 57.8277\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4757 - val_loss: 56.8931\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.8833 - val_loss: 56.3692\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7582 - val_loss: 57.7509\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7562 - val_loss: 55.7579\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.4180 - val_loss: 56.4910\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0675 - val_loss: 55.6781\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5532 - val_loss: 56.9965\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.0260 - val_loss: 57.3404\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1400 - val_loss: 55.0671\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7739 - val_loss: 55.7633\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8622 - val_loss: 56.5663\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8083 - val_loss: 55.5961\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 50.3052 - val_loss: 54.7315\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4711 - val_loss: 56.2960\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5682 - val_loss: 53.9365\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4221 - val_loss: 54.3570\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5797 - val_loss: 54.4911\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.2251 - val_loss: 57.9146\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.3819 - val_loss: 52.5067\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0942 - val_loss: 54.7892\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.0434 - val_loss: 50.1646\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8939 - val_loss: 53.7538\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6079 - val_loss: 54.6631\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7493 - val_loss: 51.5402\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8220 - val_loss: 53.6687\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7724 - val_loss: 51.2965\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6179 - val_loss: 51.8322\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8512 - val_loss: 52.3671\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3668 - val_loss: 54.5307\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5389 - val_loss: 53.1925\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7479 - val_loss: 51.5990\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1141 - val_loss: 48.7308\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3509 - val_loss: 53.0149\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3746 - val_loss: 52.5861\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7174 - val_loss: 49.0432\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1447 - val_loss: 53.4094\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.4873 - val_loss: 59.1705\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7228 - val_loss: 51.6380\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9736 - val_loss: 51.2298\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 43.9949 - val_loss: 50.1798\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.2746 - val_loss: 50.7760\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6842 - val_loss: 51.5972\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.8761 - val_loss: 49.7664\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4579 - val_loss: 52.6753\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 44.0380 - val_loss: 52.0793\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1498 - val_loss: 48.2002\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.7970 - val_loss: 48.5983\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0730 - val_loss: 49.1815\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.8689 - val_loss: 48.5498\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.8072 - val_loss: 47.9005\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.8641 - val_loss: 47.2699\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.1297 - val_loss: 49.9883\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9708 - val_loss: 49.9321\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9776 - val_loss: 48.1307\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6568 - val_loss: 47.8612\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.6954 - val_loss: 46.5559\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 42.2148 - val_loss: 44.3740\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0339 - val_loss: 45.6016\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2422 - val_loss: 47.2074\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.0324 - val_loss: 48.7539\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.1282 - val_loss: 46.1157\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9332 - val_loss: 44.1830\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.7959 - val_loss: 46.6000\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2969 - val_loss: 48.1125\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.4250 - val_loss: 44.9567\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 41.1043 - val_loss: 45.0849\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5289 - val_loss: 45.1102\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.0603 - val_loss: 43.8013\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.8022 - val_loss: 44.9092\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6591 - val_loss: 45.5367\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5831 - val_loss: 44.6966\n",
      "3/3 [==============================] - 0s 860us/step - loss: 27.1568\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 546.0020 - val_loss: 595.7819\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 499.1676 - val_loss: 525.9066\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 406.7081 - val_loss: 408.8715\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 283.1788 - val_loss: 256.1351\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 135.3046 - val_loss: 130.2332\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.8757 - val_loss: 107.8752\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.0532 - val_loss: 101.7977\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.8524 - val_loss: 91.1230\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.5799 - val_loss: 84.9928\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7696 - val_loss: 83.2691\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7264 - val_loss: 82.7180\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8650 - val_loss: 78.7763\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.2875 - val_loss: 78.9300\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8255 - val_loss: 81.8431\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6780 - val_loss: 80.0730\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.1768 - val_loss: 78.8202\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0172 - val_loss: 76.5593\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.5098 - val_loss: 79.0046\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.4427 - val_loss: 79.0928\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7700 - val_loss: 76.9913\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5319 - val_loss: 76.5452\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4864 - val_loss: 77.9887\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.6296 - val_loss: 75.0301\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5412 - val_loss: 74.5086\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9492 - val_loss: 78.6007\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2787 - val_loss: 75.3588\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.2963 - val_loss: 75.7737\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8368 - val_loss: 77.2692\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.8323 - val_loss: 76.8671\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7020 - val_loss: 76.4358\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.8795 - val_loss: 77.1029\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0578 - val_loss: 74.8181\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.7642 - val_loss: 74.2550\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7803 - val_loss: 74.9123\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.6404 - val_loss: 74.4477\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9056 - val_loss: 73.1052\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3982 - val_loss: 75.3357\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4162 - val_loss: 73.8628\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4955 - val_loss: 72.6720\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.5148 - val_loss: 75.5826\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9843 - val_loss: 73.1442\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.2842 - val_loss: 71.7549\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.5250 - val_loss: 72.2405\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8919 - val_loss: 74.4470\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.5656 - val_loss: 73.8773\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3652 - val_loss: 72.5724\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.7213 - val_loss: 73.2745\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1311 - val_loss: 71.8244\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9293 - val_loss: 73.1783\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4412 - val_loss: 74.1777\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.1676 - val_loss: 73.1031\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0672 - val_loss: 72.4994\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6743 - val_loss: 71.8394\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6121 - val_loss: 72.5307\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.6550 - val_loss: 71.7754\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5482 - val_loss: 72.1922\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2554 - val_loss: 70.9341\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4993 - val_loss: 71.7385\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1945 - val_loss: 71.6146\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2745 - val_loss: 71.6784\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3313 - val_loss: 71.9802\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6116 - val_loss: 71.2599\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8714 - val_loss: 72.9729\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2754 - val_loss: 71.2459\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6952 - val_loss: 71.1786\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6728 - val_loss: 70.6911\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.7787 - val_loss: 69.8364\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6664 - val_loss: 70.6767\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5006 - val_loss: 70.6240\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7153 - val_loss: 71.2783\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2967 - val_loss: 69.6633\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.2561 - val_loss: 70.1966\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.0819 - val_loss: 70.5758\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5223 - val_loss: 69.2598\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.1888 - val_loss: 70.5554\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.5962 - val_loss: 70.8771\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7073 - val_loss: 68.9786\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9162 - val_loss: 70.4894\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.9996 - val_loss: 69.7167\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.7753 - val_loss: 69.5129\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7395 - val_loss: 69.4478\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.6365 - val_loss: 70.9923\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5351 - val_loss: 70.1192\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8264 - val_loss: 68.9819\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5155 - val_loss: 73.2197\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0927 - val_loss: 69.6903\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1113 - val_loss: 68.3657\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.1978 - val_loss: 68.4960\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0557 - val_loss: 69.6312\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0199 - val_loss: 68.9706\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8718 - val_loss: 69.0204\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8048 - val_loss: 68.7585\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6377 - val_loss: 69.2458\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6705 - val_loss: 67.3924\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7054 - val_loss: 68.5108\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5854 - val_loss: 67.6423\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.5295 - val_loss: 68.7151\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3716 - val_loss: 68.2396\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3826 - val_loss: 67.3653\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2042 - val_loss: 68.4096\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4114 - val_loss: 69.3045\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4312 - val_loss: 67.8711\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.3217 - val_loss: 68.6853\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1251 - val_loss: 68.1547\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9798 - val_loss: 68.5340\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0400 - val_loss: 67.3885\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.6763 - val_loss: 66.9135\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0164 - val_loss: 67.6114\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.7147 - val_loss: 67.9578\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5017 - val_loss: 67.1815\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3887 - val_loss: 66.9115\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3900 - val_loss: 66.5626\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7381 - val_loss: 68.5461\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1961 - val_loss: 65.5001\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1371 - val_loss: 66.4858\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 47.7816 - val_loss: 71.5906\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.9831 - val_loss: 65.8135\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2201 - val_loss: 65.3663\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5373 - val_loss: 68.1941\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0610 - val_loss: 69.2119\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.5998 - val_loss: 65.6030\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.6648 - val_loss: 66.9355\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3107 - val_loss: 69.2978\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7748 - val_loss: 66.8398\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8939 - val_loss: 65.4142\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5261 - val_loss: 67.0202\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.1004 - val_loss: 67.1783\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.4173 - val_loss: 66.2561\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2383 - val_loss: 68.1373\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1997 - val_loss: 66.2530\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.7938 - val_loss: 65.2910\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.7578 - val_loss: 68.0561\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1986 - val_loss: 65.9724\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0257 - val_loss: 64.7661\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0015 - val_loss: 64.6439\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 45.7575 - val_loss: 65.5760\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6072 - val_loss: 65.2017\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5394 - val_loss: 66.1979\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.6392 - val_loss: 66.1218\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4631 - val_loss: 64.8617\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5795 - val_loss: 65.1491\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7310 - val_loss: 65.0661\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.4075 - val_loss: 67.4907\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9068 - val_loss: 66.0022\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.2469 - val_loss: 64.6708\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1403 - val_loss: 65.4032\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0553 - val_loss: 64.9810\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0417 - val_loss: 65.3598\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0939 - val_loss: 65.4388\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6358 - val_loss: 63.7779\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0428 - val_loss: 64.8366\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1725 - val_loss: 64.5548\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8813 - val_loss: 63.4909\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6162 - val_loss: 65.1496\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.7825 - val_loss: 64.7512\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0910 - val_loss: 64.5771\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.0530 - val_loss: 62.9089\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4362 - val_loss: 65.7686\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5948 - val_loss: 63.0064\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4815 - val_loss: 63.8010\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6122 - val_loss: 64.1753\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5420 - val_loss: 62.1389\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.5765 - val_loss: 62.8753\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2600 - val_loss: 62.8455\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6052 - val_loss: 63.0673\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3324 - val_loss: 64.4774\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7654 - val_loss: 61.8691\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.9475 - val_loss: 63.7986\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1565 - val_loss: 62.8925\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.3552 - val_loss: 61.7152\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9879 - val_loss: 64.5326\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7468 - val_loss: 62.1111\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1200 - val_loss: 63.3696\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6744 - val_loss: 62.2519\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4480 - val_loss: 64.1927\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1126 - val_loss: 64.2364\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5031 - val_loss: 62.0309\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.4200 - val_loss: 63.1451\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1283 - val_loss: 61.5492\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3271 - val_loss: 62.6194\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2186 - val_loss: 63.8978\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3106 - val_loss: 62.5477\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0511 - val_loss: 60.8765\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1749 - val_loss: 63.4025\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4065 - val_loss: 62.6388\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1166 - val_loss: 60.8915\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0878 - val_loss: 61.8508\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8153 - val_loss: 60.7367\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2898 - val_loss: 61.5227\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.0125 - val_loss: 62.4686\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.9356 - val_loss: 61.8125\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.2422 - val_loss: 60.4305\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.9932 - val_loss: 69.5986\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.1594 - val_loss: 61.5728\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1659 - val_loss: 60.6564\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3014 - val_loss: 62.6016\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9739 - val_loss: 60.0048\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6635 - val_loss: 60.9718\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2992 - val_loss: 61.6546\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1610 - val_loss: 61.4814\n",
      "3/3 [==============================] - 0s 906us/step - loss: 69.5868\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 106.4200 - val_loss: 128.5847\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.5234 - val_loss: 99.2314\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.4441 - val_loss: 95.9732\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 60.6551 - val_loss: 89.0230\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9803 - val_loss: 86.4576\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5306 - val_loss: 86.0843\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2808 - val_loss: 81.8842\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3096 - val_loss: 93.9211\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4226 - val_loss: 83.3053\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.9114 - val_loss: 77.3879\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2019 - val_loss: 78.3085\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.7393 - val_loss: 78.5048\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1396 - val_loss: 74.8972\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8637 - val_loss: 81.8742\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3390 - val_loss: 75.9036\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.9005 - val_loss: 76.9200\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0261 - val_loss: 71.3887\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1186 - val_loss: 68.9138\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8632 - val_loss: 68.6125\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9560 - val_loss: 78.3913\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1297 - val_loss: 66.6920\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1565 - val_loss: 73.3188\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8725 - val_loss: 66.9606\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0284 - val_loss: 67.2689\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5388 - val_loss: 66.1055\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6081 - val_loss: 64.1252\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7646 - val_loss: 90.2729\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2921 - val_loss: 61.7891\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8011 - val_loss: 60.6811\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.1903 - val_loss: 65.7558\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5309 - val_loss: 64.0298\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3067 - val_loss: 59.1247\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6403 - val_loss: 66.6906\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4107 - val_loss: 60.7128\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.2648 - val_loss: 64.9245\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5456 - val_loss: 58.3415\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2691 - val_loss: 59.5249\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.2768 - val_loss: 65.4063\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9163 - val_loss: 58.2889\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9934 - val_loss: 55.8484\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3273 - val_loss: 54.7430\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9854 - val_loss: 55.4317\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3885 - val_loss: 57.3095\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0786 - val_loss: 54.8168\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8057 - val_loss: 53.2997\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4254 - val_loss: 55.5211\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1881 - val_loss: 54.8210\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.0402 - val_loss: 57.2898\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6652 - val_loss: 51.9682\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8801 - val_loss: 52.5172\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1136 - val_loss: 52.5788\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8173 - val_loss: 54.7281\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1283 - val_loss: 51.7822\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7515 - val_loss: 51.3034\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3101 - val_loss: 51.7920\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.7181 - val_loss: 50.2910\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8177 - val_loss: 60.1552\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6262 - val_loss: 51.7634\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1189 - val_loss: 51.8588\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3423 - val_loss: 48.3016\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2541 - val_loss: 58.4326\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0329 - val_loss: 56.8513\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1181 - val_loss: 47.6637\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1144 - val_loss: 46.0334\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6336 - val_loss: 53.6136\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.6941 - val_loss: 50.1855\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0822 - val_loss: 47.2347\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3772 - val_loss: 47.1291\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5913 - val_loss: 54.8400\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1997 - val_loss: 47.2396\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7956 - val_loss: 52.0416\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0243 - val_loss: 47.8149\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9669 - val_loss: 45.7282\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8318 - val_loss: 46.0549\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1644 - val_loss: 51.4614\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8578 - val_loss: 51.0730\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2682 - val_loss: 44.9711\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4849 - val_loss: 47.2929\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2576 - val_loss: 46.4626\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.3291 - val_loss: 43.0357\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5119 - val_loss: 42.5326\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2684 - val_loss: 43.4048\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3719 - val_loss: 48.2743\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6162 - val_loss: 41.9307\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.3556 - val_loss: 44.1996\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9544 - val_loss: 43.7766\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.7058 - val_loss: 44.0014\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1467 - val_loss: 42.5491\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5726 - val_loss: 44.4548\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7455 - val_loss: 40.7751\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1709 - val_loss: 41.2478\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4628 - val_loss: 42.0526\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6144 - val_loss: 47.5653\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.9194 - val_loss: 46.1991\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9148 - val_loss: 40.8663\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6531 - val_loss: 40.3378\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0138 - val_loss: 59.7101\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6475 - val_loss: 48.6597\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6403 - val_loss: 43.0248\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8475 - val_loss: 42.3851\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2770 - val_loss: 40.1655\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2911 - val_loss: 41.0948\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9331 - val_loss: 39.2248\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8870 - val_loss: 38.2773\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.9846 - val_loss: 41.2453\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9824 - val_loss: 42.1699\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4480 - val_loss: 41.9527\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7738 - val_loss: 37.6846\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7571 - val_loss: 38.7097\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5541 - val_loss: 41.3995\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4647 - val_loss: 43.3586\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0365 - val_loss: 38.4757\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4382 - val_loss: 38.6494\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.0419 - val_loss: 44.1384\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2046 - val_loss: 54.2274\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.4832 - val_loss: 42.5848\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9317 - val_loss: 38.4677\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1114 - val_loss: 56.7227\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7363 - val_loss: 38.9312\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7851 - val_loss: 41.4449\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7044 - val_loss: 39.1223\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6091 - val_loss: 40.2984\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.5814 - val_loss: 38.7568\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1525 - val_loss: 42.4511\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5647 - val_loss: 36.1241\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3108 - val_loss: 49.3753\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7256 - val_loss: 39.1233\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3705 - val_loss: 34.9499\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2632 - val_loss: 39.4046\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5559 - val_loss: 35.8823\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.0469 - val_loss: 34.4008\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5970 - val_loss: 40.8680\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.1661 - val_loss: 36.9775\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1586 - val_loss: 35.5351\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3447 - val_loss: 34.6873\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7319 - val_loss: 40.2967\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2602 - val_loss: 36.9249\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9440 - val_loss: 38.2608\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6612 - val_loss: 34.3507\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7298 - val_loss: 34.8506\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8343 - val_loss: 46.8067\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.0891 - val_loss: 34.5093\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7932 - val_loss: 33.5976\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3104 - val_loss: 33.2666\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3230 - val_loss: 34.9162\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1494 - val_loss: 34.7711\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.6915 - val_loss: 37.5582\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3936 - val_loss: 33.4506\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5160 - val_loss: 32.6556\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.4263 - val_loss: 33.1577\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6831 - val_loss: 33.9738\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1902 - val_loss: 32.8494\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1776 - val_loss: 31.9282\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1083 - val_loss: 32.9067\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0214 - val_loss: 35.4301\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8492 - val_loss: 32.6713\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6947 - val_loss: 32.5181\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5900 - val_loss: 36.1316\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2752 - val_loss: 33.6337\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6339 - val_loss: 31.2352\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5081 - val_loss: 38.6208\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4032 - val_loss: 34.0294\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6042 - val_loss: 31.4621\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2968 - val_loss: 33.9714\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8086 - val_loss: 35.1342\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5295 - val_loss: 37.5536\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1252 - val_loss: 32.9683\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7194 - val_loss: 35.2336\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5093 - val_loss: 34.6151\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4152 - val_loss: 31.3376\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.8502 - val_loss: 30.0803\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0300 - val_loss: 30.2811\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3325 - val_loss: 29.5323\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1530 - val_loss: 31.0601\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2666 - val_loss: 38.8932\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0651 - val_loss: 29.5134\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9745 - val_loss: 32.1798\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0216 - val_loss: 28.9872\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9642 - val_loss: 29.9966\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0325 - val_loss: 33.4218\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6954 - val_loss: 33.2866\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6868 - val_loss: 31.2246\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8186 - val_loss: 33.5594\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9045 - val_loss: 28.8410\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2349 - val_loss: 34.9013\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6712 - val_loss: 27.8650\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7754 - val_loss: 28.8513\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0930 - val_loss: 28.1319\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8094 - val_loss: 30.9620\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.0954 - val_loss: 30.3116\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0757 - val_loss: 34.4200\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.8046 - val_loss: 31.7154\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2856 - val_loss: 30.4781\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5487 - val_loss: 28.5482\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2438 - val_loss: 29.4929\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9509 - val_loss: 29.4056\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8101 - val_loss: 34.9228\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3332 - val_loss: 34.0960\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.2802 - val_loss: 31.7116\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5665 - val_loss: 27.6019\n",
      "3/3 [==============================] - 0s 776us/step - loss: 27.9692\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3248.9939 - val_loss: 1189.9817\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 772.0034 - val_loss: 726.2209\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 482.3400 - val_loss: 395.2886\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 217.9104 - val_loss: 227.8827\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 162.2010 - val_loss: 161.4389\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 107.2079 - val_loss: 123.6872\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.6445 - val_loss: 102.1948\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.7514 - val_loss: 87.8771\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.7039 - val_loss: 79.7232\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2640 - val_loss: 74.2120\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0028 - val_loss: 71.5667\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2999 - val_loss: 68.9422\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7386 - val_loss: 69.2873\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6399 - val_loss: 68.6176\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.4749 - val_loss: 64.8477\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4239 - val_loss: 64.8969\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3534 - val_loss: 62.0806\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8371 - val_loss: 61.2800\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.3179 - val_loss: 62.5715\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5147 - val_loss: 59.9564\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0716 - val_loss: 59.9848\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3896 - val_loss: 60.1144\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8098 - val_loss: 61.8290\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4551 - val_loss: 58.1814\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0738 - val_loss: 56.6095\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9945 - val_loss: 58.3419\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4554 - val_loss: 57.8067\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3306 - val_loss: 56.7210\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1296 - val_loss: 55.6186\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7318 - val_loss: 55.5038\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7666 - val_loss: 55.3647\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7150 - val_loss: 57.2049\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9457 - val_loss: 53.9436\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1293 - val_loss: 56.4642\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.6000 - val_loss: 51.7868\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3668 - val_loss: 54.8388\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.2440 - val_loss: 55.6755\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9381 - val_loss: 51.7924\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0915 - val_loss: 50.2031\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6445 - val_loss: 52.4138\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6777 - val_loss: 51.3479\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6771 - val_loss: 50.1358\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6944 - val_loss: 48.2703\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3038 - val_loss: 49.9049\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6199 - val_loss: 48.2665\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1986 - val_loss: 47.1824\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.9859 - val_loss: 47.2398\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6541 - val_loss: 47.9370\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7075 - val_loss: 45.3205\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6690 - val_loss: 47.1112\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0504 - val_loss: 61.4855\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.2128 - val_loss: 53.0822\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8758 - val_loss: 56.7847\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1989 - val_loss: 45.6108\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7397 - val_loss: 45.4184\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.7670 - val_loss: 44.3106\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4365 - val_loss: 43.3124\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2031 - val_loss: 42.7085\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3615 - val_loss: 43.1351\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8884 - val_loss: 42.0156\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2597 - val_loss: 43.4774\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0078 - val_loss: 42.9017\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0118 - val_loss: 42.1364\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8453 - val_loss: 45.0946\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0364 - val_loss: 47.1356\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.9342 - val_loss: 42.0093\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4195 - val_loss: 44.2057\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8702 - val_loss: 40.4401\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8651 - val_loss: 40.9738\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1694 - val_loss: 40.3231\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6785 - val_loss: 42.0362\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6040 - val_loss: 39.4710\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6929 - val_loss: 38.3653\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4941 - val_loss: 37.3983\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.2976 - val_loss: 38.8291\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6107 - val_loss: 39.9903\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.3759 - val_loss: 38.6267\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4224 - val_loss: 39.1190\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8163 - val_loss: 46.8042\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2385 - val_loss: 40.2879\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 33.5109 - val_loss: 46.5116\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9899 - val_loss: 36.9907\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2289 - val_loss: 37.8060\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2746 - val_loss: 36.7260\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.4652 - val_loss: 39.1209\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8465 - val_loss: 36.6355\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5560 - val_loss: 57.7293\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9662 - val_loss: 35.7382\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4193 - val_loss: 36.0351\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2673 - val_loss: 37.6365\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3377 - val_loss: 36.6232\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4277 - val_loss: 35.4602\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.5714 - val_loss: 35.7991\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8466 - val_loss: 34.8190\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3716 - val_loss: 34.2856\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9297 - val_loss: 34.8620\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9326 - val_loss: 35.2863\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8310 - val_loss: 34.7254\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2138 - val_loss: 32.8878\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2653 - val_loss: 36.0509\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4572 - val_loss: 33.7180\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7252 - val_loss: 33.9678\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9399 - val_loss: 35.3306\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5653 - val_loss: 35.7435\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.7005 - val_loss: 32.5072\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7418 - val_loss: 31.6789\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4380 - val_loss: 36.1685\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7511 - val_loss: 41.4051\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2264 - val_loss: 34.5479\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2485 - val_loss: 31.8075\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2544 - val_loss: 34.8346\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2568 - val_loss: 33.4952\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0468 - val_loss: 31.8320\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2351 - val_loss: 31.7878\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8028 - val_loss: 30.6222\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.3295 - val_loss: 31.1738\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2514 - val_loss: 36.0055\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5291 - val_loss: 31.7530\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9176 - val_loss: 30.6999\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2611 - val_loss: 40.3150\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.8917 - val_loss: 32.6347\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3185 - val_loss: 29.9761\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.3700 - val_loss: 29.8860\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0805 - val_loss: 31.4111\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.3941 - val_loss: 31.2825\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4888 - val_loss: 31.9599\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1902 - val_loss: 39.0693\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9113 - val_loss: 30.0353\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1787 - val_loss: 30.0495\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8785 - val_loss: 30.1833\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.7335 - val_loss: 31.1612\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.0511 - val_loss: 31.6873\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7480 - val_loss: 47.3359\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6901 - val_loss: 37.0718\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4586 - val_loss: 28.6616\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0791 - val_loss: 36.5110\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4717 - val_loss: 30.6794\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1203 - val_loss: 30.0470\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7547 - val_loss: 29.6345\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 23.0867 - val_loss: 31.3752\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1579 - val_loss: 29.3176\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.5320 - val_loss: 29.8317\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.7822 - val_loss: 34.8932\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3714 - val_loss: 31.9887\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2115 - val_loss: 30.9681\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1467 - val_loss: 28.8258\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.0965 - val_loss: 31.0607\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6099 - val_loss: 33.6302\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4561 - val_loss: 28.4237\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7658 - val_loss: 29.2003\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.7138 - val_loss: 28.9894\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4883 - val_loss: 27.7028\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5153 - val_loss: 39.0233\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8750 - val_loss: 30.6976\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1191 - val_loss: 27.2773\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 22.6416 - val_loss: 28.6966\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.0359 - val_loss: 29.1191\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6984 - val_loss: 33.0868\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1813 - val_loss: 33.9124\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.3474 - val_loss: 29.1756\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.1050 - val_loss: 27.8226\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1121 - val_loss: 35.6475\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6423 - val_loss: 33.7678\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4132 - val_loss: 31.2463\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 23.9691 - val_loss: 28.6392\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.1449 - val_loss: 28.8821\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9151 - val_loss: 26.6746\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.3028 - val_loss: 27.8024\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4964 - val_loss: 31.3418\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.9845 - val_loss: 26.7296\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7128 - val_loss: 28.6666\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6569 - val_loss: 28.2307\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3513 - val_loss: 27.8525\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6053 - val_loss: 28.4118\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9586 - val_loss: 27.8103\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7064 - val_loss: 27.9331\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.9494 - val_loss: 27.6528\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5598 - val_loss: 29.6566\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.4017 - val_loss: 32.1928\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1465 - val_loss: 40.1283\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3400 - val_loss: 41.5154\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2442 - val_loss: 32.7078\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4633 - val_loss: 28.5539\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.7172 - val_loss: 28.7537\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6817 - val_loss: 29.0285\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1152 - val_loss: 27.6353\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5261 - val_loss: 30.2597\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1349 - val_loss: 28.1110\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.5896 - val_loss: 28.3727\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7824 - val_loss: 28.7382\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.7499 - val_loss: 28.8126\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3201 - val_loss: 27.3901\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4222 - val_loss: 44.2922\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2811 - val_loss: 28.2045\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.0004 - val_loss: 26.1910\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.1445 - val_loss: 29.4724\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2871 - val_loss: 27.2110\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.3379 - val_loss: 26.2520\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.0893 - val_loss: 27.4877\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.2165 - val_loss: 42.7596\n",
      "3/3 [==============================] - 0s 801us/step - loss: 43.5740\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 137.9704 - val_loss: 111.1748\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 90.6155 - val_loss: 88.9207\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.0250 - val_loss: 97.0090\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.4373 - val_loss: 83.6781\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8231 - val_loss: 82.0157\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4260 - val_loss: 82.6625\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7496 - val_loss: 81.8499\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.7857 - val_loss: 76.2865\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5355 - val_loss: 77.8205\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2066 - val_loss: 72.2215\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6073 - val_loss: 70.1246\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0403 - val_loss: 83.6093\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.8430 - val_loss: 73.2385\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.3610 - val_loss: 85.3097\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5322 - val_loss: 81.7308\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1949 - val_loss: 66.1425\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6987 - val_loss: 72.0161\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.9187 - val_loss: 64.0476\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0486 - val_loss: 63.7420\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5963 - val_loss: 65.6628\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6827 - val_loss: 71.6624\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.4641 - val_loss: 60.0740\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7272 - val_loss: 60.8351\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5268 - val_loss: 61.1919\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7338 - val_loss: 64.8281\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7266 - val_loss: 59.8703\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3385 - val_loss: 59.4937\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9775 - val_loss: 63.0997\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5854 - val_loss: 55.1390\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7750 - val_loss: 57.8384\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8299 - val_loss: 54.2760\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.6692 - val_loss: 52.1133\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2382 - val_loss: 53.7902\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.5131 - val_loss: 53.8011\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0633 - val_loss: 52.5287\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1265 - val_loss: 58.3011\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3650 - val_loss: 57.9805\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.6050 - val_loss: 52.2009\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8412 - val_loss: 56.7350\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5293 - val_loss: 54.5953\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9945 - val_loss: 47.6851\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8575 - val_loss: 66.4675\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.3759 - val_loss: 55.9951\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5121 - val_loss: 55.4438\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3286 - val_loss: 48.9521\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6336 - val_loss: 45.3415\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6448 - val_loss: 45.9101\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2335 - val_loss: 52.2355\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3030 - val_loss: 45.5560\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9590 - val_loss: 43.2802\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3126 - val_loss: 44.7856\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2492 - val_loss: 44.7803\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0760 - val_loss: 42.3455\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5140 - val_loss: 41.3005\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8202 - val_loss: 40.9518\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9346 - val_loss: 43.4301\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6428 - val_loss: 45.0475\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7732 - val_loss: 45.4343\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2665 - val_loss: 40.4458\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7484 - val_loss: 41.5574\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4400 - val_loss: 41.2607\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6169 - val_loss: 40.3466\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3496 - val_loss: 39.7237\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5280 - val_loss: 39.3348\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.2911 - val_loss: 45.3225\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1849 - val_loss: 43.6212\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4716 - val_loss: 38.3487\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5018 - val_loss: 37.8646\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.2558 - val_loss: 37.5938\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.1246 - val_loss: 39.9113\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0680 - val_loss: 40.8732\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0945 - val_loss: 66.3770\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7867 - val_loss: 40.2885\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9298 - val_loss: 37.3092\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.5777 - val_loss: 39.7304\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0568 - val_loss: 41.1120\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2669 - val_loss: 42.8001\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4113 - val_loss: 36.0862\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7706 - val_loss: 38.6104\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.9123 - val_loss: 38.1896\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5871 - val_loss: 36.7715\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5452 - val_loss: 37.6004\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 30.8188 - val_loss: 36.0134\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.2106 - val_loss: 35.8896\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 30.9869 - val_loss: 39.0068\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5843 - val_loss: 35.3159\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6360 - val_loss: 33.9724\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7712 - val_loss: 35.7640\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5322 - val_loss: 33.8958\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1052 - val_loss: 35.9248\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2443 - val_loss: 40.7780\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.2808 - val_loss: 48.3253\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.6721 - val_loss: 37.0323\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.2942 - val_loss: 37.8630\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2783 - val_loss: 34.1972\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.4758 - val_loss: 33.6847\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8517 - val_loss: 33.2392\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.9145 - val_loss: 35.3956\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3956 - val_loss: 34.4288\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7546 - val_loss: 37.0706\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.6361 - val_loss: 35.0363\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1595 - val_loss: 37.4210\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.7438 - val_loss: 45.7149\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.7484 - val_loss: 42.6022\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2558 - val_loss: 32.7158\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.7861 - val_loss: 37.8245\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5276 - val_loss: 44.1520\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4292 - val_loss: 37.1208\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6411 - val_loss: 33.7432\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4397 - val_loss: 34.8844\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.3150 - val_loss: 41.1175\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.9253 - val_loss: 31.9588\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0967 - val_loss: 31.7329\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5768 - val_loss: 35.1805\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6873 - val_loss: 31.0634\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6809 - val_loss: 32.5923\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.3633 - val_loss: 33.6020\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.6988 - val_loss: 32.0389\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8961 - val_loss: 34.0730\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8136 - val_loss: 46.5539\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.2110 - val_loss: 33.3753\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2845 - val_loss: 37.1931\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4186 - val_loss: 30.7136\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0689 - val_loss: 31.7695\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1799 - val_loss: 30.7091\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6839 - val_loss: 31.0061\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4743 - val_loss: 30.2787\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.8112 - val_loss: 29.9262\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.1971 - val_loss: 32.4119\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.9040 - val_loss: 30.1111\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9318 - val_loss: 36.3139\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9726 - val_loss: 31.3638\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.4247 - val_loss: 34.9918\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6531 - val_loss: 44.6427\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.2178 - val_loss: 37.7258\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1316 - val_loss: 30.7287\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9936 - val_loss: 38.6224\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4298 - val_loss: 39.2750\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.1943 - val_loss: 30.6263\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9819 - val_loss: 32.3306\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3960 - val_loss: 31.5480\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4586 - val_loss: 30.9796\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2896 - val_loss: 29.9548\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1826 - val_loss: 33.2879\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.2710 - val_loss: 33.2513\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.2149 - val_loss: 32.4796\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7992 - val_loss: 29.9427\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0702 - val_loss: 34.5090\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.7902 - val_loss: 31.8783\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9975 - val_loss: 33.8536\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9653 - val_loss: 30.8730\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0899 - val_loss: 34.1620\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7019 - val_loss: 30.9867\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6450 - val_loss: 33.9036\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1372 - val_loss: 30.5654\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8678 - val_loss: 38.0427\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6903 - val_loss: 31.0542\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 27.2143 - val_loss: 29.5734\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.9311 - val_loss: 29.6539\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2279 - val_loss: 28.9229\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.5124 - val_loss: 30.3791\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2735 - val_loss: 30.0687\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6345 - val_loss: 30.6236\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.9150 - val_loss: 30.5782\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9765 - val_loss: 32.3588\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2542 - val_loss: 31.1560\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1991 - val_loss: 36.4252\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.5484 - val_loss: 33.3300\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3064 - val_loss: 43.7709\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4660 - val_loss: 67.2013\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7185 - val_loss: 54.2909\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7048 - val_loss: 28.6139\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4135 - val_loss: 27.7134\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.9447 - val_loss: 27.3364\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7247 - val_loss: 27.6624\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.0848 - val_loss: 29.3554\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.0152 - val_loss: 31.1681\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.1577 - val_loss: 32.1555\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4268 - val_loss: 34.5577\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.6046 - val_loss: 27.5172\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.3779 - val_loss: 31.7089\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0997 - val_loss: 28.7342\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6751 - val_loss: 29.7243\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3885 - val_loss: 29.8936\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2391 - val_loss: 28.4468\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.9302 - val_loss: 28.1530\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 26.8582 - val_loss: 28.7432\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8575 - val_loss: 27.7944\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.6612 - val_loss: 27.3554\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2299 - val_loss: 28.6796\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2352 - val_loss: 29.2242\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.2876 - val_loss: 28.2995\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2409 - val_loss: 39.6699\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.1600 - val_loss: 39.4074\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.7157 - val_loss: 33.2195\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.2785 - val_loss: 30.9256\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2575 - val_loss: 27.5515\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.7897 - val_loss: 28.8493\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.2263 - val_loss: 28.0042\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.6193 - val_loss: 26.9418\n",
      "3/3 [==============================] - 0s 815us/step - loss: 28.3706\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 758.4854 - val_loss: 398.2556\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 237.6291 - val_loss: 156.0988\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 137.4693 - val_loss: 134.0113\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 124.8726 - val_loss: 125.4100\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 108.9498 - val_loss: 117.3861\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.6399 - val_loss: 113.8738\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.8349 - val_loss: 106.6661\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 91.0224 - val_loss: 95.5565\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.8927 - val_loss: 93.9776\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.7455 - val_loss: 88.7756\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.9828 - val_loss: 88.8289\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.0397 - val_loss: 86.4715\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.2658 - val_loss: 86.1709\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.0961 - val_loss: 85.9595\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5808 - val_loss: 87.0987\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.7490 - val_loss: 89.4743\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.9263 - val_loss: 80.1888\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.6900 - val_loss: 78.5669\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9113 - val_loss: 83.1209\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.4655 - val_loss: 78.4772\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9897 - val_loss: 89.9697\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.2035 - val_loss: 81.6891\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1684 - val_loss: 76.9738\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0615 - val_loss: 78.0730\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.6199 - val_loss: 78.3520\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5585 - val_loss: 75.7868\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2239 - val_loss: 76.7566\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.6582 - val_loss: 92.5843\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.0470 - val_loss: 83.8614\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9806 - val_loss: 73.9177\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5893 - val_loss: 77.2465\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9080 - val_loss: 73.5508\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1650 - val_loss: 72.2431\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.8246 - val_loss: 69.9234\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0438 - val_loss: 68.7072\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.1015 - val_loss: 69.5490\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6238 - val_loss: 68.6214\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3986 - val_loss: 68.5101\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0995 - val_loss: 66.5101\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2507 - val_loss: 66.5652\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4108 - val_loss: 68.1629\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6419 - val_loss: 70.8898\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5898 - val_loss: 70.8993\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.8796 - val_loss: 65.4738\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.3778 - val_loss: 65.3329\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6956 - val_loss: 62.9847\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8428 - val_loss: 66.3622\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3397 - val_loss: 62.3064\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.6314 - val_loss: 71.0688\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2009 - val_loss: 59.4519\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7768 - val_loss: 67.3887\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4775 - val_loss: 59.3922\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.3816 - val_loss: 62.2296\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7775 - val_loss: 59.7516\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9039 - val_loss: 58.9579\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1091 - val_loss: 60.2293\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1245 - val_loss: 59.6038\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0122 - val_loss: 57.6523\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4917 - val_loss: 57.3656\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0726 - val_loss: 58.4582\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9023 - val_loss: 57.2428\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.4392 - val_loss: 60.1446\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4183 - val_loss: 61.2521\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7330 - val_loss: 60.4704\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.4608 - val_loss: 52.5917\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.3069 - val_loss: 53.7783\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8782 - val_loss: 59.8157\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.8954 - val_loss: 55.3640\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2192 - val_loss: 52.8392\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9662 - val_loss: 61.3939\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.1265 - val_loss: 55.7729\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.4136 - val_loss: 51.0466\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.5930 - val_loss: 55.6743\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.5405 - val_loss: 53.7690\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5856 - val_loss: 53.4763\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.1284 - val_loss: 50.6540\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.3436 - val_loss: 53.3691\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.2289 - val_loss: 50.9689\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7538 - val_loss: 49.3722\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.5452 - val_loss: 48.2927\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9356 - val_loss: 48.4676\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.9927 - val_loss: 53.4385\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4488 - val_loss: 47.3812\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7282 - val_loss: 69.0470\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.0206 - val_loss: 46.6491\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7290 - val_loss: 45.9358\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.3120 - val_loss: 50.4178\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6591 - val_loss: 45.1793\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7904 - val_loss: 45.7835\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6391 - val_loss: 51.9372\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.4518 - val_loss: 53.2718\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3481 - val_loss: 48.7086\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6157 - val_loss: 44.8004\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1757 - val_loss: 45.4132\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.9325 - val_loss: 47.4267\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 39.8801 - val_loss: 47.0859\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3072 - val_loss: 41.3561\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0904 - val_loss: 43.3352\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.9818 - val_loss: 46.0830\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.3747 - val_loss: 46.7769\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8318 - val_loss: 42.2504\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.2116 - val_loss: 39.8748\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4315 - val_loss: 49.3601\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.5693 - val_loss: 44.1938\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8015 - val_loss: 51.6346\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2772 - val_loss: 41.5429\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4717 - val_loss: 41.2602\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.1653 - val_loss: 46.5589\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4886 - val_loss: 45.4690\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.6691 - val_loss: 42.0678\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5427 - val_loss: 45.5012\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.6491 - val_loss: 41.3251\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1596 - val_loss: 39.7919\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 36.3757 - val_loss: 43.3304\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2003 - val_loss: 38.9174\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.1929 - val_loss: 46.4747\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0350 - val_loss: 47.5230\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.7414 - val_loss: 40.5893\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4936 - val_loss: 39.3234\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.5119 - val_loss: 41.7455\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.0221 - val_loss: 39.6819\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7982 - val_loss: 39.2753\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5642 - val_loss: 40.3039\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6342 - val_loss: 46.4728\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5606 - val_loss: 42.1537\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6428 - val_loss: 41.8089\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2846 - val_loss: 38.9983\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3596 - val_loss: 37.7382\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.5574 - val_loss: 37.6477\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8992 - val_loss: 41.1218\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5594 - val_loss: 37.7492\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.1516 - val_loss: 38.3952\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.6670 - val_loss: 38.9665\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8778 - val_loss: 40.3746\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7675 - val_loss: 42.2088\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9014 - val_loss: 37.9530\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5689 - val_loss: 36.9055\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.5175 - val_loss: 37.5473\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2099 - val_loss: 37.8697\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8790 - val_loss: 38.7928\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0072 - val_loss: 39.1165\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5411 - val_loss: 43.7134\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9899 - val_loss: 46.4519\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7227 - val_loss: 39.5504\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8223 - val_loss: 38.2261\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3919 - val_loss: 39.2542\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7449 - val_loss: 39.6155\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.9873 - val_loss: 37.5963\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4986 - val_loss: 38.0441\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1561 - val_loss: 41.0449\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4250 - val_loss: 40.3531\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0979 - val_loss: 37.9034\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8087 - val_loss: 38.4865\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3614 - val_loss: 38.1807\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.5036 - val_loss: 57.2137\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1679 - val_loss: 37.0592\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.2336 - val_loss: 35.6911\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.4605 - val_loss: 43.9361\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.1309 - val_loss: 36.3553\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5780 - val_loss: 37.0285\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.1943 - val_loss: 36.6539\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3060 - val_loss: 40.5803\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.9347 - val_loss: 42.2379\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.4674 - val_loss: 36.8964\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.2841 - val_loss: 37.5691\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9267 - val_loss: 38.7436\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 32.8735 - val_loss: 36.2107\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0184 - val_loss: 37.6475\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4818 - val_loss: 36.8179\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8179 - val_loss: 35.4339\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8409 - val_loss: 41.6645\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3017 - val_loss: 34.7865\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.1166 - val_loss: 37.7966\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6581 - val_loss: 38.8804\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.5446 - val_loss: 37.5777\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.3174 - val_loss: 39.1015\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.3026 - val_loss: 40.3167\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.9034 - val_loss: 35.6506\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4718 - val_loss: 36.2902\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.2642 - val_loss: 36.3431\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4012 - val_loss: 38.6617\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.4815 - val_loss: 36.2022\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2636 - val_loss: 36.4600\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.6531 - val_loss: 34.1658\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3395 - val_loss: 36.3646\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.8093 - val_loss: 44.5272\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.4232 - val_loss: 41.8914\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.5103 - val_loss: 35.9707\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9452 - val_loss: 38.0623\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.8245 - val_loss: 47.2449\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7221 - val_loss: 37.0221\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.3087 - val_loss: 34.5562\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7386 - val_loss: 33.3808\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.8804 - val_loss: 34.6022\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2104 - val_loss: 51.6303\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.3674 - val_loss: 36.4783\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6659 - val_loss: 35.9380\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.1944 - val_loss: 37.1353\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.5776 - val_loss: 46.7802\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7882 - val_loss: 41.7757\n",
      "3/3 [==============================] - 0s 888us/step - loss: 20.5896\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3505.1575 - val_loss: 1101.9720\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 534.3529 - val_loss: 333.8345\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 262.8115 - val_loss: 241.0581\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 125.5080 - val_loss: 85.1420\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0891 - val_loss: 73.2116\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6375 - val_loss: 68.6481\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5050 - val_loss: 72.2821\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.4515 - val_loss: 69.4053\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7903 - val_loss: 66.4865\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8548 - val_loss: 66.0643\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8583 - val_loss: 65.6128\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1489 - val_loss: 66.9653\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0145 - val_loss: 70.2890\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6241 - val_loss: 66.5798\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9529 - val_loss: 65.5414\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1439 - val_loss: 66.9983\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2326 - val_loss: 67.7930\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5307 - val_loss: 66.4525\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1559 - val_loss: 66.3188\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9623 - val_loss: 66.2089\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7068 - val_loss: 65.7093\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.3014 - val_loss: 65.2971\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.5717 - val_loss: 64.1861\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0945 - val_loss: 67.0722\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.6086 - val_loss: 62.4573\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7544 - val_loss: 63.6517\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2021 - val_loss: 63.8303\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8780 - val_loss: 63.0370\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8903 - val_loss: 62.5011\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1619 - val_loss: 64.9195\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.5797 - val_loss: 62.4439\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4427 - val_loss: 64.9212\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.2674 - val_loss: 64.6016\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.7991 - val_loss: 61.2861\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.9197 - val_loss: 62.9795\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.4536 - val_loss: 61.8889\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.3171 - val_loss: 60.3025\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.1547 - val_loss: 62.8260\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2331 - val_loss: 61.1896\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6715 - val_loss: 60.9658\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3137 - val_loss: 60.2906\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6176 - val_loss: 59.9748\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9840 - val_loss: 59.7103\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 40.2079 - val_loss: 61.0765\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3022 - val_loss: 59.6191\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.6580 - val_loss: 60.3649\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9487 - val_loss: 59.5871\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2827 - val_loss: 58.8774\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.6685 - val_loss: 58.6057\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.2512 - val_loss: 60.7253\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.8613 - val_loss: 58.1118\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.7148 - val_loss: 57.6294\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.6315 - val_loss: 57.5673\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.5459 - val_loss: 56.6622\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2678 - val_loss: 56.0993\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.5215 - val_loss: 56.9647\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2262 - val_loss: 56.3918\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7642 - val_loss: 56.3486\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.7341 - val_loss: 56.2428\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3691 - val_loss: 53.9782\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9487 - val_loss: 55.5300\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8090 - val_loss: 53.8481\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 36.9885 - val_loss: 55.9446\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.4680 - val_loss: 53.9174\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.3836 - val_loss: 55.7659\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.4807 - val_loss: 52.5886\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.7892 - val_loss: 53.2514\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6827 - val_loss: 54.7985\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.1701 - val_loss: 52.0321\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.8201 - val_loss: 52.5189\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.5125 - val_loss: 53.9365\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.6922 - val_loss: 50.7040\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.6351 - val_loss: 53.5597\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.9570 - val_loss: 49.5359\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.3103 - val_loss: 52.0885\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.3217 - val_loss: 51.0102\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8384 - val_loss: 52.5912\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8118 - val_loss: 52.1993\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.5188 - val_loss: 50.5542\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.0022 - val_loss: 50.2304\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.1505 - val_loss: 49.3684\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 34.0780 - val_loss: 49.3407\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.7054 - val_loss: 48.9077\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0323 - val_loss: 48.9195\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4676 - val_loss: 48.8661\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4291 - val_loss: 46.6755\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.4430 - val_loss: 47.5912\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.2035 - val_loss: 48.7485\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8511 - val_loss: 46.5942\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.3289 - val_loss: 51.2416\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 33.1983 - val_loss: 45.3818\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.6899 - val_loss: 47.2584\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0100 - val_loss: 45.8816\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.9988 - val_loss: 46.0910\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.8702 - val_loss: 44.4432\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.8449 - val_loss: 46.7910\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.0447 - val_loss: 49.8566\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.4873 - val_loss: 45.9559\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 31.7866 - val_loss: 43.1280\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9917 - val_loss: 47.9189\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.7291 - val_loss: 42.8238\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.1294 - val_loss: 44.7513\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.5192 - val_loss: 43.4599\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.3038 - val_loss: 41.1236\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.4653 - val_loss: 53.3888\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.8573 - val_loss: 40.8616\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.2172 - val_loss: 44.1784\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5913 - val_loss: 41.6277\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.4941 - val_loss: 42.8239\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 29.6355 - val_loss: 43.2052\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6013 - val_loss: 41.2371\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8324 - val_loss: 43.6088\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9805 - val_loss: 40.7041\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.5291 - val_loss: 40.3665\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.2536 - val_loss: 38.5749\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.8005 - val_loss: 44.0389\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5207 - val_loss: 37.7118\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.0603 - val_loss: 47.8402\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5960 - val_loss: 37.5109\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.8847 - val_loss: 41.4272\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9874 - val_loss: 39.4530\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9116 - val_loss: 37.5117\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.6681 - val_loss: 43.9584\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.5508 - val_loss: 39.9118\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.4271 - val_loss: 37.1677\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.7288 - val_loss: 35.3198\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.3435 - val_loss: 39.5303\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 31.3030 - val_loss: 43.9007\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 28.2418 - val_loss: 35.2057\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.6122 - val_loss: 39.1228\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.9294 - val_loss: 35.4575\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0161 - val_loss: 38.1493\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.0993 - val_loss: 32.4150\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6449 - val_loss: 46.0851\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2505 - val_loss: 32.8832\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5497 - val_loss: 33.3906\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.5377 - val_loss: 34.8333\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2171 - val_loss: 36.0472\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9981 - val_loss: 33.5107\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.0114 - val_loss: 32.0213\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.2172 - val_loss: 37.1825\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.3603 - val_loss: 33.0420\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.4384 - val_loss: 31.3327\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.7998 - val_loss: 33.2705\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.7221 - val_loss: 31.6097\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.0334 - val_loss: 34.4401\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1984 - val_loss: 36.1890\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 25.9131 - val_loss: 31.7066\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.8750 - val_loss: 32.3962\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 29.8247 - val_loss: 44.4777\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7956 - val_loss: 34.9758\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6457 - val_loss: 32.6169\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.7622 - val_loss: 31.1301\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5856 - val_loss: 39.2658\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 25.1662 - val_loss: 30.4515\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5584 - val_loss: 32.5676\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4811 - val_loss: 32.3263\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.0297 - val_loss: 32.1921\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7530 - val_loss: 31.9632\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1579 - val_loss: 29.3734\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.8331 - val_loss: 38.4657\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.4137 - val_loss: 29.2125\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4985 - val_loss: 30.9687\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6615 - val_loss: 31.7230\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4586 - val_loss: 28.5846\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.9800 - val_loss: 29.1270\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 24.1814 - val_loss: 31.8402\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 23.3999 - val_loss: 29.9245\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6962 - val_loss: 31.4974\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.6597 - val_loss: 28.7414\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9633 - val_loss: 38.8229\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.5189 - val_loss: 31.6146\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4355 - val_loss: 29.9224\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9892 - val_loss: 28.3180\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.4524 - val_loss: 27.9461\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.1661 - val_loss: 28.3398\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5618 - val_loss: 28.1705\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3090 - val_loss: 29.0408\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.8705 - val_loss: 30.0329\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4493 - val_loss: 26.6472\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.5751 - val_loss: 26.8732\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.9207 - val_loss: 32.1743\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.0247 - val_loss: 28.9786\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.2526 - val_loss: 26.4326\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.1076 - val_loss: 30.5655\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 21.5583 - val_loss: 29.5868\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4617 - val_loss: 25.2138\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 23.7936 - val_loss: 25.4875\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.3124 - val_loss: 28.6885\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0982 - val_loss: 25.8795\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.9087 - val_loss: 26.5173\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2181 - val_loss: 31.8344\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.4012 - val_loss: 28.4455\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 22.4690 - val_loss: 25.9418\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.2400 - val_loss: 24.7530\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.8088 - val_loss: 29.3397\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 20.3105 - val_loss: 30.2708\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.0466 - val_loss: 25.3142\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.8132 - val_loss: 36.6596\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 21.6622 - val_loss: 27.5476\n",
      "3/3 [==============================] - 0s 895us/step - loss: 44.1385\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5489.7134 - val_loss: 4815.8276\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 4186.0737 - val_loss: 3691.7156\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3200.8425 - val_loss: 2864.3235\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2462.8628 - val_loss: 2237.5393\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1908.5536 - val_loss: 1768.6559\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1512.3794 - val_loss: 1413.6447\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1222.3792 - val_loss: 1187.5249\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1035.6112 - val_loss: 1041.2227\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 908.1853 - val_loss: 924.2236\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 800.6155 - val_loss: 822.1835\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 707.3403 - val_loss: 732.8273\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 624.5081 - val_loss: 649.8190\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 547.7200 - val_loss: 573.2067\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 478.0065 - val_loss: 505.2274\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 416.0509 - val_loss: 441.9209\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 357.1439 - val_loss: 383.3955\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 304.2245 - val_loss: 330.6320\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 256.9844 - val_loss: 283.8689\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 215.8901 - val_loss: 242.7382\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 178.6045 - val_loss: 206.0554\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 147.9934 - val_loss: 176.2431\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 123.5472 - val_loss: 153.4887\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 105.2185 - val_loss: 135.9216\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.0868 - val_loss: 121.8467\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.5933 - val_loss: 112.6441\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.7708 - val_loss: 106.9544\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.5069 - val_loss: 103.0789\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.4752 - val_loss: 100.8732\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.4457 - val_loss: 99.6881\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9858 - val_loss: 98.9660\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.6255 - val_loss: 98.2558\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.3916 - val_loss: 97.7246\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1940 - val_loss: 97.2496\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9531 - val_loss: 96.9304\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9221 - val_loss: 96.3398\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8099 - val_loss: 96.1897\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.7545 - val_loss: 95.7217\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6753 - val_loss: 95.3233\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6056 - val_loss: 95.2302\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.5708 - val_loss: 95.4715\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.5526 - val_loss: 95.5577\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.4157 - val_loss: 95.2994\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3612 - val_loss: 95.1181\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2386 - val_loss: 94.9896\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1794 - val_loss: 94.6631\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1115 - val_loss: 94.4862\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.0879 - val_loss: 94.1635\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9733 - val_loss: 93.8557\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9322 - val_loss: 93.4372\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.8669 - val_loss: 93.1828\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.7753 - val_loss: 93.2187\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.7220 - val_loss: 93.2762\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.6392 - val_loss: 93.1207\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.6386 - val_loss: 92.8682\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5893 - val_loss: 93.0060\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5514 - val_loss: 93.1077\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.6222 - val_loss: 93.3391\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4954 - val_loss: 93.0417\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4516 - val_loss: 93.0042\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.3743 - val_loss: 92.6638\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.2906 - val_loss: 92.5165\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1405 - val_loss: 92.1698\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1275 - val_loss: 92.0705\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0913 - val_loss: 92.0115\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0609 - val_loss: 92.0066\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0123 - val_loss: 91.7896\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9435 - val_loss: 91.5091\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8595 - val_loss: 91.3872\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8180 - val_loss: 91.2508\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7864 - val_loss: 91.0071\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7167 - val_loss: 91.3842\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7366 - val_loss: 91.7366\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7058 - val_loss: 91.2987\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.6233 - val_loss: 91.0604\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5163 - val_loss: 90.8783\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5102 - val_loss: 90.4736\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5925 - val_loss: 90.2551\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.4094 - val_loss: 90.3895\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.2998 - val_loss: 90.2465\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2833 - val_loss: 90.3149\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3210 - val_loss: 90.1282\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2887 - val_loss: 90.4810\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.1508 - val_loss: 90.5579\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0219 - val_loss: 90.6182\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9236 - val_loss: 90.5098\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9787 - val_loss: 90.2629\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9354 - val_loss: 90.2273\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.8902 - val_loss: 90.1323\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.8079 - val_loss: 89.9428\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7796 - val_loss: 89.8398\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6607 - val_loss: 89.3985\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.6587 - val_loss: 89.2354\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5865 - val_loss: 89.2553\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5518 - val_loss: 89.1858\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.6187 - val_loss: 88.9069\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5544 - val_loss: 88.6441\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5900 - val_loss: 88.5011\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4153 - val_loss: 88.5980\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3949 - val_loss: 88.4149\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3140 - val_loss: 88.5070\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2577 - val_loss: 88.4055\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1800 - val_loss: 88.5596\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1927 - val_loss: 88.8209\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3790 - val_loss: 88.2891\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0474 - val_loss: 88.3947\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9459 - val_loss: 88.5531\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.0121 - val_loss: 88.2507\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9036 - val_loss: 88.4048\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8721 - val_loss: 88.0674\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7827 - val_loss: 87.7002\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7705 - val_loss: 87.8207\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7066 - val_loss: 87.7362\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.6949 - val_loss: 87.9508\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6975 - val_loss: 88.0118\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6291 - val_loss: 88.3930\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5117 - val_loss: 88.3669\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.5679 - val_loss: 88.0396\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6654 - val_loss: 88.3880\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2997 - val_loss: 87.8278\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4040 - val_loss: 87.5533\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6811 - val_loss: 87.4861\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9301 - val_loss: 87.2156\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.4445 - val_loss: 87.3707\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.0911 - val_loss: 87.5459\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9040 - val_loss: 87.9291\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.9593 - val_loss: 87.7537\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8394 - val_loss: 87.2458\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8032 - val_loss: 87.1576\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7646 - val_loss: 87.1016\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6906 - val_loss: 87.2328\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6274 - val_loss: 87.2952\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5854 - val_loss: 87.2450\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5597 - val_loss: 86.8189\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5803 - val_loss: 86.9558\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.4640 - val_loss: 86.7713\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3704 - val_loss: 86.7143\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3527 - val_loss: 86.3763\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2993 - val_loss: 86.2727\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3809 - val_loss: 85.9757\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2603 - val_loss: 86.3317\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1822 - val_loss: 86.3857\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1338 - val_loss: 86.4063\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2334 - val_loss: 86.3625\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3527 - val_loss: 85.4396\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3336 - val_loss: 85.4371\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9720 - val_loss: 85.7846\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8160 - val_loss: 86.0853\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8430 - val_loss: 86.5201\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.8463 - val_loss: 86.1777\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.6945 - val_loss: 85.8400\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7068 - val_loss: 85.6738\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6396 - val_loss: 85.3847\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6717 - val_loss: 85.7135\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5553 - val_loss: 85.7502\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5117 - val_loss: 85.6640\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4638 - val_loss: 85.3242\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3510 - val_loss: 84.9772\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3933 - val_loss: 84.7942\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3017 - val_loss: 84.8720\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4070 - val_loss: 85.2404\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2647 - val_loss: 85.2556\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1981 - val_loss: 84.7216\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1105 - val_loss: 84.2517\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1717 - val_loss: 84.4389\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.0933 - val_loss: 84.8251\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9750 - val_loss: 84.8287\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1173 - val_loss: 85.3169\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0136 - val_loss: 85.0571\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8276 - val_loss: 84.3002\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8912 - val_loss: 83.7481\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8567 - val_loss: 83.5407\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6769 - val_loss: 83.6513\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6099 - val_loss: 83.7621\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5188 - val_loss: 83.0077\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5105 - val_loss: 82.9943\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4048 - val_loss: 83.2171\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4249 - val_loss: 82.8538\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2746 - val_loss: 82.2314\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1285 - val_loss: 82.3285\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0927 - val_loss: 82.0261\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.0129 - val_loss: 81.9856\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9259 - val_loss: 82.5100\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8349 - val_loss: 82.4950\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7572 - val_loss: 82.3589\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5423 - val_loss: 81.6024\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4621 - val_loss: 81.6071\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3964 - val_loss: 81.7747\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3388 - val_loss: 81.6707\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3557 - val_loss: 81.4879\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2454 - val_loss: 81.5376\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1828 - val_loss: 80.7081\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0073 - val_loss: 80.7215\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.8534 - val_loss: 80.7186\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6508 - val_loss: 79.9519\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6821 - val_loss: 80.1909\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6172 - val_loss: 80.9723\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3722 - val_loss: 80.8002\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6557 - val_loss: 81.5020\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5286 - val_loss: 81.8080\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3045 - val_loss: 81.8125\n",
      "3/3 [==============================] - 0s 921us/step - loss: 64.0813\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 127.6592 - val_loss: 140.5313\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 89.5041 - val_loss: 114.3108\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.0156 - val_loss: 108.2365\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.7059 - val_loss: 107.8723\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.0404 - val_loss: 107.6325\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.5117 - val_loss: 107.8016\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 76.1813 - val_loss: 107.2344\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.9147 - val_loss: 106.3910\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.4162 - val_loss: 106.0974\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.2831 - val_loss: 105.4690\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.7738 - val_loss: 104.6573\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.7742 - val_loss: 103.6751\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.2285 - val_loss: 103.3899\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.0418 - val_loss: 104.0207\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.9781 - val_loss: 103.3555\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.4511 - val_loss: 101.8192\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.2260 - val_loss: 101.6196\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.7248 - val_loss: 101.2988\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.5252 - val_loss: 101.2711\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.6449 - val_loss: 101.1792\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.9440 - val_loss: 99.6144\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.7903 - val_loss: 99.5329\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.4695 - val_loss: 98.8626\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.1596 - val_loss: 98.3867\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.6910 - val_loss: 98.4220\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.9282 - val_loss: 97.4952\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.2977 - val_loss: 98.1110\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.1747 - val_loss: 96.6561\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7557 - val_loss: 96.0733\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.6530 - val_loss: 95.8366\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.1366 - val_loss: 95.0124\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.8527 - val_loss: 95.3437\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.8570 - val_loss: 95.5868\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.5529 - val_loss: 93.9046\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.0394 - val_loss: 93.1052\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.0197 - val_loss: 93.4775\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.6016 - val_loss: 93.1999\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.5798 - val_loss: 92.4072\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 67.2815 - val_loss: 91.6016\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.7030 - val_loss: 90.9204\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6741 - val_loss: 91.0585\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3384 - val_loss: 90.3502\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2821 - val_loss: 90.3787\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8431 - val_loss: 89.0424\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5602 - val_loss: 88.9132\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1898 - val_loss: 88.7249\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0497 - val_loss: 88.3736\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9028 - val_loss: 87.7692\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.5820 - val_loss: 87.8514\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.8418 - val_loss: 86.6969\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0837 - val_loss: 86.9313\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7636 - val_loss: 85.9914\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9793 - val_loss: 85.2347\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9347 - val_loss: 85.8584\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2618 - val_loss: 86.1936\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9676 - val_loss: 84.6050\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9320 - val_loss: 83.7569\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8314 - val_loss: 83.5314\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.2183 - val_loss: 83.1681\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9970 - val_loss: 82.6735\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5998 - val_loss: 83.1989\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5226 - val_loss: 82.6244\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3118 - val_loss: 81.5193\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2404 - val_loss: 81.3531\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2823 - val_loss: 82.0483\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7318 - val_loss: 81.1039\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2098 - val_loss: 81.6308\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.4300 - val_loss: 81.3466\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1491 - val_loss: 80.5240\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9200 - val_loss: 80.1135\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6935 - val_loss: 80.6672\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8850 - val_loss: 79.9226\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6171 - val_loss: 80.0846\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7228 - val_loss: 79.9974\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6011 - val_loss: 81.5778\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4191 - val_loss: 79.3091\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6952 - val_loss: 78.5317\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8751 - val_loss: 79.0092\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5867 - val_loss: 78.2174\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4941 - val_loss: 78.2588\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3204 - val_loss: 77.3458\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0262 - val_loss: 76.6152\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9604 - val_loss: 77.0574\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8913 - val_loss: 76.1072\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5892 - val_loss: 75.9960\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6327 - val_loss: 76.0135\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.2992 - val_loss: 76.5943\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2204 - val_loss: 75.5801\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9262 - val_loss: 75.4343\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.7909 - val_loss: 75.9228\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8733 - val_loss: 75.3347\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5851 - val_loss: 74.5613\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6775 - val_loss: 74.3279\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.8537 - val_loss: 74.2719\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6135 - val_loss: 75.2641\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6352 - val_loss: 73.3832\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.6263 - val_loss: 73.5281\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1328 - val_loss: 73.9766\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7499 - val_loss: 74.4706\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.5777 - val_loss: 73.4777\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.3179 - val_loss: 72.6644\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1867 - val_loss: 72.4781\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2705 - val_loss: 72.4169\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1305 - val_loss: 72.3734\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7823 - val_loss: 71.8953\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9477 - val_loss: 71.8453\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7611 - val_loss: 72.4548\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3370 - val_loss: 71.2998\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.6375 - val_loss: 70.6508\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3203 - val_loss: 71.0106\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.3604 - val_loss: 70.7613\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.8844 - val_loss: 70.0152\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7645 - val_loss: 69.9117\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4949 - val_loss: 70.2457\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4317 - val_loss: 70.5525\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.5884 - val_loss: 69.7776\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2363 - val_loss: 69.2906\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.0331 - val_loss: 68.6656\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2842 - val_loss: 68.2388\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5001 - val_loss: 68.1678\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.9041 - val_loss: 69.9842\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2422 - val_loss: 68.8962\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6093 - val_loss: 67.5214\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2684 - val_loss: 68.6676\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.8178 - val_loss: 67.9153\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.4824 - val_loss: 67.4053\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.2574 - val_loss: 66.7827\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2812 - val_loss: 66.7169\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2057 - val_loss: 66.7474\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.7531 - val_loss: 68.3625\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2804 - val_loss: 67.9975\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.8569 - val_loss: 67.0114\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.3711 - val_loss: 66.1118\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0700 - val_loss: 66.3602\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.1102 - val_loss: 66.7009\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0749 - val_loss: 65.5096\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1634 - val_loss: 65.2621\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7218 - val_loss: 65.9556\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6542 - val_loss: 66.3537\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4898 - val_loss: 65.2098\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4325 - val_loss: 65.4989\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3259 - val_loss: 66.5156\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5644 - val_loss: 64.9044\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.6681 - val_loss: 64.1237\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.0481 - val_loss: 64.5091\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.8152 - val_loss: 64.1940\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7704 - val_loss: 63.5661\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7403 - val_loss: 63.7381\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.9132 - val_loss: 64.5948\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7326 - val_loss: 63.5032\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2219 - val_loss: 63.4745\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7790 - val_loss: 63.0123\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9048 - val_loss: 63.9296\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.2688 - val_loss: 63.9177\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.0744 - val_loss: 62.8252\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8226 - val_loss: 62.4288\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6160 - val_loss: 62.2409\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5397 - val_loss: 62.1261\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5615 - val_loss: 61.4376\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4002 - val_loss: 61.8665\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.2544 - val_loss: 62.1022\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3090 - val_loss: 60.9356\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.2257 - val_loss: 60.8662\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3403 - val_loss: 60.5078\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1470 - val_loss: 61.8669\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.0451 - val_loss: 61.4692\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7734 - val_loss: 60.0850\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.6122 - val_loss: 60.4031\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.4346 - val_loss: 62.3252\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7986 - val_loss: 61.1052\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.3112 - val_loss: 59.7794\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.9092 - val_loss: 59.9733\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.8759 - val_loss: 59.6683\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7076 - val_loss: 59.9907\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7400 - val_loss: 59.0258\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7513 - val_loss: 59.4398\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.5429 - val_loss: 58.9535\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.2886 - val_loss: 59.4332\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.3609 - val_loss: 59.4134\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1746 - val_loss: 58.4683\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9661 - val_loss: 58.3854\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 46.6033 - val_loss: 58.2893\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0688 - val_loss: 58.6161\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.7344 - val_loss: 60.0405\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.0677 - val_loss: 59.2596\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.4389 - val_loss: 57.9757\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1918 - val_loss: 58.2626\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.0464 - val_loss: 57.9656\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9258 - val_loss: 57.3374\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.1979 - val_loss: 57.0615\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 44.6492 - val_loss: 57.2959\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6091 - val_loss: 57.5400\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7243 - val_loss: 55.8686\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8511 - val_loss: 55.9110\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.4909 - val_loss: 57.0975\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.5999 - val_loss: 55.2419\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.9550 - val_loss: 55.4901\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.7313 - val_loss: 55.8207\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.6007 - val_loss: 55.2740\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.4662 - val_loss: 55.0410\n",
      "3/3 [==============================] - 0s 911us/step - loss: 46.4586\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 250.5211 - val_loss: 213.9607\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 224.8006 - val_loss: 187.0276\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 205.3099 - val_loss: 168.1250\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 190.0511 - val_loss: 154.7305\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 177.4726 - val_loss: 147.3293\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 169.3887 - val_loss: 138.4801\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 162.5649 - val_loss: 133.2303\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 156.6826 - val_loss: 129.0737\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 152.5234 - val_loss: 126.0432\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 148.5779 - val_loss: 123.2641\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 144.3265 - val_loss: 118.6807\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 140.9130 - val_loss: 114.6244\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 133.3640 - val_loss: 106.2322\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 114.3506 - val_loss: 93.2550\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96.5794 - val_loss: 89.1230\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.5908 - val_loss: 91.6857\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.9070 - val_loss: 90.3908\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.2431 - val_loss: 87.2809\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 80.5523 - val_loss: 83.4942\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.3539 - val_loss: 82.8062\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.2172 - val_loss: 80.4655\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.4711 - val_loss: 78.7637\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.5160 - val_loss: 79.6367\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.9932 - val_loss: 82.0526\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.7287 - val_loss: 80.7436\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.1894 - val_loss: 79.8271\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.2475 - val_loss: 77.1629\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.5656 - val_loss: 76.4264\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.8920 - val_loss: 77.2542\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.6295 - val_loss: 76.4822\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.3993 - val_loss: 76.5357\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.2994 - val_loss: 78.5770\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.7375 - val_loss: 77.0112\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.2385 - val_loss: 76.6845\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.7257 - val_loss: 76.6637\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.5132 - val_loss: 74.8012\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 72.9650 - val_loss: 75.3607\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.3023 - val_loss: 74.8376\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.9928 - val_loss: 73.9921\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.2299 - val_loss: 75.0361\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.9118 - val_loss: 75.3648\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.5742 - val_loss: 74.0630\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.2882 - val_loss: 74.9586\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.7824 - val_loss: 74.6449\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7715 - val_loss: 73.3650\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 69.3063 - val_loss: 73.8340\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.7684 - val_loss: 74.5059\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.6086 - val_loss: 73.1227\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1302 - val_loss: 73.3534\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.4510 - val_loss: 73.5073\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.3532 - val_loss: 73.7920\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1820 - val_loss: 73.0674\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.5827 - val_loss: 73.4005\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.7739 - val_loss: 74.4570\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.1858 - val_loss: 70.7852\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.7994 - val_loss: 70.7580\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5917 - val_loss: 71.2729\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.7287 - val_loss: 70.6450\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0029 - val_loss: 71.0627\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.6455 - val_loss: 71.3740\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.3450 - val_loss: 71.1996\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.5935 - val_loss: 70.3316\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0839 - val_loss: 71.7714\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.4712 - val_loss: 72.1626\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.4590 - val_loss: 71.6649\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3728 - val_loss: 71.3136\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.0600 - val_loss: 72.0402\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.3743 - val_loss: 72.8866\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 62.6629 - val_loss: 71.1942\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2775 - val_loss: 70.2421\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0866 - val_loss: 69.7715\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2303 - val_loss: 71.1816\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.5433 - val_loss: 69.0327\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.8418 - val_loss: 69.3010\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.8964 - val_loss: 69.6312\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2124 - val_loss: 69.9288\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7991 - val_loss: 70.3895\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1008 - val_loss: 70.1496\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5229 - val_loss: 69.3678\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3334 - val_loss: 69.2759\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5412 - val_loss: 69.4328\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0260 - val_loss: 68.5215\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8478 - val_loss: 68.2932\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5892 - val_loss: 69.0277\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6993 - val_loss: 69.2540\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5612 - val_loss: 68.6776\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2183 - val_loss: 67.9921\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.1618 - val_loss: 67.5365\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5049 - val_loss: 66.9959\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3998 - val_loss: 66.7860\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2891 - val_loss: 68.5715\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7238 - val_loss: 66.3711\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.5303 - val_loss: 66.9763\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6040 - val_loss: 67.5821\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0747 - val_loss: 66.5347\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3536 - val_loss: 68.4403\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8051 - val_loss: 69.8009\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9468 - val_loss: 68.5224\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5128 - val_loss: 67.5378\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.2860 - val_loss: 67.7191\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5321 - val_loss: 66.2221\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.1441 - val_loss: 66.4190\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.0989 - val_loss: 66.3264\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.6446 - val_loss: 65.6862\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.2238 - val_loss: 67.2717\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.9798 - val_loss: 65.8806\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6192 - val_loss: 65.3618\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.5241 - val_loss: 65.7625\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6176 - val_loss: 66.2571\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8034 - val_loss: 64.8605\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.9210 - val_loss: 66.8556\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 56.3524 - val_loss: 66.0794\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.6675 - val_loss: 65.1537\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7836 - val_loss: 65.9498\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.8932 - val_loss: 64.8487\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.7518 - val_loss: 64.7794\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.6343 - val_loss: 66.5075\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 55.4578 - val_loss: 65.5043\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2241 - val_loss: 65.3180\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1221 - val_loss: 64.7423\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1882 - val_loss: 63.9136\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9951 - val_loss: 64.6221\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7205 - val_loss: 63.8508\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4495 - val_loss: 63.9110\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.5776 - val_loss: 65.2155\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.1745 - val_loss: 63.9033\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.9237 - val_loss: 64.5130\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.2489 - val_loss: 65.3256\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.7862 - val_loss: 64.7582\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7874 - val_loss: 62.5819\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.3281 - val_loss: 63.1398\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.7596 - val_loss: 63.7727\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.6704 - val_loss: 64.3014\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.0386 - val_loss: 64.9009\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 53.4444 - val_loss: 63.3753\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3964 - val_loss: 63.0122\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.4985 - val_loss: 64.1273\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.3285 - val_loss: 65.6344\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.5083 - val_loss: 64.9972\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.9674 - val_loss: 63.4574\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8288 - val_loss: 63.3221\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6989 - val_loss: 63.2088\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.6886 - val_loss: 62.1372\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 54.1851 - val_loss: 61.3857\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5394 - val_loss: 63.1580\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 53.2795 - val_loss: 63.4044\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.3582 - val_loss: 62.5358\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5408 - val_loss: 62.2614\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.0775 - val_loss: 63.5802\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 52.4199 - val_loss: 62.0025\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7060 - val_loss: 60.9410\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.1095 - val_loss: 60.8435\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.2509 - val_loss: 60.2900\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.9392 - val_loss: 61.8228\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1902 - val_loss: 60.3721\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.6572 - val_loss: 60.4657\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.2912 - val_loss: 61.0455\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.4077 - val_loss: 61.0587\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 51.2551 - val_loss: 59.6367\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.0864 - val_loss: 59.6502\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.1111 - val_loss: 59.7400\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7839 - val_loss: 60.6444\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.7979 - val_loss: 62.1744\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.8155 - val_loss: 61.8065\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.6355 - val_loss: 61.6617\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.4376 - val_loss: 60.7690\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.5583 - val_loss: 60.0703\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1648 - val_loss: 61.0610\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 50.3418 - val_loss: 60.5160\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3384 - val_loss: 60.7636\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2377 - val_loss: 61.0175\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.2410 - val_loss: 59.7559\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3466 - val_loss: 58.1253\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7986 - val_loss: 59.1461\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3284 - val_loss: 58.5754\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 49.2450 - val_loss: 58.5536\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.7945 - val_loss: 58.5894\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.9377 - val_loss: 59.8381\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1319 - val_loss: 59.2041\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.7644 - val_loss: 58.3821\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.5879 - val_loss: 58.3693\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6363 - val_loss: 58.6933\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4828 - val_loss: 58.5258\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3607 - val_loss: 57.4510\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3220 - val_loss: 57.3585\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.1635 - val_loss: 57.9047\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3126 - val_loss: 57.5201\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.0887 - val_loss: 57.3027\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9156 - val_loss: 57.4901\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 48.1158 - val_loss: 58.1787\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.3395 - val_loss: 58.5972\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.6424 - val_loss: 59.7485\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.9422 - val_loss: 57.3123\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3007 - val_loss: 56.9487\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1241 - val_loss: 56.9953\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3284 - val_loss: 56.5130\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 47.8908 - val_loss: 55.7682\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0623 - val_loss: 56.8346\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.5053 - val_loss: 58.2239\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.1957 - val_loss: 57.1737\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 50.3401\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 578.4465 - val_loss: 414.9532\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 289.1841 - val_loss: 249.9907\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 173.0725 - val_loss: 195.9695\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 138.4128 - val_loss: 184.2134\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 131.9861 - val_loss: 182.5778\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 130.2760 - val_loss: 180.3907\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 128.1411 - val_loss: 177.8618\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126.3593 - val_loss: 175.6523\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 124.9481 - val_loss: 173.0621\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122.8358 - val_loss: 170.9627\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 121.0663 - val_loss: 168.9181\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 119.2396 - val_loss: 166.7763\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 117.5485 - val_loss: 164.7908\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 115.9855 - val_loss: 163.1281\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114.2468 - val_loss: 161.0750\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 113.4017 - val_loss: 159.4843\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 111.8143 - val_loss: 157.4786\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 110.0036 - val_loss: 155.7011\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 108.6301 - val_loss: 154.2054\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106.9923 - val_loss: 152.6751\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 105.7543 - val_loss: 151.1122\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104.6016 - val_loss: 149.6547\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 103.3984 - val_loss: 148.4575\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 102.3495 - val_loss: 147.2065\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 101.1618 - val_loss: 145.5114\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 100.1152 - val_loss: 144.4876\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99.2442 - val_loss: 143.5175\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 98.2646 - val_loss: 141.9095\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 97.0283 - val_loss: 140.1699\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96.1238 - val_loss: 139.0920\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 95.2526 - val_loss: 137.9894\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 94.4535 - val_loss: 137.3912\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.8494 - val_loss: 136.2823\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.0243 - val_loss: 135.0957\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 92.1652 - val_loss: 134.1046\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.0063 - val_loss: 133.2974\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.1770 - val_loss: 132.1905\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 90.5219 - val_loss: 131.5020\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.4647 - val_loss: 131.7661\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 90.5320 - val_loss: 129.4721\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.0591 - val_loss: 128.9531\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.9362 - val_loss: 128.5897\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.1356 - val_loss: 127.4258\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 86.5799 - val_loss: 126.6708\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.0598 - val_loss: 126.0349\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 85.5863 - val_loss: 125.6852\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.4035 - val_loss: 125.1595\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.7067 - val_loss: 124.1042\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 84.3237 - val_loss: 123.3458\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.8001 - val_loss: 122.6301\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.6340 - val_loss: 122.1804\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 82.9891 - val_loss: 122.5572\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.5015 - val_loss: 121.8782\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 82.5111 - val_loss: 120.7925\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.0495 - val_loss: 120.1083\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.1922 - val_loss: 119.7073\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.6713 - val_loss: 119.2341\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.2270 - val_loss: 118.8084\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.9522 - val_loss: 118.1665\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 80.7730 - val_loss: 117.6348\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.7270 - val_loss: 117.6871\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.1923 - val_loss: 117.0348\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.6963 - val_loss: 116.4376\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.4069 - val_loss: 116.7918\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.9374 - val_loss: 116.4997\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.5010 - val_loss: 115.4375\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.5364 - val_loss: 115.5190\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.8718 - val_loss: 114.8092\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.4617 - val_loss: 114.3481\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.3830 - val_loss: 114.2816\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.0031 - val_loss: 113.9154\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.1506 - val_loss: 113.6044\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.1901 - val_loss: 113.4149\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 78.1897 - val_loss: 113.1614\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.4688 - val_loss: 113.0031\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.1605 - val_loss: 112.5762\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.7689 - val_loss: 112.3411\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.0778 - val_loss: 112.2959\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.0313 - val_loss: 112.2418\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.9156 - val_loss: 111.6677\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.7277 - val_loss: 111.3732\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 76.5327 - val_loss: 111.3099\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.5176 - val_loss: 110.9381\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.3788 - val_loss: 110.6800\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.1913 - val_loss: 110.3954\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.1268 - val_loss: 110.1687\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.0305 - val_loss: 109.9700\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.6748 - val_loss: 109.5761\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.5688 - val_loss: 109.4620\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.4221 - val_loss: 109.5617\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.4414 - val_loss: 109.1618\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.2345 - val_loss: 108.7503\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 75.0947 - val_loss: 108.5335\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.9225 - val_loss: 108.5057\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.9698 - val_loss: 108.7906\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.8986 - val_loss: 108.1701\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.6965 - val_loss: 107.9496\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.5150 - val_loss: 107.6388\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.4194 - val_loss: 107.4745\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.3499 - val_loss: 107.1252\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 74.8398 - val_loss: 106.8740\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.0621 - val_loss: 107.7610\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.8110 - val_loss: 107.1876\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.8133 - val_loss: 106.5014\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.9698 - val_loss: 104.6137\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.8486 - val_loss: 101.5655\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.8750 - val_loss: 100.2582\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.9707 - val_loss: 101.4349\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.6787 - val_loss: 100.0611\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.1203 - val_loss: 98.4229\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 68.3308 - val_loss: 98.2080\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.2266 - val_loss: 98.0993\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.9458 - val_loss: 97.3207\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.8834 - val_loss: 97.5255\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.6209 - val_loss: 97.3151\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.1051 - val_loss: 96.3268\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9892 - val_loss: 95.6336\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.6599 - val_loss: 95.0832\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.3085 - val_loss: 94.4929\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 66.6536 - val_loss: 95.4531\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.2982 - val_loss: 93.8428\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.9183 - val_loss: 93.4787\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.9701 - val_loss: 93.4112\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1048 - val_loss: 92.9810\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.4785 - val_loss: 92.6150\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.0548 - val_loss: 92.5410\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9564 - val_loss: 92.6109\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9456 - val_loss: 91.2381\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9208 - val_loss: 91.5319\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.8552 - val_loss: 90.5320\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2144 - val_loss: 90.5719\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.1315 - val_loss: 90.2582\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.2083 - val_loss: 89.7999\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9453 - val_loss: 89.1335\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.4944 - val_loss: 88.0866\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5233 - val_loss: 88.0874\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.2892 - val_loss: 88.3301\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.1009 - val_loss: 87.7701\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.2773 - val_loss: 86.8429\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8673 - val_loss: 86.9905\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9372 - val_loss: 87.0166\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5064 - val_loss: 86.3530\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.8110 - val_loss: 86.2272\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1312 - val_loss: 86.3594\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1287 - val_loss: 86.8813\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9758 - val_loss: 85.4261\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.9243 - val_loss: 85.1604\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.1102 - val_loss: 85.1775\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6541 - val_loss: 84.9661\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.6489 - val_loss: 84.4986\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.5642 - val_loss: 84.8508\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.7413 - val_loss: 83.6778\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6267 - val_loss: 83.0923\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1554 - val_loss: 83.6191\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1518 - val_loss: 84.7263\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2836 - val_loss: 84.5119\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0574 - val_loss: 83.2973\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.3766 - val_loss: 82.8170\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6838 - val_loss: 83.2591\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6982 - val_loss: 82.8611\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5146 - val_loss: 82.7674\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3233 - val_loss: 82.1795\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.4850 - val_loss: 82.0315\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3955 - val_loss: 82.3169\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5226 - val_loss: 82.1525\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1613 - val_loss: 82.0887\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0508 - val_loss: 81.9445\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5346 - val_loss: 81.8910\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2193 - val_loss: 81.4734\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7630 - val_loss: 81.2172\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9665 - val_loss: 81.1392\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.8655 - val_loss: 81.1665\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6610 - val_loss: 80.8225\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.5492 - val_loss: 80.5706\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.3799 - val_loss: 80.3637\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.3429 - val_loss: 80.3376\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1399 - val_loss: 81.6742\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7630 - val_loss: 80.6264\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5260 - val_loss: 80.9497\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9629 - val_loss: 80.1133\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7102 - val_loss: 80.2361\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.4049 - val_loss: 80.2200\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9560 - val_loss: 79.7437\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6657 - val_loss: 79.4630\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.8706 - val_loss: 79.2381\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9003 - val_loss: 79.2367\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.7398 - val_loss: 79.1356\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.6107 - val_loss: 78.6402\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2732 - val_loss: 78.9360\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4048 - val_loss: 78.2091\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3463 - val_loss: 77.6736\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1144 - val_loss: 77.7099\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9506 - val_loss: 77.5417\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9918 - val_loss: 78.5925\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1654 - val_loss: 77.4452\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.0448 - val_loss: 77.1405\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2614 - val_loss: 77.1006\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8279 - val_loss: 76.4739\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0165 - val_loss: 76.6166\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.5497 - val_loss: 76.9354\n",
      "3/3 [==============================] - 0s 909us/step - loss: 36.0727\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 12186.3398 - val_loss: 8635.1543\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6869.7769 - val_loss: 4618.1987\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3608.1917 - val_loss: 2321.3013\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1755.0388 - val_loss: 1108.5961\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 810.9927 - val_loss: 551.3033\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 391.7562 - val_loss: 301.4640\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 209.8547 - val_loss: 212.8826\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 151.3876 - val_loss: 189.2906\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 136.7690 - val_loss: 185.6452\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 134.1684 - val_loss: 185.7090\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 134.3029 - val_loss: 186.1141\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 133.9553 - val_loss: 185.2536\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 133.4099 - val_loss: 184.5115\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 133.0108 - val_loss: 184.0978\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 132.4649 - val_loss: 183.0443\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 131.8930 - val_loss: 182.4007\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 131.6525 - val_loss: 181.8514\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 131.0968 - val_loss: 181.2884\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 130.6101 - val_loss: 180.7776\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 130.1335 - val_loss: 180.1957\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 129.4026 - val_loss: 179.7991\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 129.2718 - val_loss: 179.7234\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 128.6328 - val_loss: 178.8413\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 127.7642 - val_loss: 177.7102\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 127.4681 - val_loss: 176.9368\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 126.6581 - val_loss: 176.4304\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 126.4025 - val_loss: 176.2944\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 125.9411 - val_loss: 176.0009\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 125.1268 - val_loss: 174.3126\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 124.2171 - val_loss: 173.4774\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 123.6255 - val_loss: 173.0312\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 123.0065 - val_loss: 172.1689\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122.3936 - val_loss: 171.6836\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 121.9929 - val_loss: 171.2764\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 121.0869 - val_loss: 169.9292\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 120.2899 - val_loss: 169.1012\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 119.4952 - val_loss: 168.1321\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 118.6423 - val_loss: 166.8113\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 117.9955 - val_loss: 166.1291\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 117.3368 - val_loss: 165.1309\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 116.3146 - val_loss: 165.1473\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 115.9840 - val_loss: 164.2626\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 115.0347 - val_loss: 163.0978\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 114.0872 - val_loss: 161.2646\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 113.0391 - val_loss: 160.2291\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 112.2012 - val_loss: 160.0262\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 111.4189 - val_loss: 158.6842\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 110.3713 - val_loss: 157.5488\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 109.2964 - val_loss: 155.9163\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 108.5975 - val_loss: 154.7624\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 107.5663 - val_loss: 154.1634\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 106.6294 - val_loss: 152.6724\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 105.4497 - val_loss: 151.6430\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104.6063 - val_loss: 151.0507\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 103.1917 - val_loss: 148.8986\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 102.4622 - val_loss: 147.4517\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 101.2853 - val_loss: 146.2169\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 100.2440 - val_loss: 145.0541\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 99.0151 - val_loss: 143.9812\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 97.9304 - val_loss: 143.2458\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96.8579 - val_loss: 141.7449\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 95.6369 - val_loss: 140.2287\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 94.5551 - val_loss: 138.9981\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 93.3440 - val_loss: 137.8043\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.1399 - val_loss: 136.7735\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.1342 - val_loss: 135.6752\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 90.1454 - val_loss: 134.3686\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 88.8306 - val_loss: 132.7183\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 87.4105 - val_loss: 131.3116\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 86.3962 - val_loss: 130.7962\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 85.0667 - val_loss: 128.2914\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 84.2030 - val_loss: 126.5104\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 82.6105 - val_loss: 125.1182\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 80.9889 - val_loss: 123.9193\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.7457 - val_loss: 123.0436\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.5432 - val_loss: 121.0726\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.4770 - val_loss: 119.5280\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.7785 - val_loss: 119.1212\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.1403 - val_loss: 117.4190\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.8175 - val_loss: 116.1326\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 73.1533 - val_loss: 114.8494\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 71.7774 - val_loss: 113.8264\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 70.8906 - val_loss: 112.1944\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.7178 - val_loss: 110.9831\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.9995 - val_loss: 109.5545\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 68.1026 - val_loss: 108.5115\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.8003 - val_loss: 108.1670\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1119 - val_loss: 106.9991\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 65.2949 - val_loss: 105.5241\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.7547 - val_loss: 104.5334\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.3916 - val_loss: 104.4162\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.7829 - val_loss: 103.4382\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.5299 - val_loss: 102.7250\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9808 - val_loss: 103.0330\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.6496 - val_loss: 101.4070\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.9298 - val_loss: 100.6850\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2799 - val_loss: 100.7220\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.0317 - val_loss: 100.9095\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 62.2043 - val_loss: 100.7844\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.7775 - val_loss: 99.2743\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7218 - val_loss: 99.2632\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.6025 - val_loss: 98.7117\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4646 - val_loss: 98.4173\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3879 - val_loss: 98.4086\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.7581 - val_loss: 98.8374\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2942 - val_loss: 98.0819\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2554 - val_loss: 98.3993\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3588 - val_loss: 98.8254\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 61.1954 - val_loss: 97.7664\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.4689 - val_loss: 97.6370\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.3777 - val_loss: 98.6717\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1753 - val_loss: 98.0346\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7806 - val_loss: 97.3430\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2278 - val_loss: 97.3622\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6280 - val_loss: 98.5719\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.2101 - val_loss: 98.1914\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8934 - val_loss: 97.2085\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7835 - val_loss: 97.0107\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1535 - val_loss: 98.6026\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.1167 - val_loss: 97.7010\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6654 - val_loss: 96.6259\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.8240 - val_loss: 96.8406\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.5797 - val_loss: 98.0575\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 61.0286 - val_loss: 97.9719\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.9350 - val_loss: 96.3663\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7405 - val_loss: 96.8077\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3902 - val_loss: 96.5763\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3038 - val_loss: 96.5522\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2738 - val_loss: 96.5921\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2965 - val_loss: 97.3325\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6866 - val_loss: 96.1949\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.1474 - val_loss: 96.7373\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.1484 - val_loss: 96.7896\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.2606 - val_loss: 96.4472\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0117 - val_loss: 95.9613\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9668 - val_loss: 96.7346\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3900 - val_loss: 97.2449\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.3796 - val_loss: 96.4807\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.6450 - val_loss: 96.7233\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9342 - val_loss: 95.9627\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9426 - val_loss: 95.3851\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.9439 - val_loss: 95.6356\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.8176 - val_loss: 95.6422\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.7105 - val_loss: 96.0960\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.0282 - val_loss: 95.3420\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3482 - val_loss: 96.6472\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7380 - val_loss: 95.5471\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4712 - val_loss: 95.3489\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6358 - val_loss: 95.4689\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9282 - val_loss: 95.0040\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.5626 - val_loss: 94.9058\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.0007 - val_loss: 97.2274\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.3023 - val_loss: 94.7982\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.5491 - val_loss: 94.7504\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 59.1318 - val_loss: 94.4141\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.6507 - val_loss: 94.4246\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9657 - val_loss: 94.6785\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.7529 - val_loss: 96.5315\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9207 - val_loss: 94.7035\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.9191 - val_loss: 94.7784\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2660 - val_loss: 95.8116\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0314 - val_loss: 94.5191\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.2364 - val_loss: 94.5537\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8402 - val_loss: 95.0818\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 59.1933 - val_loss: 94.8802\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.0001 - val_loss: 94.7094\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.9941 - val_loss: 94.4850\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 59.4302 - val_loss: 95.1388\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.6192 - val_loss: 93.4528\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 58.9941 - val_loss: 93.6434\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.4983 - val_loss: 93.9114\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8351 - val_loss: 93.2472\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4714 - val_loss: 93.5789\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.9710 - val_loss: 94.6816\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2301 - val_loss: 93.0125\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2946 - val_loss: 93.0445\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4467 - val_loss: 92.9460\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.3188 - val_loss: 93.8619\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9641 - val_loss: 92.6907\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.7784 - val_loss: 93.1879\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2938 - val_loss: 92.3917\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.0802 - val_loss: 92.5846\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2159 - val_loss: 93.1218\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.8218 - val_loss: 93.0108\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.2265 - val_loss: 91.8059\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4838 - val_loss: 91.7729\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.8419 - val_loss: 93.3917\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6239 - val_loss: 91.7399\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.3014 - val_loss: 91.6535\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.4811 - val_loss: 92.5298\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.9635 - val_loss: 91.3551\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6335 - val_loss: 94.0200\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 58.4086 - val_loss: 91.6261\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.3445 - val_loss: 90.6232\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.1976 - val_loss: 90.6760\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 57.2093 - val_loss: 91.0395\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4036 - val_loss: 90.6327\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.0277 - val_loss: 90.0535\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6937 - val_loss: 89.9614\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.4555 - val_loss: 92.0451\n",
      "3/3 [==============================] - 0s 927us/step - loss: 90.6940\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2189.4419 - val_loss: 411.4361\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 273.0460 - val_loss: 207.0188\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 123.1660 - val_loss: 167.8823\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 101.8446 - val_loss: 137.5724\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 88.0620 - val_loss: 122.2006\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 77.7656 - val_loss: 110.6780\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 71.4086 - val_loss: 99.2643\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66.7558 - val_loss: 91.6529\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63.8873 - val_loss: 84.9187\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 60.5161 - val_loss: 82.1636\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 59.8335 - val_loss: 80.7629\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.4316 - val_loss: 77.4708\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.9316 - val_loss: 78.4483\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.1372 - val_loss: 76.6793\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.7006 - val_loss: 75.8318\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.5466 - val_loss: 77.5782\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.1792 - val_loss: 74.4010\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.4580 - val_loss: 75.8673\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.6318 - val_loss: 74.6975\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.9500 - val_loss: 74.0327\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.7133 - val_loss: 74.5051\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.3889 - val_loss: 74.1781\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.0201 - val_loss: 72.3215\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.9994 - val_loss: 77.2325\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.3821 - val_loss: 74.1597\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.9279 - val_loss: 71.3981\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.9312 - val_loss: 75.3749\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.0548 - val_loss: 70.5272\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.7119 - val_loss: 70.0356\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.2520 - val_loss: 72.9768\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.9335 - val_loss: 69.5961\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.2694 - val_loss: 70.0095\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.3609 - val_loss: 69.5269\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.5996 - val_loss: 68.9033\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.8848 - val_loss: 68.9534\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.9110 - val_loss: 67.2136\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.3447 - val_loss: 68.0936\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.2681 - val_loss: 67.6610\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.0090 - val_loss: 66.3417\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.2998 - val_loss: 65.8265\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.0340 - val_loss: 64.4540\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.3339 - val_loss: 66.5177\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.7489 - val_loss: 63.0274\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.0415 - val_loss: 63.7100\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.9157 - val_loss: 62.7863\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.9772 - val_loss: 62.3272\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.8995 - val_loss: 61.0623\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.0787 - val_loss: 59.9513\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.1580 - val_loss: 62.3924\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.6682 - val_loss: 58.0258\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.8490 - val_loss: 59.4788\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7903 - val_loss: 57.1838\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.3317 - val_loss: 57.7638\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.7633 - val_loss: 57.2975\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.4701 - val_loss: 54.5552\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.3630 - val_loss: 59.0555\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.8636 - val_loss: 56.9473\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.5008 - val_loss: 54.3307\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.8823 - val_loss: 56.2807\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.2197 - val_loss: 53.1313\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.5681 - val_loss: 53.5867\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.3889 - val_loss: 52.2703\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.0763 - val_loss: 51.0015\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.0697 - val_loss: 49.6733\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.1701 - val_loss: 53.7405\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.7422 - val_loss: 51.8634\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.8460 - val_loss: 49.2578\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.5399 - val_loss: 47.2651\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.2988 - val_loss: 47.2560\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.5597 - val_loss: 46.5579\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.2816 - val_loss: 47.7691\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.5654 - val_loss: 45.1326\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.6461 - val_loss: 44.4616\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.8297 - val_loss: 43.1705\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.2375 - val_loss: 43.1989\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.4236 - val_loss: 44.7808\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.9363 - val_loss: 40.2565\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.1203 - val_loss: 44.3076\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.2177 - val_loss: 40.7563\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.9214 - val_loss: 39.9078\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.2116 - val_loss: 38.2713\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.8590 - val_loss: 38.8524\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.0645 - val_loss: 46.0021\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.5699 - val_loss: 47.2442\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.6091 - val_loss: 36.0735\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.9883 - val_loss: 40.6899\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.1447 - val_loss: 37.6191\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.0017 - val_loss: 36.1899\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.6038 - val_loss: 40.0982\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.2660 - val_loss: 35.8428\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.7807 - val_loss: 33.6909\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.4166 - val_loss: 33.9959\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.0538 - val_loss: 32.8290\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.5580 - val_loss: 32.9820\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.5578 - val_loss: 35.5845\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 27.2898 - val_loss: 35.9205\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.1532 - val_loss: 33.2994\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.8324 - val_loss: 30.3541\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.0589 - val_loss: 48.6377\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.6020 - val_loss: 32.5563\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.2384 - val_loss: 38.7319\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.3520 - val_loss: 35.4237\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.5664 - val_loss: 29.4395\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.9026 - val_loss: 31.4802\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.9231 - val_loss: 29.1129\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.9555 - val_loss: 29.3829\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.4105 - val_loss: 29.5538\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.3324 - val_loss: 28.9182\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.3565 - val_loss: 36.4236\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.6288 - val_loss: 29.5625\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.8018 - val_loss: 30.0407\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.6849 - val_loss: 28.4011\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.3918 - val_loss: 30.4091\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.9259 - val_loss: 32.5807\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.0756 - val_loss: 28.4776\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.2751 - val_loss: 31.5330\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.5226 - val_loss: 27.6302\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.4952 - val_loss: 27.3095\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.3873 - val_loss: 30.5464\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.3185 - val_loss: 61.1273\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.5160 - val_loss: 33.2369\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.1499 - val_loss: 26.6981\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.8469 - val_loss: 30.6819\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.6203 - val_loss: 25.9051\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.5849 - val_loss: 26.3859\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.6785 - val_loss: 25.8765\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2946 - val_loss: 26.0705\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.1996 - val_loss: 27.2527\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2338 - val_loss: 26.3270\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.1150 - val_loss: 26.2984\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.8130 - val_loss: 27.3055\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.0852 - val_loss: 24.2057\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.2220 - val_loss: 25.0491\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.7761 - val_loss: 29.4668\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.1536 - val_loss: 23.6689\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.2602 - val_loss: 24.7226\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.0355 - val_loss: 26.0513\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.2041 - val_loss: 28.3788\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.0070 - val_loss: 24.1492\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.8862 - val_loss: 26.7119\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.3327 - val_loss: 22.7994\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.2983 - val_loss: 24.8123\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 22.4439 - val_loss: 22.6994\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.3875 - val_loss: 30.6936\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.6687 - val_loss: 24.9670\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0073 - val_loss: 24.8282\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.2091 - val_loss: 24.9277\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2745 - val_loss: 22.7682\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.7608 - val_loss: 43.1478\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.7506 - val_loss: 20.9966\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2961 - val_loss: 21.8684\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6589 - val_loss: 21.5797\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.3359 - val_loss: 24.4865\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.3467 - val_loss: 25.7820\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.0907 - val_loss: 19.5655\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2391 - val_loss: 24.6229\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6933 - val_loss: 25.3059\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.9138 - val_loss: 27.3839\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.1585 - val_loss: 22.9425\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.2618 - val_loss: 20.6009\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.0160 - val_loss: 26.3142\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 19.5885 - val_loss: 26.7306\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3585 - val_loss: 24.4117\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.7825 - val_loss: 33.3109\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.5390 - val_loss: 21.6506\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.1691 - val_loss: 24.4374\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.0849 - val_loss: 20.6599\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.5497 - val_loss: 32.1972\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.6983 - val_loss: 25.3142\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.9097 - val_loss: 19.4329\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.7402 - val_loss: 19.2993\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.9689 - val_loss: 19.8422\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.6154 - val_loss: 19.9334\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4170 - val_loss: 26.6120\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.4613 - val_loss: 23.5399\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.7087 - val_loss: 22.7621\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.4330 - val_loss: 32.6186\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.6475 - val_loss: 20.5039\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.2239 - val_loss: 23.7800\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.7183 - val_loss: 19.7722\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.6281 - val_loss: 23.4113\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.2717 - val_loss: 18.5311\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.2193 - val_loss: 20.8546\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.1313 - val_loss: 19.6842\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.7297 - val_loss: 18.0648\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.5970 - val_loss: 20.3070\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.3157 - val_loss: 18.2984\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.4232 - val_loss: 18.6008\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.0672 - val_loss: 20.1155\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.2902 - val_loss: 19.9469\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.1141 - val_loss: 24.8906\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.3527 - val_loss: 21.6426\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.7905 - val_loss: 20.1707\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.6033 - val_loss: 18.1424\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.3507 - val_loss: 18.1092\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.5003 - val_loss: 20.3652\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.8806 - val_loss: 24.4022\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.3809 - val_loss: 21.1079\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.8643 - val_loss: 19.2011\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 17.6006 - val_loss: 17.6620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "tuned_model = KerasRegressor(build_fn=build_model)\n",
    "\n",
    "# possible values of parameters - we want to find the best set of them\n",
    "\n",
    "params = {'number_of_hidden_layers': [2, 3, 4, 5], 'number_of_neurons': [5, 15, 25]}\n",
    "\n",
    "# Create a randomize search cross validation object, to find the best hyperparameters it will use a KFold cross validation with 5 splits\n",
    "random_search = RandomizedSearchCV(tuned_model, param_distributions = params, cv = KFold(5))\n",
    "\n",
    "\n",
    "#Dataset\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.20) #80% training and 20% testing\n",
    "\n",
    "# find the best parameters!\n",
    "his=random_search.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_neurons': 25,\n",
       " 'number_of_hidden_layers': 4,\n",
       " 'build_fn': <function __main__.build_model(number_of_hidden_layers=3, number_of_neurons=2)>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_.get_params()\n",
    "# best combination of hyperparameters is:\n",
    "  #  'number_of_hidden_layers': 4,\n",
    "  #  'number_of_neurons': 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_found_model = build_model(4, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 2912.0842 - val_loss: 956.7483\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 539.6704 - val_loss: 286.4431\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 179.6971 - val_loss: 200.6961\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 122.3870 - val_loss: 120.6663\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 74.4059 - val_loss: 89.6117\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.2496 - val_loss: 82.9684\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 62.2081 - val_loss: 82.4884\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 60.6498 - val_loss: 81.0170\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 59.3923 - val_loss: 80.0848\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.9933 - val_loss: 79.5008\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.2885 - val_loss: 79.3125\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58.4753 - val_loss: 77.3459\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.2654 - val_loss: 78.8570\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 57.0617 - val_loss: 76.3076\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.8735 - val_loss: 76.5659\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.9707 - val_loss: 73.4934\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.6322 - val_loss: 73.1544\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 55.3997 - val_loss: 72.3751\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.6479 - val_loss: 73.6152\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54.6170 - val_loss: 69.2089\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.7353 - val_loss: 73.9849\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.6919 - val_loss: 68.8334\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52.5929 - val_loss: 69.3549\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.7943 - val_loss: 67.5082\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51.7804 - val_loss: 67.1638\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.2128 - val_loss: 69.9042\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.8114 - val_loss: 64.8856\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.9643 - val_loss: 64.4088\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.2209 - val_loss: 66.1800\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.2875 - val_loss: 62.9610\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50.1148 - val_loss: 63.9656\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 49.1962 - val_loss: 60.7957\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.2381 - val_loss: 63.4311\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.3532 - val_loss: 62.9261\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 47.6086 - val_loss: 59.1488\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.7349 - val_loss: 60.2544\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.9764 - val_loss: 60.8342\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.8430 - val_loss: 54.7232\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 45.5912 - val_loss: 57.9794\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.4309 - val_loss: 54.0197\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.5548 - val_loss: 57.4158\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.7576 - val_loss: 55.7110\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.3362 - val_loss: 52.2147\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.0812 - val_loss: 56.6726\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.2884 - val_loss: 52.6228\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 42.1428 - val_loss: 50.5132\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.8570 - val_loss: 49.5893\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.5033 - val_loss: 49.5883\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.2463 - val_loss: 48.3266\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38.5677 - val_loss: 48.1688\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.1781 - val_loss: 45.6469\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.4956 - val_loss: 44.4911\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.6138 - val_loss: 46.1818\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.8887 - val_loss: 45.9584\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.7228 - val_loss: 46.2084\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.3590 - val_loss: 45.6076\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.3237 - val_loss: 41.5499\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.7422 - val_loss: 45.5796\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.2330 - val_loss: 51.5022\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.5584 - val_loss: 39.6997\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.6261 - val_loss: 40.1773\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.7679 - val_loss: 38.6022\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.3825 - val_loss: 36.4548\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.7934 - val_loss: 39.8560\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.7101 - val_loss: 36.2091\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.6819 - val_loss: 36.6088\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.3667 - val_loss: 41.0056\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.1837 - val_loss: 40.1328\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.2988 - val_loss: 33.8365\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.5418 - val_loss: 43.7860\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.8851 - val_loss: 50.9279\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30.1644 - val_loss: 42.8135\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.6793 - val_loss: 34.6105\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.0617 - val_loss: 36.4720\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28.1019 - val_loss: 32.2624\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.7973 - val_loss: 38.2459\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.9910 - val_loss: 34.2924\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.1962 - val_loss: 33.9569\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.0413 - val_loss: 32.0899\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.1754 - val_loss: 33.4972\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.2560 - val_loss: 31.8433\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.0769 - val_loss: 29.4753\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.6884 - val_loss: 30.3225\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.4851 - val_loss: 30.2324\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.9016 - val_loss: 29.0209\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.2707 - val_loss: 29.9679\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.5475 - val_loss: 35.1633\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.7814 - val_loss: 36.9126\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.0571 - val_loss: 38.0926\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.9280 - val_loss: 29.7558\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23.4945 - val_loss: 27.8839\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.4878 - val_loss: 44.3379\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.6830 - val_loss: 44.8981\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.6101 - val_loss: 27.3165\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.6446 - val_loss: 29.0004\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.8319 - val_loss: 26.5642\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.7297 - val_loss: 26.1332\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.4313 - val_loss: 30.2345\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.5624 - val_loss: 26.2002\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.8211 - val_loss: 26.7212\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.5459 - val_loss: 26.7171\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.5320 - val_loss: 26.9973\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.2604 - val_loss: 34.8175\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2044 - val_loss: 28.5576\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2934 - val_loss: 30.4862\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.3064 - val_loss: 23.8311\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.5279 - val_loss: 25.7187\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.4532 - val_loss: 25.9271\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.2483 - val_loss: 24.7631\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.9996 - val_loss: 26.1853\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.9507 - val_loss: 29.6617\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.9678 - val_loss: 24.6435\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.7786 - val_loss: 28.2045\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.5773 - val_loss: 33.3052\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.5744 - val_loss: 34.9135\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.7877 - val_loss: 30.0722\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7909 - val_loss: 26.3922\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.9274 - val_loss: 24.8255\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1087 - val_loss: 25.7322\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.2791 - val_loss: 22.7854\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0788 - val_loss: 24.4728\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.9061 - val_loss: 25.8479\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.7936 - val_loss: 31.5396\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.3018 - val_loss: 27.3848\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.7516 - val_loss: 23.1651\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.8127 - val_loss: 22.7026\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.2898 - val_loss: 25.2067\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.1124 - val_loss: 24.9504\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.6389 - val_loss: 26.3948\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.7039 - val_loss: 25.9430\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.1631 - val_loss: 27.1595\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.5889 - val_loss: 23.8813\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.6628 - val_loss: 22.7975\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.8893 - val_loss: 29.6578\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5371 - val_loss: 25.3691\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.2402 - val_loss: 28.6441\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.0239 - val_loss: 22.4248\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.4302 - val_loss: 22.0110\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.8270 - val_loss: 20.6158\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0469 - val_loss: 23.3869\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3054 - val_loss: 22.4882\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1550 - val_loss: 26.0903\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.1159 - val_loss: 21.6533\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0464 - val_loss: 20.1693\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.5376 - val_loss: 23.6057\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3305 - val_loss: 32.7829\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.9068 - val_loss: 23.4341\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0473 - val_loss: 21.2871\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.6180 - val_loss: 21.5436\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.6195 - val_loss: 20.4632\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8962 - val_loss: 22.9103\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.0007 - val_loss: 25.5065\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.5336 - val_loss: 21.0873\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.9527 - val_loss: 23.7759\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.4954 - val_loss: 21.4447\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.9687 - val_loss: 21.6005\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.8644 - val_loss: 23.5767\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.6375 - val_loss: 23.8555\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.8952 - val_loss: 21.7272\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.1606 - val_loss: 22.5087\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.6708 - val_loss: 21.2315\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.0902 - val_loss: 20.6519\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.5865 - val_loss: 19.9352\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.1265 - val_loss: 21.0064\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.4620 - val_loss: 22.1375\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.4647 - val_loss: 18.8744\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.1055 - val_loss: 19.4803\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.8121 - val_loss: 21.6513\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.2287 - val_loss: 21.0482\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.0084 - val_loss: 19.5744\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.2462 - val_loss: 19.2985\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.3198 - val_loss: 27.4327\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.9435 - val_loss: 18.5127\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.0298 - val_loss: 20.3363\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.8840 - val_loss: 20.1309\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 15.5617 - val_loss: 18.7265\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.0293 - val_loss: 19.5205\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.5707 - val_loss: 19.7096\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.8098 - val_loss: 18.5769\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.5879 - val_loss: 19.7725\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.0352 - val_loss: 16.9263\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.7924 - val_loss: 24.8355\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.2402 - val_loss: 29.6617\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.0566 - val_loss: 20.8990\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.0727 - val_loss: 28.5778\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.9552 - val_loss: 22.2773\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.4212 - val_loss: 20.8549\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.9742 - val_loss: 19.0676\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.8979 - val_loss: 20.1932\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.3759 - val_loss: 19.2873\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.9034 - val_loss: 36.0380\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 21.2073 - val_loss: 30.6794\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.9401 - val_loss: 25.7408\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.8706 - val_loss: 19.8920\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.6561 - val_loss: 18.5204\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.8758 - val_loss: 18.5062\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.6885 - val_loss: 18.6373\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.0106 - val_loss: 18.6869\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.9697 - val_loss: 19.1114\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.9453 - val_loss: 19.5804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc9601fdee0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_found_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model minimum mse loss on validation set is:  16.926280975341797 \n"
     ]
    }
   ],
   "source": [
    "print(f\"The best model minimum mse loss on validation set is:  { min(best_found_model.history.history['val_loss']) } \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 22, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse of Best found Saved Model is 19.58\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_found_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"The mse of Best found Saved Model is {round(mse, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_ax = range(len(y_pred))\n",
    "plt.scatter(x_ax, y_test, s=5, color=\"blue\", label=\"original\") \n",
    "plt.plot(x_ax, y_pred, lw=0.8, color=\"green\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
